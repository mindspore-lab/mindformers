# DeepSeek Coder

> ## ğŸš¨ å¼ƒç”¨è¯´æ˜
>
> æœ¬æ¨¡å‹å·²è¿‡æ—¶ï¼Œä¸å†è¿›è¡Œç»´æŠ¤ï¼Œå¹¶å°†åœ¨ *1.5.0* ä¹‹åçš„ç‰ˆæœ¬ä¸‹æ¶ã€‚å¦‚éœ€ä½¿ç”¨æ­¤æ¨¡å‹ï¼Œå»ºè®®æ ¹æ®å®˜æ–¹æ–‡æ¡£ä¸­çš„ **[æ¨¡å‹åº“](https://www.mindspore.cn/mindformers/docs/zh-CN/dev/start/models.html)** é€‰æ‹©åˆé€‚çš„ç‰ˆæœ¬è¿›è¡Œä½¿ç”¨ã€‚
>
> å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ **[ç¤¾åŒºIssue](https://gitee.com/mindspore/mindformers/issues/new)** æäº¤åé¦ˆã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£ä¸æ”¯æŒï¼

## æ¨¡å‹æè¿°

DeepSeek Coderç”±ä¸€ç³»åˆ—ä»£ç è¯­è¨€æ¨¡å‹ç»„æˆï¼Œæ¯ä¸ªæ¨¡å‹éƒ½åœ¨2T tokenä¸Šä»é›¶å¼€å§‹è®­ç»ƒï¼Œå…¶ä¸­87%çš„ä»£ç å’Œ13%çš„è‡ªç„¶è¯­è¨€ç»„æˆï¼Œè‹±æ–‡å’Œä¸­æ–‡éƒ½æœ‰ã€‚åœ¨ç¼–ç åŠŸèƒ½æ–¹é¢ï¼ŒDeepSeek
Coderåœ¨å¤šç§ç¼–ç¨‹è¯­è¨€å’Œå„ç§åŸºå‡†æµ‹è¯•ä¸Šçš„å¼€æºä»£ç æ¨¡å‹ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## æ¨¡å‹æ€§èƒ½

ä»¥ä¸‹æ¨¡å‹æ€§èƒ½å‡ç”±Atlas 800T A2ç¡¬ä»¶ç¯å¢ƒä¸‹æµ‹è¯•å¾—å‡ºã€‚

| Config                                                |      Task       | Datasets | SeqLength |  Phase  | Performance |
|:------------------------------------------------------|:---------------:|:--------:|:---------:|:-------:|:-----------:|
| [deepseek1.5-7b](deepseek1_5_7b/predict_deepseek_coder1_5_7b.yaml) | text_generation |    -     |   2048    | Predict | 60 tokens/s |

ä»¥ä¸‹æ¨¡å‹æ€§èƒ½å‡ç”±Atlas 900 A2 PoDcç¡¬ä»¶ç¯å¢ƒä¸‹æµ‹è¯•å¾—å‡ºã€‚

| Config                                                 |      Task       |  Datasets   | SeqLength |  Phase   |  Performance   |
|:-------------------------------------------------------|:---------------:|:-----------:|:---------:|:--------:|:--------------:|
| [deepseek1.5-7b](deepseek1_5_7b/finetune_deepseek_coder1_5_7b.yaml) | text_generation | code_alpaca |   8192    | Finetune | 340 tokens/s/p |

## æ¨¡å‹æ–‡ä»¶

`deepseek-coder-7b-v1.5` åŸºäº `mindformers` å®ç°ï¼Œä¸»è¦æ¶‰åŠçš„æ–‡ä»¶æœ‰ï¼š

1. æ¨¡å‹é…ç½®ï¼š

    ```text
    deepseek1_5/deepseek1_5_7b
        â”œâ”€â”€ finetune_deepseek_coder1_5_7b.yaml     # å…¨å‚å¾®è°ƒå¯åŠ¨é…ç½®
        â””â”€â”€ predict_deepseek_coder1_5_7b.yaml     # åœ¨çº¿æ¨ç†å¯åŠ¨é…ç½®
    ```

2. æ¨¡å‹ç›¸å…³è„šæœ¬ï¼š

    ```text
    deepseek1_5
        â”œâ”€â”€ alpaca_converter.py                   # alpacaæ•°æ®é›†æ ¼å¼è½¬æ¢è„šæœ¬
        â”œâ”€â”€ convert_weight.py                     # hf->msæƒé‡è½¬æ¢è„šæœ¬
        â”œâ”€â”€ convert_reversed.py                   # ms->hfæƒé‡è½¬æ¢è„šæœ¬
        â””â”€â”€ deepseek_preprocess_1_5.py            # alpacaæ•°æ®é›†æ ¼å¼è½¬æ¢è„šæœ¬
    ```

## ç¯å¢ƒåŠæ•°æ®å‡†å¤‡

### å®‰è£…ç¯å¢ƒ

### ç¯å¢ƒå‚æ•°è®¾ç½®

```shell
export MS_DEV_RUNTIME_CONF="inline:true"
```

MindFormersè½¯ç¡¬ä»¶é…å¥—å…³ç³»ä»¥åŠå®‰è£…å‚è€ƒ[ç¯å¢ƒå®‰è£…æŒ‡å—](../../README_CN.md#äºŒmindformerså®‰è£…)å’Œ[ç‰ˆæœ¬åŒ¹é…å…³ç³»](../../README_CN.md#ä¸‰ç‰ˆæœ¬åŒ¹é…å…³ç³»)ã€‚

### æ•°æ®åŠæƒé‡å‡†å¤‡

#### æ•°æ®é›†ä¸‹è½½

å½“å‰æä¾›code_alpaca_20k.jsonæ•°æ®é›†çš„é¢„å¤„ç†å’Œå¾®è°ƒæ ·ä¾‹ï¼Œç”¨äºå¯¹Deepseek-Coder-7B-v1.5-Instructï¼ŒDeepseek-Coder-7B-v1.5-Baseæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚

| æ•°æ®é›†åç§°                           | é€‚ç”¨æ¨¡å‹           |                                          é€‚ç”¨é˜¶æ®µ                                           | ä¸‹è½½é“¾æ¥                                                                                    |
|:--------------------------------|----------------|:---------------------------------------------------------------------------------------:|-----------------------------------------------------------------------------------------|
| code_alpaca_20k.json | Deepseek-Coder-7B-v1.5-Instruct<br/>Deepseek-Coder-7B-v1.5-Base | finetune / lora | [Link](https://github.com/sahil280114/codealpaca/blob/master/data/code_alpaca_20k.json) |

ä¸‹è½½æ•°æ®é›†åï¼Œéœ€è¦å…ˆæ‰§è¡Œalpaca_converter.pyè„šæœ¬å°†æ•°æ®é›†è½¬æ¢ä¸ºalpaca-data-converted.jsonï¼Œå†ç”¨deepseek_preprocess_1_5.pyè„šæœ¬è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼Œå°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºmindrecordæ ¼å¼ã€‚æ•°æ®é¢„å¤„ç†ä¸­æ‰€ç”¨çš„`tokenizer.json`å¯ä»¥é€šè¿‡[é“¾æ¥](https://huggingface.co/deepseek-ai/deepseek-coder-33b-instruct/blob/main/tokenizer.json)è¿›è¡Œä¸‹è½½ã€‚

```python
python alpaca_converter.py \
  --data_path /path/code_alpaca_20k.json \
  --output_path /path/alpaca-data-converted.json

python deepseek_preprocess_1_5.py \
  --dataset_type qa \
  --input_glob /path/alpaca-data-converted.json  \
  --model_file /path/tokenizer.json \
  --seq_length 4096 \
  --output_file /path/alpaca_finetune_4k.mindrecord

å‚æ•°è¯´æ˜ï¼š

- dataset_type: å›ºå®šå€¼ qa
- Input_globï¼šå¾…å¤„ç†çš„æ•°æ®é›†è·¯å¾„ï¼Œå…·ä½“åˆ°æ–‡ä»¶
- model_fileï¼štokenizeræ–‡ä»¶ï¼Œä¸€èˆ¬ä»huggingfceä¸‹è½½ï¼Œå…·ä½“åˆ°æ–‡ä»¶
- seq_lengthï¼šè¯è¡¨é•¿åº¦ï¼Œå½“å‰å›ºå®šä¸º4096ï¼Œå¯ä»¥ä¿®æ”¹ä¸º16384ç­‰
- pad_token_idï¼šç©ºç™½å¡«å……IDï¼Œå½“å‰å›ºå®šä¸º100015
- output_fileï¼šè¾“å‡ºæ–‡ä»¶ï¼Œå…·ä½“åˆ°æ–‡ä»¶ï¼Œåç¼€ä¸ºmindrecord
```

#### æ¨¡å‹æƒé‡ä¸‹è½½

ç”¨æˆ·å¯ä»¥ä»HuggingFaceå®˜æ–¹ä¸‹è½½é¢„è®­ç»ƒæƒé‡ï¼Œç»è¿‡[æ¨¡å‹æƒé‡è½¬æ¢](#æ¨¡å‹æƒé‡è½¬æ¢)åè¿›è¡Œä½¿ç”¨ï¼Œtokenizer.jsonæ–‡ä»¶ä¹Ÿåœ¨é“¾æ¥ä¸­ä¸‹è½½ã€‚

| æ¨¡å‹åç§°                            | MindSporeæƒé‡ |                             æƒé‡                             | ç”¨é€” |
|:--------------------------------|------------| :----------------------------------------------------------: |----|
| Deepseek-Coder-7B-v1.5-Instruct | - | [Link](https://huggingface.co/deepseek-ai/deepseek-coder-7b-instruct-v1.5/tree/main) | æ¨ç† |
| Deepseek-Coder-7B-v1.5-Base     | - |       [Link](deepseek-ai/deepseek-coder-7b-base-v1.5)        | å¾®è°ƒ |

#### æ¨¡å‹æƒé‡è½¬æ¢

##### torchæƒé‡è½¬mindsporeæƒé‡

æ‰§è¡Œ`convert_weight.py`è½¬æ¢è„šæœ¬ï¼Œå°†HuggingFaceçš„æƒé‡è½¬æ¢ä¸ºå®Œæ•´çš„ckptæƒé‡ã€‚

```python
cd research
python convert_weight.py \
--model deepseek1_5 \
--input_path /path/ckpt \
--output_path MS_CKPT_NAME
```

- å‚æ•°è¯´æ˜
  input_path: é¢„è®­ç»ƒæƒé‡æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•, æ­¤å‚æ•°å¿…é¡», ä¸”éœ€è¦åŒ…å«config.jsonç›¸å…³æ¨¡å‹æ–‡ä»¶
  output_path: è½¬æ¢åçš„è¾“å‡ºæ–‡ä»¶å­˜æ”¾è·¯å¾„ï¼ˆ`.ckpt`æ–‡ä»¶ï¼‰, æ­¤å‚æ•°å¿…é¡»

##### [æ¨¡å‹æƒé‡åˆ‡åˆ†ä¸åˆå¹¶](../../docs/feature_cards/Transform_Ckpt.md)*

ä»hugging faceæˆ–å®˜æ–¹githubä»“åº“è½¬æ¢è€Œæ¥çš„æƒé‡é€šå¸¸æ˜¯å•å¡æƒé‡ï¼ŒåŸºäºè¯¥æƒé‡è¿›è¡Œå¤šå¡å¾®è°ƒï¼Œè¯„æµ‹ï¼Œæ¨ç†ï¼Œæ¶‰åŠckptä»å•æœºç­–ç•¥åˆ°åˆ†å¸ƒå¼ç­–ç•¥çš„åˆ‡æ¢ã€‚

é€šå¸¸è®­ç»ƒé‡‡ç”¨åˆ†å¸ƒå¼è®­ç»ƒï¼ŒåŸºäºè¯¥æƒé‡è¿›è¡Œè¯„æµ‹ï¼Œæ¨ç†å¤šé‡‡ç”¨å•å¡ï¼Œæ¶‰åŠckptä»åˆ†å¸ƒå¼ç­–ç•¥åˆ°å•æœºç­–ç•¥çš„åˆ‡æ¢ã€‚

ä»¥ä¸Šæ¶‰åŠåˆ°ckptçš„å•å¡ï¼Œå¤šå¡è½¬æ¢ï¼Œè¯¦ç»†æ•™ç¨‹è¯·å‚è€ƒç‰¹æ€§æ–‡æ¡£[æ¨¡å‹æƒé‡åˆ‡åˆ†ä¸åˆå¹¶](../../docs/feature_cards/Transform_Ckpt.md)

## è‡ªåŠ¨è½¬æ¢æƒé‡

MindFormersæä¾›è‡ªåŠ¨æƒé‡è½¬æ¢å’Œç¦»çº¿æƒé‡è½¬æ¢åŠŸèƒ½ï¼Œå¯å‚è€ƒ[è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹](../../docs/feature_cards/Transform_Ckpt.md#è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹)å’Œ[ç¦»çº¿æƒé‡è½¬æ¢](../../docs/feature_cards/Transform_Ckpt.md#ç¦»çº¿æƒé‡è½¬æ¢)è¿›è¡Œåˆ†å¸ƒå¼æ¨¡å‹æƒé‡è½¬æ¢ã€‚

## å…¨å‚å¾®è°ƒ

æ‰§è¡Œå‰ä¿®æ”¹finetune_deepseek_coder1_5_7b.yamlæ–‡ä»¶çš„å‚æ•°`tokenizer_file`ä¸ºæ–‡ä»¶`tokenizer.json`è·¯å¾„

åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š

```shell
bash ./scripts/msrun_launcher.sh "./run_mindformer.py \
--config ./research/deepseek1_5/finetune_deepseek_coder1_5_7b.yaml \
--use_parallel True \
--load_checkpoint  ./ckpt_trans \
--run_mode train \
--train_data  ./dataset/train_data" \
8 8 127.0.0.1 9543 0 output/msrun_log False 3000;
```

å‚æ•°è¯´æ˜ï¼š

- config: å›ºå®šè·¯å¾„ï¼Œé…ç½®æ–‡ä»¶æ‰€åœ¨è·¯å¾„
- usr_parallelï¼šå›ºå®šå€¼ï¼ŒTrue
- load_checkpointï¼šåŠ è½½åˆ‡åˆ†åæƒé‡çš„è·¯å¾„ï¼Œå…·ä½“åˆ°æ–‡ä»¶å¤¹
- run_modeï¼šå›ºå®šå€¼ï¼Œtrain
- train_dataï¼šæ•°æ®é›†æ‰€åœ¨ä½ç½®ï¼Œå…·ä½“åˆ°æ–‡ä»¶å¤¹

> æ³¨ï¼šæ­¤æ¨¡å‹æš‚ä¸æ”¯æŒé…ç½®`context_parallel`ï¼Œå› æ­¤æš‚ä¸æ”¯æŒé•¿åºåˆ—ã€‚

## æ¨ç†

ä½¿ç”¨æ¨ç†åŠŸèƒ½æ—¶ï¼Œç›®å‰ä»…æ”¯æŒå¤šå¡æ¨ç†ï¼Œæ¨èä½¿ç”¨Deepseek-Coder-7B-v1.5-Instructå’ŒDeepseek-Coder-7B-v1.5-Baseæƒé‡ï¼Œé»˜è®¤è®¾ç½®seq_length=4096ï¼Œ
æ¨¡å‹æƒé‡ä»¥åŠtokenizeræ–‡ä»¶å¯å‚è€ƒæ¨¡å‹æƒé‡ä¸‹è½½ã€‚

### å‚æ•°é…ç½®

> æ ¸æŸ¥é…ç½®æ–‡ä»¶ `predict_deepseek_coder1_5_7b.yaml`ã€‚
> æ˜¯å¦åœ¨ç»è¿‡`è‡ªåŠ¨æƒé‡è½¬æ¢`æ“ä½œåï¼Œä¿®æ”¹`load_checkpoint`ï¼Œ`checkpoint_name_or_path`ï¼Œ`tokenizer_file`å‚æ•°ä¸ºå¾…ä½¿ç”¨çš„çœŸå®é…ç½®åœ°å€ã€‚
> æ ¸æŸ¥æ— è¯¯è¿›è¡Œåç»­æ“ä½œã€‚

### å¤šå¡æ¨ç†

æ‰§è¡Œå‰ä¿®æ”¹predict_deepseek_coder1_5_7b.yamlæ–‡ä»¶çš„å‚æ•°`auto_trans_ckpt`ä¸º`True`ï¼Œå‚æ•°`tokenizer_file`ä¸ºæ–‡ä»¶`tokenizer.json`è·¯å¾„ï¼Œ
å¹¶é…ç½®å‚æ•°`load_checkpoint`çš„è·¯å¾„ä¸ºåŠ è½½æƒé‡çš„è·¯å¾„

  ```shell
  bash scripts/msrun_launcher.sh "run_mindformer.py
  --config research/deepseek1_5/predict_deepseek_coder1_5_7b.yaml
  --run_mode=predict
  --predict_data 'write a quick sort algorithm.'
  --predict_length 100
  --use_parallel True
  --use_past True" 2
  # è¿è¡Œç»“æœï¼š[{'text_generation_text': ["write a quick sort algorithm.\nI'm trying to write a quicksort algorithm in python. I'm having trouble with the partition part.\nHere is my code:\n def quicksort(arr):\n if len(arr) <= 1:\n return arr\n pivot = arr[len(arr) // 2]\n left = [x for x in arr if x < pivot]\n middle = [x for x in arr if x == pivot]\n right = [x for x in arr if x > pivot]\n return quicksort(left) + middle + quicksort(right)\n print(quicksort([3,6,8,10,1,2,1]))\n\nThe problem is that the pivot is not being used to split the array into two halves. I'm not sure what I'm doing wrong.\nYou can use the following code to fix the problem:\n def quicksort(arr):\n if len(arr) <= 1:\n return arr\n pivot = arr[len(arr) // 2]\n left = [x for x in arr if x < pivot]\n middle = [x for x in arr if x == pivot]\n right = [x for x in arr if x > pivot]\n return quicksort(left) + middle + quicksort(right)\n print(quicksort([3,6,8,10,1,2,1]))\n\nThe problem is that the pivot is not being used to split the array into two halves. I'm not sure what I'm doing wrong.\nThe problem is that the pivot is not being used to split the array into two halves. I'm not sure what I'm doing wrong.\nThe problem is that the pivot is not being used to split the array into two halves. I'm not sure what I'm doing wrong.\nThe problem is that the pivot is not being used to split the array into two halves. I'm not sure what I'm doing wrong.\nThe problem is that the pivot is not being used to split the array into two halves. I'm not sure what I'm doing wrong.\nThe problem is that the pivot is not being used to split the array into two halves. I'm not sure what I'm doing wrong.\nThe"]}]
  ```