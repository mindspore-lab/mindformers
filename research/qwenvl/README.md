# Qwen-VL

> ## ğŸš¨ å¼ƒç”¨è¯´æ˜
>
> æœ¬æ¨¡å‹å·²è¿‡æ—¶ï¼Œä¸å†è¿›è¡Œç»´æŠ¤ï¼Œå¹¶å°†åœ¨ *1.6.0* ç‰ˆæœ¬ä¸‹æ¶ã€‚å¦‚éœ€ä½¿ç”¨æ­¤æ¨¡å‹ï¼Œå»ºè®®æ ¹æ®å®˜æ–¹æ–‡æ¡£ä¸­çš„ **[æ¨¡å‹åº“](https://www.mindspore.cn/mindformers/docs/zh-CN/r1.5.0/start/models.html)** é€‰æ‹©åˆé€‚çš„ç‰ˆæœ¬è¿›è¡Œä½¿ç”¨ã€‚
>
> å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ **[ç¤¾åŒºIssue](https://gitee.com/mindspore/mindformers/issues/new)** æäº¤åé¦ˆã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£ä¸æ”¯æŒï¼

## æ¨¡å‹æè¿°

Qwen-VL æ˜¯é˜¿é‡Œäº‘ç ”å‘çš„å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLarge Vision Language Model, LVLMï¼‰ã€‚Qwen-VL å¯ä»¥ä»¥å›¾åƒã€æ–‡æœ¬ã€æ£€æµ‹æ¡†ä½œä¸ºè¾“å…¥ï¼Œå¹¶ä»¥æ–‡æœ¬å’Œæ£€æµ‹æ¡†ä½œä¸ºè¾“å‡ºã€‚

```text
@article{Qwen-VL,
  title={Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}
```

## æ¨¡å‹æ€§èƒ½

ä»¥ä¸‹æ¨¡å‹æ€§èƒ½å‡ç”±Atlas 800T A2ç¡¬ä»¶ç¯å¢ƒä¸‹æµ‹è¯•å¾—å‡ºã€‚

| Config                                                    |             Task              |      Datasets       |   Performance   |  Phase   |
|:----------------------------------------------------------|:-----------------------------:|:-------------------:|:---------------:|:--------:|
| [qwenvl_9.6b](qwenvl_9.6b/finetune_qwenvl_9.6b_bf16.yaml) | multimodal_to_text_generation | LlaVA-Instruct-150K | 2587 tokens/s/p | Finetune |
| [qwenvl_9.6b](qwenvl_9.6b/predict_qwenvl_9.6b.yaml)       | multimodal_to_text_generation |          -          |   42 tokens/s   | Predict  |

## æ¨¡å‹æ–‡ä»¶

`Qwen-VL` åŸºäº `MindFormers` å®ç°ï¼Œä¸»è¦æ¶‰åŠçš„æ–‡ä»¶æœ‰ï¼š

1. æ¨¡å‹å…·ä½“å®ç°ï¼š

   ```text
   research/qwenvl
     â”œâ”€â”€ qwenvl_config.py         # é…ç½®æ–‡ä»¶
     â”œâ”€â”€ qwenvl_tokenizer.py      # tokenizer
     â”œâ”€â”€ qwenvl_model.py          # qwenvlæ¨¡å‹å®ç°
     â””â”€â”€ qwen_model.py            # qwenæ¨¡å‹å®ç°
   ```

2. æ¨¡å‹é…ç½®ï¼š

   ```text
   research/qwenvl
     â””â”€â”€ qwenvl_9.6b
             â”œâ”€â”€ predict_qwenvl_9.6b.yaml            # qwenvlæ¨ç†å¯åŠ¨é…ç½®
             â””â”€â”€ finetune_qwenvl_9.6b_bf16.yaml      # qwenvlå¾®è°ƒå¯åŠ¨é…ç½®ï¼ˆ2kï¼Œbf16ï¼‰
   ```

3. ç¯å¢ƒå‡†å¤‡å’Œä»»åŠ¡å¯åŠ¨è„šæœ¬ï¼š

   ```text
   research/qwenvl
     â”œâ”€â”€ qwenvl_processor.py      # è®­ç»ƒå’Œæ¨ç†æ—¶å€™ä½¿ç”¨çš„æ•°æ®å¤„ç†
     â”œâ”€â”€ qwenvl_transform.py      # qwenvl_processor.pyä¸­ä½¿ç”¨çš„æ–‡æœ¬æ•°æ®å¤„ç†å®ç°
     â”œâ”€â”€ convert_weight.py        # æƒé‡è½¬æ¢è„šæœ¬
     â””â”€â”€ data_convert.py          # æ•°æ®é¢„å¤„ç†è½¬æ¢è„šæœ¬
   ```

## ç¯å¢ƒåŠæ•°æ®å‡†å¤‡

### å®‰è£…ç¯å¢ƒ

MindFormersè½¯ç¡¬ä»¶é…å¥—å…³ç³»ä»¥åŠå®‰è£…å‚è€ƒ[ç¯å¢ƒå®‰è£…æŒ‡å—](../../README_CN.md#æºç ç¼–è¯‘å®‰è£…)å’Œ[ç‰ˆæœ¬åŒ¹é…å…³ç³»](../../README_CN.md#ç‰ˆæœ¬åŒ¹é…å…³ç³»)ã€‚

### æ•°æ®åŠæƒé‡å‡†å¤‡

#### æ•°æ®é›†åˆ¶ä½œ

ç›®å‰æœ¬ä»“åº“ä¸­å¯¹Qwen-VLä½¿ç”¨å¾®è°ƒæ•°æ®é›†æ ¼å¼åŒQwen-VLå¼€æºä½¿ç”¨æ•°æ®é›†æ ¼å¼ä¸€è‡´ï¼Œå¦‚ä¸‹ç¤ºä¾‹ï¼š

```json
[
  {
    "id": "identity_0",
    "conversations": [
      {
        "from": "user",
        "value": "Picture 1: <img>assets/demo.jpeg</img>\nå›¾ä¸­çš„ç‹—æ˜¯ä»€ä¹ˆå“ç§ï¼Ÿ"
      },
      {
        "from": "assistant",
        "value": "å›¾ä¸­æ˜¯ä¸€åªæ‹‰å¸ƒæ‹‰å¤šçŠ¬ã€‚"
      },
      {
        "from": "user",
        "value": "æ¡†å‡ºå›¾ä¸­çš„æ ¼å­è¡¬è¡«"
      },
      {
        "from": "assistant",
        "value": "<ref>æ ¼å­è¡¬è¡«</ref><box>(588,499),(725,789)</box>"
      }
    ]
  }
]
```

Qwen-VLå¼€æºæ¨¡å‹ä¸­æœªå¼€æºç›¸å…³æ•°æ®é›†ï¼Œä»¥ä¸‹æä¾›ä½¿ç”¨å…¬å¼€æ•°æ®é›†è½¬æ¢ä¸ºä¸Šè¿°æ•°æ®æ ¼å¼çš„æ ·ä¾‹ï¼Œå¹¶ç”¨äºæ¨¡å‹å¾®è°ƒã€‚è‹¥é“¾æ¥è·³è½¬å¤±è´¥ï¼Œå¯æ‰‹åŠ¨å¤åˆ¶ç²˜è´´ https://images.cocodataset.org/zips/train2014.zip è‡³åœ°å€æ è®¿é—®ä¸‹è½½ã€‚

| æ•°æ®é›†åç§°                                     |     é€‚ç”¨æ¨¡å‹     |   é€‚ç”¨é˜¶æ®µ   |                                                       ä¸‹è½½é“¾æ¥                                                        |
|:------------------------------------------|:------------:|:--------:|:-----------------------------------------------------------------------------------------------------------------:|
| LlaVA-Instruct-150K detail_23k.jsonï¼ˆå¯¹è¯æ•°æ®ï¼‰ | Qwen-VL-9.6B | finetune | [Link](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K/resolve/main/detail_23k.json?download=true) |
| COCO2014 Trainï¼ˆå›¾ç‰‡æ•°æ®ï¼‰                      | Qwen-VL-9.6B | finetune |                             [Link](https://images.cocodataset.org/zips/train2014.zip)                             |

ä¸‹è½½æ•°æ®é›†åï¼Œéœ€è¦æ‰§è¡Œ`data_convert.py`è„šæœ¬è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼Œå°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºä¸Šè¿°å¯¹è¯æ ¼å¼æ•°æ®ã€‚

```shell
cd research/qwenvl
python data_convert.py --data_path /path/to/detail_23k.json --image_location /location/of/coco/train2014 --output_path /path/to/converted/json --user_role_name user --assistant_role_name assistant
```

å…¶ä¸­`--data_path`è¡¨ç¤ºåŸå§‹å¯¹è¯æ•°æ®è·¯å¾„ï¼Œ`--image_location`è¡¨ç¤ºCOCO
train2014æ–‡ä»¶å¤¹æ‰€åœ¨è·¯å¾„ï¼Œè·¯å¾„ä¸åŒ…å«train2014ï¼Œ`--output_path`è¡¨ç¤ºè½¬æ¢åå¯¹è¯æ•°æ®ä¿å­˜è·¯å¾„, `--user_role_name`
è¡¨ç¤ºè½¬æ¢åå¯¹è¯ä¸­ç”¨æˆ·åç§°ï¼Œ`--assistant_role_name`è¡¨ç¤ºè½¬æ¢åå¯¹è¯ä¸­åŠ©æ‰‹åç§°ã€‚

#### æ¨¡å‹æƒé‡ä¸‹è½½

MindFormersæä¾›å·²ç»è½¬æ¢å®Œæˆçš„é¢„è®­ç»ƒæƒé‡ã€è¯è¡¨æ–‡ä»¶ç”¨äºå¾®è°ƒ/æ¨ç†ï¼Œç”¨æˆ·å¯è‡ªè¡Œä»ä¸‹æ–¹é“¾æ¥æ‹‰å–åç›´æ¥ä½¿ç”¨ï¼›Baseç”¨äºå¾®è°ƒï¼Œä¹Ÿå¯è¿›è¡Œç®€å•æ¨ç†ï¼ŒChatæƒé‡å¯ä»¥è‡ªè¡Œé€šè¿‡æƒé‡è½¬æ¢è„šæœ¬è¿›è¡Œè½¬æ¢ã€‚

ä¹Ÿå¯é€‰æ‹©ä»HuggingFaceä¸‹è½½æ‰€æœ‰å·¥ç¨‹æ–‡ä»¶åè¿›è¡Œ[æ¨¡å‹æƒé‡è½¬æ¢](#æ¨¡å‹æƒé‡è½¬æ¢)ä½¿ç”¨ã€‚

| æ¨¡å‹åç§°          |                                               MindSporeæƒé‡                                               |                           HuggingFaceæƒé‡                            |
|:--------------|:-------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------:|
| Qwen-VL-Base  | [Link](https://modelers.cn/coderepo/web/v1/file/MindSpore-Lab/Qwen-VL/main/media/qwenvl_base_fp16.ckpt) |            [Link](https://huggingface.co/Qwen/Qwen-VL/)            |
| qwen.tiktoken |     [Link](https://modelers.cn/coderepo/web/v1/file/MindSpore-Lab/Qwen-VL/main/media/qwen.tiktoken)     | [link](https://huggingface.co/Qwen/Qwen-VL/blob/main/qwen.tiktoken) |

#### æ¨¡å‹æƒé‡è½¬æ¢

è¿›è¡Œæƒé‡è½¬æ¢éœ€è¦å®‰è£…ä»¥ä¸‹ä¾èµ–åŒ…ã€‚

```shell
pip install torch
pip install transformers  # å¦‚æœtransformersä½¿ç”¨tokenizersç‰ˆæœ¬ä¸æ˜¯0.21.0ï¼Œåœ¨æƒé‡è½¬æ¢å®Œæˆåé‡è£…tokenizersç‰ˆæœ¬ä¸º0.21.0
pip install einops transformers_stream_generator accelerate
```

æ‰§è¡Œ`mindformers/convert_weight.py`è½¬æ¢è„šæœ¬ï¼Œå°†HuggingFaceçš„æƒé‡è½¬æ¢ä¸ºå®Œæ•´çš„ckptæƒé‡ã€‚

```shell
python convert_weight.py --model qwenvl --input_path /path/to/hf/dir \
--output_path /path/to/qwenvl_ms.ckpt \
--dtype fp16
```

å‚æ•°è¯´æ˜ï¼š

`input_path`ï¼šä¼ å…¥ä»`Huggingface`ä¸‹è½½å¥½æ¨¡å‹æ–‡ä»¶å¤¹ï¼›
`output_path`ï¼šæ˜¯ç”¨äºå­˜å‚¨è½¬æ¢åæƒé‡çš„è·¯å¾„ï¼›
`dtype`ï¼šè½¬æ¢æƒé‡çš„ç²¾åº¦é€‰æ‹©ã€‚

## å¾®è°ƒ

å¾®è°ƒé˜¶æ®µå³Qwen-VLè®ºæ–‡ä¸­çš„ç¬¬ä¸‰é˜¶æ®µï¼Œåœ¨è¿™ä¸ªé˜¶æ®µä¸­ï¼Œä¼šå°†ViTè¿›è¡Œå†»ç»“ï¼Œä»…è®­ç»ƒQwenLMåŠCrossAttnéƒ¨åˆ†å‚æ•°ï¼Œè®­ç»ƒå‚æ•°çº¦7.78Bã€‚

### Stage-3å¾®è°ƒ

MindFormersæä¾›äº†é»˜è®¤å¾®è°ƒé…ç½®`finetune_qwenvl_9.6b.yaml`ï¼Œé»˜è®¤é…ç½®ä¸­ä½¿ç”¨æ•°æ®é›†[LlaVa-150k detail_23k](#æ•°æ®é›†åˆ¶ä½œ)
ï¼Œå¼€å¯LLMéƒ¨åˆ†çš„Flash Attentionï¼Œè®¾ç½®å›¾æ–‡å¯¹è¯ä¸­æœ€å¤šåŒ…å«ä¸€å¼ å›¾åƒã€‚

#### å•æœºè®­ç»ƒ

1. ä¿®æ”¹`finetune_qwenvl_9.6b_bf16.yaml`ä¸­ç›¸å…³é…ç½®ï¼Œé…ç½®å…·ä½“æ•°æ®é›†ã€è¯è¡¨è·¯å¾„ç­‰ç›¸å…³ä¿¡æ¯ã€‚

   ```yaml
   load_checkpoint: '/path/model_dir' # æƒé‡è·¯å¾„ï¼Œä¹Ÿå¯é€šè¿‡å¯åŠ¨å‘½ä»¤è‡ªåŠ¨ä¼ å…¥
   auto_trans_ckpt: True              # æ‰“å¼€è‡ªåŠ¨æƒé‡è½¬æ¢ï¼Œä¹Ÿå¯é€šè¿‡å¯åŠ¨å‘½ä»¤è‡ªåŠ¨ä¼ å…¥
   use_parallel: True
   run_mode: 'finetune'

   train_dataset: &train_dataset
     data_loader:
      type: BaseMultiModalDataLoader
      annotation_file: "/path/to/converted/json"     # æ ¹æ®å®é™…ä½ç½®ï¼Œå¡«å†™å¯¹è¯jsonæ–‡ä»¶æ‰€åœ¨è·¯å¾„
      shuffle: True
     modal_to_text_transform:
        type: BaseXModalToTextTransform
        model_transform_template:
          type: QwenVLContentTransformTemplate      # QwenVLå…³äºæ•°æ®é›†æ•°æ®å¤„ç†æ¨¡æ¿
          auto_register: qwenvl_processor.QwenVLContentTransformTemplate
          output_columns: ["input_ids", "images", "image_context_pos", "labels"] # æ–‡æœ¬å¤„ç†åæ•°æ®æ•°æ®çš„åˆ—åï¼Œä¸éœ€è¦é…ç½®
          mode: "train"
          dataset_dir: "/location/of/coco/train2014" # è¯¥å¤„é…ç½®æ–‡ä»¶å¤¹ä½ç½®ä¸jsonæ•°æ®é›†ä¸­å›¾ç‰‡è·¯å¾„æ‹¼æ¥å¾—åˆ°å›¾ç‰‡çš„ç»å¯¹è·¯å¾„ï¼Œå¦‚æœæ•°æ®é›†ä¸­è·¯å¾„å·²æ˜¯ç»å¯¹è·¯å¾„ï¼Œè¯¥å¤„ä¸éœ€è¦é…ç½®ï¼›å½“ä½¿ç”¨ç¤ºä¾‹æ•°æ®é›†æ—¶ä¸ºtrain2014æ–‡ä»¶å¤¹æ‰€åœ¨è·¯å¾„ï¼Œé…ç½®é¡¹ä¸åŒ…å«train2014,
          modal_content_padding_size: 1             # æ ¹æ®æ•°æ®é›†ä¸­å¯¹è¯å®é™…åŒ…å«å›¾ç‰‡æ•°é‡è¿›è¡Œé…ç½®ï¼Œåœ¨ä½¿ç”¨ç¤ºä¾‹æ•°æ®é›†æ—¶ä¸º1
          system_message: "You are a helpful assistant."  # å¾®è°ƒæ—¶ï¼Œç³»ç»Ÿprompt
          user_role_name: user                            # æ ¹æ®æ•°æ®é›†è½¬æ¢å®é™…é…ç½®ï¼Œä¿®æ”¹ä¸ºç”¨æˆ·è§’è‰²åï¼Œé»˜è®¤é…ç½®ä¸ºuser
          assistant_role_name: assistant                  # æ ¹æ®æ•°æ®é›†è½¬æ¢å®é™…é…ç½®ï¼Œä¿®æ”¹ä¸ºåŠ©æ‰‹è§’è‰²åï¼Œé»˜è®¤é…ç½®ä¸ºassistant
          user_prompt: ""                  # userè§’è‰²prompt
          assistant_prompt: ""             # assistantè§’è‰²prompt
          image_size: 448                  # æ•°æ®é›†åŠ è½½å°†å›¾ç‰‡æ”¾ç¼©è‡³è¯¥å°ºå¯¸
        max_length: 2048                   # è®­ç»ƒæ—¶ä½¿ç”¨seq_length
     modal_content_input_columns: [ "images"]      # æ¨¡æ€å†…å®¹è½¬æ¢è¾“å…¥åˆ—åï¼Œè¯¥å¤„å›ºå®šä¸ºimages
     modal_content_output_columns: [ "images" ]    # æ¨¡æ€å†…å®¹è½¬æ¢è¾“å‡ºåˆ—åï¼Œè¯¥å¤„å›ºå®šä¸ºimages
     modal_content_transforms:                     # æ¨¡æ€å†…å®¹è½¬æ¢ï¼Œä¸éœ€è¦é…ç½®ï¼Œä»…ä¸ºç¤ºæ„
      - type: BatchToTensor
      - type: BatchNormalize
        mean: [ 0.48145466, 0.4578275, 0.40821073 ]
        std: [ 0.26862954, 0.26130258, 0.27577711 ]
        is_hwc: False
     net_input_columns: [ "input_ids", "images", "image_context_pos", "labels" ]  # æœ€ç»ˆä»æ•°æ®é›†æµæ°´çº¿ä¸­å–æ‰€é…ç½®åˆ—ååŠå…¶é¡ºåºé€å…¥åˆ°ç½‘ç»œè¾“å…¥
     tokenizer:
       type: QwenVLTokenizer
       auto_register: qwenvl_tokenizer.QwenVLTokenizer
       vocab_file: '/path/to/vocab_file'
    ```

2. å¯åŠ¨å¾®è°ƒä»»åŠ¡

è¿è¡Œå¦‚ä¸‹å‘½ä»¤å¯åŠ¨å•æœº8å¡å¾®è°ƒä»»åŠ¡ã€‚

```shell
bash scripts/msrun_launcher.sh "run_mindformer.py \
--config research/qwenvl/qwenvl_9.6b/finetune_qwenvl_9.6b_bf16.yaml \
--register_path research/qwenvl \
--run_mode finetune \
--load_checkpoint /path/to/ckpt \
--use_parallel True \
--auto_trans_ckpt True" 8

# ä»¥ä¸Šé™¤configå’Œregister_pathå¤–å…¶ä»–ä¼ å‚å¦‚æœåœ¨yamlæ–‡ä»¶ä¸­å·²ç»é…ç½®ï¼Œå¯ä»¥åœ¨å¯åŠ¨å‘½ä»¤ä¸­ä¸å†ä¼ å…¥
# å‚æ•°è¯´æ˜
# config: é…ç½®æ–‡ä»¶è·¯å¾„
# run_mode: è¿è¡Œæ¨¡å¼ï¼Œå¾®è°ƒæ—¶è®¾ç½®ä¸ºfinetuneï¼Œæ¨ç†æ—¶è®¾ç½®ä¸ºpredict
# load_checkpoint: å½“ä½¿ç”¨å®Œæ•´æƒé‡æ—¶ä¼ å…¥ckptè·¯å¾„ï¼›å½“ä½¿ç”¨åˆ†å¸ƒå¼æƒé‡æ—¶ä¼ å…¥æƒé‡æ–‡ä»¶å¤¹è·¯å¾„model_dirï¼Œæƒé‡æŒ‰ç…§'model_dir/rank_0/xxx.ckpt'æ ¼å¼å­˜æ”¾
# auto_trans_ckpt: è‡ªåŠ¨æƒé‡è½¬æ¢å¼€å…³ï¼Œå½“ä¼ å…¥å®Œæ•´æƒé‡æ—¶æ‰“å¼€
```

#### å¤šæœºè®­ç»ƒ

ä»¥Qwen-VL-9.6Bè¿›è¡Œ2æœº16å¡è®­ç»ƒä¸ºä¾‹ï¼Œåªéœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶å’Œæƒé‡å³å¯ã€‚

1. ä¿®æ”¹`finetune_qwenvl_9.6b_bf16.yaml`ä¸­å¹¶è¡Œç›¸å…³é…ç½®ï¼Œæ•°æ®é›†é…ç½®ç›¸å…³å¯å‚è€ƒä¸Šæ–‡[å•æœºè®­ç»ƒ](#å•æœºè®­ç»ƒ)ã€‚

    ```yaml
    parallel_config:
      data_parallel: 16
      model_parallel: 1
      pipeline_stage: 1
      micro_batch_num: 1
    ```

2. å¯åŠ¨å¾®è°ƒä»»åŠ¡

   å¤šæœºè®­ç»ƒéœ€è¦åˆ†åˆ«åœ¨ä¸åŒèŠ‚ç‚¹æ‰§è¡Œå‘½ä»¤ï¼Œä»¥ä¸‹ä¸º2æœº16å¡è®­ç»ƒè¿‡ç¨‹ï¼Œå‚æ•°è¯´æ˜ä»¥åŠä½¿ç”¨æ›´å¤šèŠ‚ç‚¹å‚è€ƒ[msrunæ–¹å¼å¯åŠ¨](../../README_CN.md#æ–¹å¼ä¸€ä½¿ç”¨å·²æœ‰è„šæœ¬å¯åŠ¨)
   å¤šæœºå¤šå¡éƒ¨åˆ†è¿›è¡Œé…ç½®ã€‚

   > æ³¨ï¼šå¦‚æœå„èŠ‚ç‚¹é—´ä½¿ç”¨å…±äº«å­˜å‚¨å­˜æ”¾å·¥ç¨‹æ–‡ä»¶ï¼Œåˆ™å¯ä»¥ä½¿ç”¨[æƒé‡è‡ªåŠ¨è½¬æ¢](https://www.mindspore.cn/mindformers/docs/zh-CN/r1.5.0/function/transform_weight.html#%E8%87%AA%E5%8A%A8%E8%BD%AC%E6%8D%A2)
   ï¼Œåœ¨Qwen-VLä¸­å¯é€šè¿‡åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®`auto_trans_ckpt=True`æˆ–åœ¨è¿è¡Œå‘½ä»¤æ—¶è®¾ç½®`--auto_trans_ckpt True`
   ï¼›å¦‚æœä¸èƒ½æ»¡è¶³å…±äº«å­˜å‚¨æ¡ä»¶ï¼Œéœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶`auto_trans_ckpt=False`æˆ–åœ¨è¿è¡Œå‘½ä»¤æ—¶è®¾ç½®`--auto_trans_ckpt False`ï¼Œ
   æ­¤æ—¶ï¼Œé¢„è®­ç»ƒæƒé‡å¯ä»¥ä½¿ç”¨[æƒé‡ç¦»çº¿è½¬æ¢](https://www.mindspore.cn/mindformers/docs/zh-CN/r1.5.0/function/transform_weight.html#%E7%A6%BB%E7%BA%BF%E8%BD%AC%E6%8D%A2)
   è¿›è¡Œè½¬æ¢å¾—åˆ°åˆ‡åˆ†åçš„åˆ†å¸ƒå¼æƒé‡ï¼Œä»¥é¿å…æ¯å¼ å¡åŠ è½½å®Œæ•´æƒé‡ï¼Œå¯¼è‡´hostä¾§å†…å­˜å ç”¨è¿‡é«˜ã€‚

- åœ¨èŠ‚ç‚¹0æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œå…¶ä¸­192.168.1.1éœ€è¦æ”¹ä¸ºèŠ‚ç‚¹0çš„å®é™…ipï¼Œå°†èŠ‚ç‚¹0ä½œä¸ºä¸»èŠ‚ç‚¹ï¼Œ2æœºå…±16å¡ä¸”æ¯ä¸ªèŠ‚ç‚¹8å¡ã€‚

  ```shell
  # ä»¥ä½¿ç”¨å…±äº«ç›˜ä¸ºä¾‹
  bash scripts/msrun_launcher.sh "run_mindformer.py \
  --register_path research/qwenvl
  --run_mode finetune \
  --config research/qwenvl/qwenvl_9.6b/finetune_qwenvl_9.6b_bf16.yaml \
  --load_checkpoint /path/to/ckpt \
  --use_parallel True \
  --auto_trans_ckpt True" \
   16 8 192.168.1.1 8118 0 output/msrun_log False 300
  ```

- åœ¨èŠ‚ç‚¹1æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œå…¶ä¸­192.168.1.1éœ€è¦æ”¹ä¸ºèŠ‚ç‚¹0çš„å®é™…ipã€‚

  ```shell
  bash scripts/msrun_launcher.sh "run_mindformer.py \
  --register_path research/qwenvl
  --run_mode finetune \
  --config research/qwenvl/qwenvl_9.6b/finetune_qwenvl_9.6b_bf16.yaml \
  --load_checkpoint /path/to/ckpt \
  --use_parallel True \
  --auto_trans_ckpt True" \
   16 8 192.168.1.1 8118 1 output/msrun_log False 300
  ```

## æ¨ç†

è¿›è¡Œæ¨ç†å‰ï¼Œæ¨¡å‹æƒé‡ä»¥åŠtokenizeræ–‡ä»¶å¯å‚è€ƒ[æ¨¡å‹æƒé‡ä¸‹è½½](#æ¨¡å‹æƒé‡ä¸‹è½½)è¿›è¡Œå‡†å¤‡ï¼Œå¹¶ä¿®æ”¹`predict_qwenvl_9.6b.yaml`ä¸­ç›¸å…³é…ç½®ï¼Œè¡¥å……è¯è¡¨è·¯å¾„ã€‚

ä¿®æ”¹`predict_qwenvl_9.6b.yaml`ä¸­ç›¸å…³é…ç½®ï¼Œè¡¥å……è¯è¡¨è·¯å¾„ã€‚

   ```yaml
   processor:
     tokenizer:
       vocab_file: "/path/to/qwen.tiktoken"
       type: QwenVLTokenizer
       auto_register: qwenvl_tokenizer.QwenVLTokenizer
   ```

### å•å¡æ¨ç†

å½“å‰QwenVLåªæ”¯æŒå•å¡æ¨ç†ï¼Œä»¥ä¸‹æä¾›æ¨ç†æ ·ä¾‹ã€‚

- é¦–å…ˆä¸‹è½½ç¤ºä¾‹å›¾ç‰‡[demo.jpeg](https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/MindFormers/qwenvl/demo.jpeg)ï¼Œå¹¶åœ¨å¦‚ä¸‹ç¤ºä¾‹è„šæœ¬ä¸­çš„`--predict_data`å¤„æŒ‡å®šè¯¥å›¾ç‰‡è·¯å¾„ã€‚
- è¿è¡Œå¦‚ä¸‹è„šæœ¬

```shell
python run_mindformer.py \
--config research/qwenvl/qwenvl_9.6b/predict_qwenvl_9.6b.yaml \
--register_path research/qwenvl \
--run_mode predict \
--predict_data 'path of demo.jpeg'  'Describe the image in English:' \
--modal_type image text \
--load_checkpoint /path/to/qwenvl_9.6b_base.ckpt \
--use_parallel False \
--auto_trans_ckpt False \
--predict_batch_size 1
 # æ¨ç†ç»“æœï¼š
 # Picture 1: <img>path of demo.jpeg</img>
 # Describe the image in English: A women and a dog on the bench at sunset.<|endoftext|>
```