# Llm_boost

> ## ğŸš¨ å¼ƒç”¨è¯´æ˜
>
> æœ¬æ–‡æ¡£å·²è¿‡æ—¶ï¼Œä¸å†è¿›è¡Œç»´æŠ¤ï¼Œå¹¶å°†åœ¨ *1.6.0* ç‰ˆæœ¬ä¸‹æ¶ï¼Œå…¶ä¸­å¯èƒ½åŒ…å«è¿‡æ—¶çš„ä¿¡æ¯æˆ–å·²è¢«æ›´æ–°çš„åŠŸèƒ½æ›¿ä»£ã€‚å»ºè®®å‚è€ƒæœ€æ–°çš„ **[å®˜æ–¹æ–‡æ¡£](https://www.mindspore.cn/mindformers/docs/zh-CN/r1.5.0/index.html)** ï¼Œä»¥è·å–å‡†ç¡®çš„ä¿¡æ¯ã€‚
>
> å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ **[ç¤¾åŒºIssue](https://gitee.com/mindspore/mindformers/issues/new)** æäº¤åé¦ˆã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£ä¸æ”¯æŒï¼

## åŠŸèƒ½æè¿°

llm_boostä¸ºå¤§æ¨¡å‹æ¨ç†åŠ é€Ÿæ¨¡å—, æ”¯æŒå¯¹æ¥ç¬¬ä¸‰æ–¹æ¨ç†æ¡†æ¶è¿›è¡Œæ¨ç†

## æ”¯æŒæ¨¡å‹

|   æ¨¡å‹    |     ç¡¬ä»¶      | æ¨ç†  |  åç«¯   |
| :-------: | :-----------: | :---: | :-----: |
| Llama2-7b | Atlas 800T A2 | å•å¡  | BuildIn |
| Qwen2-7b  | Atlas 800T A2 | å•å¡  | BuildIn |

## ç¯å¢ƒåŠæ•°æ®å‡†å¤‡

### å®‰è£…ç¯å¢ƒ

MindFormersè½¯ç¡¬ä»¶é…å¥—å…³ç³»ä»¥åŠå®‰è£…å‚è€ƒ[ç¯å¢ƒå®‰è£…æŒ‡å—](../../README_CN.md#æºç ç¼–è¯‘å®‰è£…)å’Œ[ç‰ˆæœ¬åŒ¹é…å…³ç³»](../../README_CN.md#ç‰ˆæœ¬åŒ¹é…å…³ç³»)ã€‚

### 1. å®‰è£…CANN

- è¯¦ç»†ä¿¡æ¯å¯å‚è§[æ˜‡è…¾ç¤¾åŒºCANNè½¯ä»¶](https://www.hiascend.com/software/cann)
- å®‰è£…é¡ºåºï¼šå…ˆå®‰è£…toolkit å†å®‰è£…kernel

#### 1.1 å®‰è£…toolkit

- ä¸‹è½½

| cpu     | åŒ…åï¼ˆå…¶ä¸­`${version}`ä¸ºå®é™…ç‰ˆæœ¬ï¼‰               |
| ------- | ------------------------------------------------ |
| aarch64 | Ascend-cann-toolkit_${version}_linux-aarch64.run |
| x86     | Ascend-cann-toolkit_${version}_linux-x86_64.run  |

- å®‰è£…

  ```bash
  # å®‰è£…toolkit
  chmod +x Ascend-cann-toolkit_${version}_linux-aarch64.run
  ./Ascend-cann-toolkit_${version}_linux-aarch64.run --install
  source /usr/local/Ascend/ascend-toolkit/set_env.sh
  ```

#### 1.2 å®‰è£…kernel

- ä¸‹è½½

| åŒ…å                                       |
| ------------------------------------------ |
| Ascend-cann-kernels-*_${version}_linux.run |

- æ ¹æ®èŠ¯ç‰‡å‹å·é€‰æ‹©å¯¹åº”çš„å®‰è£…åŒ…

- å®‰è£…

  ```bash
  chmod +x Ascend-cann-kernels-*_${version}_linux.run
  ./Ascend-cann-kernels-*_${version}_linux.run --install
  ```

#### 1.3 å®‰è£…åŠ é€Ÿåº“

- ä¸‹è½½åŠ é€Ÿåº“

  | åŒ…åï¼ˆå…¶ä¸­`${version}`ä¸ºå®é™…ç‰ˆæœ¬ï¼‰            |
  | --------------------------------------------- |
  | Ascend-cann-nnal_${version}_linux-aarch64.run |
  | Ascend-cann-nnal_${version}_linux-x86_64.run  |
  | ...                                           |

- å°†æ–‡ä»¶æ”¾ç½®åœ¨\${working_dir}è·¯å¾„ä¸‹

- å®‰è£…

    ```bash
    chmod +x Ascend-cann-nnal_*_linux-*.run
    ./Ascend-cann-nnal_*_linux-*.run --install --install-path=${working_dir}
    source ${working_dir}/nnal/atb/set_env.sh
    ```

### 2. å®‰è£…atb_models

  ```bash
  mkdir atb-models
  cd atb-models
  tar -zxvf ../Ascend-mindie-atb-models_*_linux-*_torch*-abi0.tar.gz
  sed -i '/PYTORCH/s/^/#/' set_env.sh
  source set_env.sh
  ```

## æ¨¡å‹æƒé‡ä¸‹è½½

ç”¨æˆ·å¯ä»¥ä»HuggingFaceå®˜æ–¹ä¸‹è½½é¢„è®­ç»ƒæƒé‡ï¼Œç»è¿‡[æ¨¡å‹æƒé‡è½¬æ¢](#æ¨¡å‹æƒé‡è½¬æ¢)åè¿›è¡Œä½¿ç”¨ï¼Œ`vocab.json`å’Œ`merges.txt`æ–‡ä»¶ä¹Ÿåœ¨é“¾æ¥ä¸­ä¸‹è½½ã€‚

è¯è¡¨ä¸‹è½½é“¾æ¥ï¼š[vocab.json](https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/vocab.json)å’Œ[merges.txt](https://huggingface.co/Qwen/Qwen2-72B-Instruct/blob/main/merges.txt)

| æ¨¡å‹åç§°          |                                     Baseæƒé‡ï¼ˆå»ºè®®è®­ç»ƒå’Œå¾®è°ƒä½¿ç”¨ï¼‰                                     |                  Instructæƒé‡ï¼ˆå»ºè®®æ¨ç†ä½¿ç”¨ï¼‰                   |
| :---------------- | :----------------------------------------------------------------------------------------------------: | :-------------------------------------------------------------: |
| llama2-7b         | [Link](https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/MindFormers/llama2/llama2_7b.ckpt) |     [Link](https://huggingface.co/meta-llama/Llama-2-7b-hf)     |
| qwen2-7b-Instruct |                         [Link](https://huggingface.co/Qwen/Qwen2-7B/tree/main)                         | [Link](https://huggingface.co/Qwen/Qwen2-7B-Instruct/tree/main) |

## æ¨¡å‹æƒé‡è½¬æ¢

ä¸‹è½½å®Œæˆåï¼Œè¿è¡Œ`mindformers/convert_weight.py`è½¬æ¢è„šæœ¬ï¼Œå°†huggingfaceçš„æƒé‡è½¬æ¢ä¸ºå®Œæ•´çš„ckptæƒé‡ã€‚

```shell
ä»¥Llama2-7bä¸ºä¾‹ã€‚
python convert_weight.py --model llama --input_path TORCH_CKPT_DIR --output_path {path}/MS_CKPT_NAME --dtype bf16

# å‚æ•°è¯´æ˜
model:       æ¨¡å‹åç§°
input_path:  ä¸‹è½½HuggingFaceæƒé‡çš„æ–‡ä»¶å¤¹è·¯å¾„
output_path: è½¬æ¢åçš„MindSporeæƒé‡æ–‡ä»¶ä¿å­˜è·¯å¾„
dtype:       è½¬æ¢æƒé‡çš„ç²¾åº¦
```

## æ¨¡å‹æƒé‡åˆ‡åˆ†

åœ¨åˆ†å¸ƒå¼æ¨ç†åœºæ™¯ä¸‹ï¼Œå¸¸éœ€è¦å°†æ¨¡å‹æƒé‡é‡æ–°åˆ‡åˆ†ä»¥é€‚åº”ç›®æ ‡åˆ‡åˆ†ç­–ç•¥ï¼Œå¸¸è§åœºæ™¯ä¸ºï¼š

**åœºæ™¯ä¸€**ï¼šä»å®Œæ•´æ¨¡å‹æƒé‡åˆ‡åˆ†è‡³åˆ†å¸ƒå¼æƒé‡

é€šå¸¸æ˜¯å·²æœ‰å®Œæ•´æƒé‡ï¼Œä½†ç›®æ ‡åˆ‡åˆ†ç­–ç•¥å­˜åœ¨mpåˆ‡åˆ†ï¼Œæ­¤æ—¶éœ€è¦å…ˆç”Ÿæˆç›®æ ‡strategyï¼Œç„¶åå‚è€ƒ[æƒé‡è½¬æ¢æ–‡æ¡£](../../docs/feature_cards/Transform_Ckpt.md)ï¼Œå°†å®Œæ•´æƒé‡è½¬æ¢ä¸ºç›®æ ‡åˆ‡åˆ†æƒé‡ã€‚

ä»¥`Qwen2-7b`2å¡æ¨ç†ä¸ºä¾‹, ç”Ÿæˆç›®æ ‡strategyã€‚

```shell
  cd research/llm_boost
  # æ¨ç†å‘½ä»¤ä¸­å‚æ•°ä¼šè¦†ç›–yamlæ–‡ä»¶ä¸­çš„ç›¸åŒå‚æ•°
  python run_llm_boost.py \
    --config_path ./predict_qwen2_7b_instruct_llm_boost.yaml \
    --only_save_strategy True \
    --load_checkpoint /path/model_dir \
    --vocab_file /path/vocab.json \
    --merges_file /path/merges.txt \
    --use_parallel True \
    --device_num 2
```

**åœºæ™¯äºŒ**ï¼šä»åˆ†å¸ƒå¼è®­ç»ƒè·å¾—çš„å·²åˆ‡åˆ†æƒé‡è½¬åŒ–ä¸ºå¦ä¸€ç­–ç•¥çš„åˆ†å¸ƒå¼æƒé‡

é€šå¸¸æ˜¯åœ¨åˆ†å¸ƒå¼è®­ç»ƒå®Œæˆåè·å–äº†æŒ‰è®­ç»ƒåˆ‡åˆ†ç­–ç•¥è¿›è¡Œåˆ‡åˆ†çš„æƒé‡ï¼Œåœ¨æ¨ç†é˜¶æ®µæ¨¡å‹éœ€è¦è½¬æ¢ä¸ºå¦ä¸€åˆ‡åˆ†ç­–ç•¥ï¼›
åŒæ ·éœ€è¦ç”Ÿæˆç›®æ ‡strategyï¼Œå‚è€ƒ[æƒé‡è½¬æ¢æ–‡æ¡£](../../docs/feature_cards/Transform_Ckpt.md)ï¼Œä¸åŸæœ‰åˆ‡åˆ†startegyä¸€åŒï¼Œè½¬æ¢æ¨¡å‹åˆ‡åˆ†ç­–ç•¥

## æ¨ç†

  ä¸»è¦å‚æ•°é…ç½®å‚è€ƒï¼š

  ```shell
  # model config
  model:
    model_config:
      type: LlmBoostConfig
      llm_backend: BuildIn  # llm backend
      boost_model_name: Llama # model name
    arch:
      type: LlmBoostForCausalLM
  ```

  è¿è¡Œä¸‹é¢çš„ä»£ç éœ€è¦å…ˆå°†`mindformers`ç›®å½•æ‰€åœ¨è·¯å¾„åŠ å…¥åˆ°`PYTHONPATH`ç¯å¢ƒå˜é‡ä¸­ã€‚

### å•å¡æ¨ç†

ä»¥`Qwen2-7b`å•å¡æ¨ç†ä¸ºä¾‹ã€‚

```shell
  cd research/llm_boost
  # æ¨ç†å‘½ä»¤ä¸­å‚æ•°ä¼šè¦†ç›–yamlæ–‡ä»¶ä¸­çš„ç›¸åŒå‚æ•°
  python run_llm_boost.py \
    --predict_data "å¸®æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥" \
    --config_path ./predict_qwen2_7b_instruct_llm_boost.yaml \
    --load_checkpoint /path/model_dir \
    --vocab_file /path/vocab.json \
    --merges_file /path/merges.txt \
    --use_parallel False \
    --batch_size 4

  # è¾“å‡ºæ¨ç†ç»“æœï¼šå¸®åŠ©æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥ï¼ŒåŒ…æ‹¬æ™¯ç‚¹ã€ç¾é£Ÿã€ä½å®¿ç­‰ä¿¡æ¯...
```

### å¤šå¡æ¨ç†

ä»¥`Qwen2-7b`å¤šå¡æ¨ç†ä¸ºä¾‹ã€‚

1. ä¸»è¦å‚æ•°é…ç½®å‚è€ƒï¼š

   ```yaml
   parallel_config:
     data_parallel: 1
     model_parallel: 4
     pipeline_stage: 1
     micro_batch_num: 1
     vocab_emb_dp: False
     gradient_aggregation_group: 4
   ```

2. å¯åŠ¨å¤šå¡æ¨ç†

```shell
  cd research/llm_boost
  # æ¨ç†å‘½ä»¤ä¸­å‚æ•°ä¼šè¦†ç›–yamlæ–‡ä»¶ä¸­çš„ç›¸åŒå‚æ•°
  bash ../../scripts/msrun_launcher.sh "run_llm_boost.py \
    --predict_data "å¸®æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥" \
    --config /path/predict_qwen2_7b_instruct_llm_boost.yaml \
    --load_checkpoint /path/model_dir \
    --vocab_file /path/vocab.json \
    --merges_file /path/merges.txt \
    --use_parallel True \
    --batch_size 4 \
    --device_num 4" 4

  # è¾“å‡ºæ¨ç†ç»“æœï¼šå¸®åŠ©æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥ï¼ŒåŒ…æ‹¬æ™¯ç‚¹ã€ç¾é£Ÿã€ä½å®¿ç­‰ä¿¡æ¯...
```

## åŸºäºMindIEçš„æœåŠ¡åŒ–æ¨ç†

MindIEï¼Œå…¨ç§°Mind Inference Engineï¼Œæ˜¯åä¸ºæ˜‡è…¾é’ˆå¯¹AIå…¨åœºæ™¯ä¸šåŠ¡çš„æ¨ç†åŠ é€Ÿå¥—ä»¶ã€‚

MindFormersæ‰¿è½½åœ¨æ¨¡å‹åº”ç”¨å±‚MindIE-LLMä¸­ï¼ŒMindIE-LLMæ˜¯å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ¡†æ¶ï¼Œæä¾›APIæ”¯æŒå¤§æ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚

MindIEå®‰è£…æµç¨‹è¯·å‚è€ƒ[MindIEæœåŠ¡åŒ–éƒ¨ç½²æ–‡æ¡£](https://www.mindspore.cn/mindformers/docs/zh-CN/r1.5.0/usage/mindie_deployment.html)ã€‚

ä»¥ä¸‹ä¾‹å­é»˜è®¤å·²å®ŒæˆMindIEå®‰è£…éƒ¨ç½²ä¸”ä»…é€‚ç”¨äº**MindIE RC3ç‰ˆæœ¬**ï¼Œä¸”å®‰è£…è·¯å¾„å‡ä¸ºé»˜è®¤è·¯å¾„`/usr/local/Ascend/`ã€‚

æ­¤ä¾‹å­ä½¿ç”¨Qwen2-7Bæ¨¡å‹æ¼”ç¤ºã€‚

### ä¿®æ”¹MindIEå¯åŠ¨é…ç½®

æ‰“å¼€mindie-serviceä¸­çš„config.jsonæ–‡ä»¶ï¼Œä¿®æ”¹serverç›¸å…³é…ç½®ã€‚

```bash
vim /usr/local/Ascend/mindie/1.0.RC3/mindie-service/conf/config.json
```

éœ€è¦å…³æ³¨ä»¥ä¸‹å­—æ®µçš„é…ç½®

1. `ModelDeployConfig.ModelConfig.backendType`

   è¯¥é…ç½®ä¸ºå¯¹åº”çš„åç«¯ç±»å‹ï¼Œå¿…å¡«"ms"ã€‚

   ```json
   "backendType": "ms"
   ```

2. `ModelDeployConfig.ModelConfig.modelWeightPath`

      è¯¥é…ç½®ä¸ºæ¨¡å‹é…ç½®æ–‡ä»¶ç›®å½•ï¼Œæ”¾ç½®æ¨¡å‹å’Œtokenizerç­‰ç›¸å…³æ–‡ä»¶ã€‚

      ä»¥Qwen2-7Bä¸ºä¾‹ï¼Œ`modelWeightPath`çš„ç»„ç»‡ç»“æ„å¦‚ä¸‹ï¼š

      ```reStructuredText
      mf_model
       â””â”€â”€ qwen2_7b
              â”œâ”€â”€ config.json                              # æ¨¡å‹jsoné…ç½®æ–‡ä»¶
              â”œâ”€â”€ vocab.json                               # æ¨¡å‹vocabæ–‡ä»¶ï¼Œhfä¸Šå¯¹åº”æ¨¡å‹ä¸‹è½½
              â”œâ”€â”€ merges.txt                               # æ¨¡å‹mergesæ–‡ä»¶ï¼Œhfä¸Šå¯¹åº”æ¨¡å‹ä¸‹è½½
              â”œâ”€â”€ predict_qwen2_7b_instruct_llm_boost.yaml # æ¨¡å‹yamlé…ç½®æ–‡ä»¶
              â”œâ”€â”€ qwen2_tokenizer.py                       # æ¨¡å‹tokenizeræ–‡ä»¶,ä»mindformersä»“ä¸­researchç›®å½•ä¸‹æ‰¾åˆ°å¯¹åº”æ¨¡å‹å¤åˆ¶
              â”œâ”€â”€ llm_boost.py                             # llm_boostæ¨¡å‹æ–‡ä»¶ï¼Œä»mindformersä»“ä¸­research/llm_boostç›®å½•ä¸‹å¤åˆ¶
              â”œâ”€â”€ llm_boost_config.py                      # llm_boosté…ç½®å®šä¹‰æ–‡ä»¶ï¼Œ ä»mindformersä»“ä¸­research/llm_boostç›®å½•ä¸‹å¤åˆ¶
              â””â”€â”€ qwen2_7b_ckpt_dir                        # æ¨¡å‹çš„æƒé‡æ–‡ä»¶è·¯å¾„
      ```

      predict_qwen2_7b_instruct_llm_boost.yamléœ€è¦å…³æ³¨ä»¥ä¸‹é…ç½®ï¼š

      ```yaml
      load_checkpoint: '/mf_model/qwen2_7b/qwen2_7b_ckpt_dir' # ä¸ºå­˜æ”¾æ¨¡å‹å•å¡æƒé‡æ–‡ä»¶è·¯å¾„
      use_parallel: False  # æ˜¯å¦å¼€å¯å¤šå¡å¹¶è¡Œæ¨ç†
      parallel_config:
        model_parallel: 1  # å¤šå¡æ¨ç†é…ç½®æ¨¡å‹åˆ‡åˆ†ï¼Œä¸€èˆ¬ä¸ä½¿ç”¨å¡æ•°ä¸€è‡´
      model:
        model_config:
          type: LlmBoostConfig
          llm_backend: BuildIn
          boost_model_name: Qwen
          auto_map:
            AutoModel: llm_boost.LlmBoostForCausalLM
            AutoTokenizer: [qwen2_tokenizer.Qwen2Tokenizer, null]
            AutoConfig: llm_boost_config.LlmBoostConfig
        arch:
          type: LlmBoostForCausalLM
      processor:
        tokenizer:
          vocab_file: "/path/vocab.json"  #vocabæ–‡ä»¶è·¯å¾„
          merges_file: "/path/merges.txt" #mergesæ–‡ä»¶è·¯å¾„
      ```

æœ€ç»ˆä¿®æ”¹å®Œåçš„config.jsonå¦‚ä¸‹ï¼š

```json
{
    "Version": "1.0.0",
    "LogConfig" :
    {
        "logLevel" : "Info",
        "logFileSize" : 20,
        "logFileNum" : 20,
        "logPath" : "logs/mindservice.log"
    },

    "ServerConfig" :
    {
        "ipAddress" : "127.0.0.1",
        "managementIpAddress": "127.0.0.2",
        "port" : 1025,
        "managementPort" : 1026,
        "metricsPort" : 1027,
        "maxLinkNum" : 1000,
        "httpsEnabled" : false,
        "fullTextEnabled" : false,
        "tlsCaPath" : "security/ca/",
        "tlsCaFile" : ["ca.pem"],
        "tlsCert" : "security/certs/server.pem",
        "tlsPk" : "security/keys/server.key.pem",
        "tlsPkPwd" : "security/pass/key_pwd.txt",
        "tlsCrl" : "security/certs/server_crl.pem",
        "managementTlsCaFile" : ["management_ca.pem"],
        "managementTlsCert" : "security/certs/management/server.pem",
        "managementTlsPk" : "security/keys/management/server.key.pem",
        "managementTlsPkPwd" : "security/pass/management/key_pwd.txt",
        "managementTlsCrl" : "security/certs/management/server_crl.pem",
        "kmcKsfMaster" : "tools/pmt/master/ksfa",
        "kmcKsfStandby" : "tools/pmt/standby/ksfb",
        "inferMode" : "standard",
        "pdInterNodeTLSEnabled": false,
        "pdCommunicationPort": 1121,
        "interNodeTlsCaFile" : "security/grpc/ca/ca.pem",
        "interNodeTlsCert" : "security/grpc/certs/server.pem",
        "interNodeTlsPk" : "security/grpc/keys/server.key.pem",
        "interNodeTlsPkPwd" : "security/grpc/pass/key_pwd.txt",
        "interCommTlsCrl" : "security/certs/server_crl.pem",
        "interNodeKmcKsfMaster": "tools/pmt/master/ksfa",
        "interNodeKmcKsfStandby": "tools/pmt/standby/ksfb"
    },

    "BackendConfig": {
        "backendName" : "mindieservice_llm_engine",
        "modelInstanceNumber" : 1,
        "npuDeviceIds" : [[0]],
        "tokenizerProcessNumber" : 8,
        "multiNodesInferEnabled": false,
        "multiNodesInferPort": 1120,
        "interNodeTLSEnabled": true,
        "interNodeTlsCaFile": "security/grpc/ca/ca.pem",
        "interNodeTlsCert": "security/grpc/certs/server.pem",
        "interNodeTlsPk": "security/grpc/keys/server.key.pem",
        "interNodeTlsPkPwd": "security/grpc/pass/mindie_server_key_pwd.txt",
        "interNodeTlsCrl" : "security/grpc/certs/server_crl.pem",
        "interNodeKmcKsfMaster": "tools/pmt/master/ksfa",
        "interNodeKmcKsfStandby": "tools/pmt/standby/ksfb",
        "ModelDeployConfig":
        {
            "maxSeqLen" : 2560,
            "maxInputTokenLen" : 2048,
            "truncation" : false,
            "ModelConfig" : [
                {
                    "modelInstanceType": "Standard",
                    "modelName" : "qwen2_7b",
                    "modelWeightPath" : "/mf_model/qwen2_7b",
                    "worldSize" : 1,
                    "cpuMemSize" : 16,
                    "npuMemSize" : 16,
                    "backendType": "ms"
                }
            ]
        },

        "ScheduleConfig":
        {
            "templateType": "Standard",
            "templateName" : "Standard_LLM",
            "cacheBlockSize" : 128,
            "maxPrefillBatchSize" : 50,
            "maxPrefillTokens" : 8192,
            "prefillTimeMsPerReq" : 150,
            "prefillPolicyType" : 0,
            "decodeTimeMsPerReq" : 50,
            "decodePolicyType" : 0,
            "maxBatchSize" : 200,
            "maxIterTimes" : 512,
            "maxPreemptCount" : 0,
            "supportSelectBatch" : false,
            "maxQueueDelayMicroseconds" : 5000
        }
    }
}
```

> æ³¨ï¼šä¸ºä¾¿äºæµ‹è¯•ï¼Œ`httpsEnabled`å‚æ•°è®¾ç½®ä¸º`false`ï¼Œå¿½ç•¥åç»­httpsé€šä¿¡ç›¸å…³å‚æ•°ã€‚

#### å¯åŠ¨æœåŠ¡

```bash
cd /usr/local/Ascend/mindie/1.0.RC3/mindie-service
nohup ./bin/mindieservice_daemon > output.log 2>&1 &
tail -f output.log
```

æ‰“å°å¦‚ä¸‹ä¿¡æ¯ï¼Œå¯åŠ¨æˆåŠŸã€‚

```json
Daemon start success!
```

#### è¯·æ±‚æµ‹è¯•

æœåŠ¡å¯åŠ¨æˆåŠŸåï¼Œå¯ä½¿ç”¨curlå‘½ä»¤å‘é€è¯·æ±‚éªŒè¯ï¼Œæ ·ä¾‹å¦‚ä¸‹ï¼š

```bash
curl -w "\ntime_total=%{time_total}\n" -H "Accept: application/json" -H "Content-type: application/json" -X POST -d '{"inputs": "å¸®æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥","stream": false}' http://127.0.0.1:1025/generate
```

è¿”å›æ¨ç†ç»“æœéªŒè¯æˆåŠŸï¼š

```json
{"generated_text":"ï¼ŒåŒ…æ‹¬æ™¯ç‚¹ã€ç¾é£Ÿå’Œä½å®¿æ¨èã€‚\nå½“ç„¶ï¼ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€è¦çš„ä¸Šæµ·æ—…æ¸¸æ”»ç•¥ï¼š\n\n"}
```
