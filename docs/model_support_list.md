# æ¨¡å‹æ”¯æŒåˆ—è¡¨

> ## ğŸš¨ å¼ƒç”¨è¯´æ˜
>
> æœ¬æ–‡æ¡£å·²è¿‡æ—¶ï¼Œä¸å†è¿›è¡Œç»´æŠ¤ï¼Œå¹¶å°†åœ¨ *1.6.0* ç‰ˆæœ¬ä¸‹æ¶ï¼Œå…¶ä¸­å¯èƒ½åŒ…å«è¿‡æ—¶çš„ä¿¡æ¯æˆ–å·²è¢«æ›´æ–°çš„åŠŸèƒ½æ›¿ä»£ã€‚å»ºè®®å‚è€ƒæœ€æ–°çš„ **[å®˜æ–¹æ–‡æ¡£](https://www.mindspore.cn/mindformers/docs/zh-CN/r1.5.0/index.html)** ï¼Œä»¥è·å–å‡†ç¡®çš„ä¿¡æ¯ã€‚
>
> å¦‚æœæ‚¨ä»éœ€ä½¿ç”¨æœ¬æ–‡æ¡£ä¸­çš„å†…å®¹ï¼Œè¯·ä»”ç»†æ ¸å¯¹å…¶é€‚ç”¨æ€§ï¼Œå¹¶ç»“åˆæœ€æ–°ç‰ˆæœ¬çš„ç›¸å…³èµ„æºè¿›è¡ŒéªŒè¯ã€‚
>
> å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ **[ç¤¾åŒºIssue](https://gitee.com/mindspore/mindformers/issues/new)** æäº¤åé¦ˆã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£ä¸æ”¯æŒï¼

## NLP

### [text_generation](task_cards/text_generation.md)

|                      æ¨¡å‹ <br> model                      |                                     æ¨¡å‹è§„æ ¼<br/>type                                      | æ•°æ®é›† <br> dataset |               è¯„ä¼°æŒ‡æ ‡ <br> metric               |                            è¯„ä¼°å¾—åˆ† <br> score                            |                                  é…ç½®<br>config                                  |
|:-------------------------------------------------------:|:--------------------------------------------------------------------------------------:|:----------------:|:--------------------------------------------:|:---------------------------------------------------------------------:|:------------------------------------------------------------------------------:|
|             [llama2](model_cards/llama2.md)             | llama2_7b <br/> llama2_13b <br/> llama2_7b_lora <br/> llama2_13b_lora <br/> llama2_70b |      alpaca      |                PPL / EM / F1                 | 6.58 / 39.6 / 60.5 <br/> 6.14 / 27.91 / 44.23 <br/> - <br/> - <br/> - |   [configs](https://gitee.com/mindspore/mindformers/tree/r1.5.0/configs/llama2)   |
|         [llama3](../research/llama3/llama3.md)          |                               llama3_8b <br/> llama3_70b                               |      alpaca      |                      -                       |                                   -                                   |  [configs](https://gitee.com/mindspore/mindformers/tree/r1.5.0/research/llama3)   |
|               [glm3](model_cards/glm3.md)               |                                        glm3_6b                                         |      ADGEN       |                      -                       |                                   -                                   |    [configs](https://gitee.com/mindspore/mindformers/tree/r1.5.0/configs/glm3)    |
|          [codellama](model_cards/codellama.md)          |                                     codellama_34b                                      |    CodeAlpaca    |                      -                       |                                   -                                   | [configs](https://gitee.com/mindspore/mindformers/tree/r1.5.0/configs/codellama)  |
|   [deepseek coder](../research/deepseek/deepseek.md)    |                                      deepseek_33b                                      |    CodeAlpaca    |                      -                       |                                   -                                   | [configs](https://gitee.com/mindspore/mindformers/tree/r1.5.0/research/deepseek)  |
|         [glm32k](../research/glm32k/README.md)          |                                      glm3_6b_32k                                       |    LongBench     |                      -                       |                                   -                                   |  [configs](https://gitee.com/mindspore/mindformers/tree/r1.5.0/research/glm32k)   |
|        [Qwen1.5](../research/qwen1_5/qwen1_5.md)        |                     qwen1_5_7b <br/> qwen1_5_14b <br/> qwen1_5_72b                     |      alpaca      |                      -                       |                                   -                                   |  [configs](https://gitee.com/mindspore/mindformers/tree/r1.5.0/research/qwen1_5)  |
|     [internlm2](../research/internlm2/internlm2.md)     |                            internlm2_7b <br/> internlm2_20b                            |      alpaca      |                      -                       |                                   -                                   | [configs](https://gitee.com/mindspore/mindformers/tree/r1.5.0/research/internlm2) |
|        [mixtral](../research/mixtral/mixtral.md)        |                                      mixtral_8x7b                                      |    wikitext-2    |                      -                       |                                   -                                   |  [configs](https://gitee.com/mindspore/mindformers/tree/r1.5.0/research/mixtral)  |

## Multi-Modal

### image_to_text_generation

|             æ¨¡å‹ <br> model              | æ¨¡å‹è§„æ ¼<br/>type    |   æ•°æ®é›† <br> dataset    | è¯„ä¼°æŒ‡æ ‡ <br> metric | è¯„ä¼°å¾—åˆ† <br> score |                                                      é…ç½®<br>config                                                      |
|:--------------------------------------:|------------------|:---------------------:|:----------------:|:---------------:|:----------------------------------------------------------------------------------------------------------------------:|
| [QwenVL](../research/qwenvl/README.md) | qwenvl_9.6b_bf16 | LLaVa-150k detail_23k |        -         |        -        | [configs](https://gitee.com/mindspore/mindformers/tree/r1.5.0/research/qwenvl/qwenvl_9.6b/finetune_qwenvl_9.6b_bf16.yaml) |

## LLMå¤§æ¨¡å‹èƒ½åŠ›æ”¯æŒä¸€è§ˆ

|     æ¨¡å‹  \  ç‰¹æ€§     | ä½å‚å¾®è°ƒ |      è¾¹è®­è¾¹è¯„      | Flash Attention | å¹¶è¡Œæ¨ç†  |  æµå¼æ¨ç†   |  Chat   |  å¤šè½®å¯¹è¯   |
|:-----------------:|:----:|:--------------:|:---------------:|:-----:|:-------:|:-------:|:-------:|
| Llama2-7B/13B/70B | Lora |      PPL       |     &check;     | dp/mp | &check; | &check; | &check; |
|   Llama3-8B/70B   |  -   |       -        |     &check;     | dp/mp | &check; | &check; | &check; |
|   CodeLlama-34B   | Lora |   HumanEval    |     &check;     | dp/mp | &check; |    -    |    -    |
|      GLM2-6B      | Lora | PPL/Bleu/Rouge |     &check;     | dp/mp | &check; | &check; | &check; |
|      GLM3-6B      |  -   |       -        |     &check;     | dp/mp | &check; | &check; | &check; |
|    GLM3-6B-32k    |  -   |       -        |     &check;     | dp/mp | &check; | &check; | &check; |
|   GPT2-128m/13B   | Lora |      PPL       |     &check;     | dp/mp | &check; |    -    |    -    |
| BaiChuan2-7B/13B  | Lora |      PPL       |     &check;     | dp/mp | &check; | &check; | &check; |
|    Qwen-7B/14B    | Lora |       -        |     &check;     | dp/mp | &check; | &check; | &check; |
|    QwenVL-9.6B    |  -   |       -        |     &check;     | dp/mp | &check; |    -    |    -    |
|  Qwen-7B/14B/72B  |  -   |       -        |     &check;     | dp/mp | &check; | &check; | &check; |
|  InternLM-7B/20B  | Lora |      PPL       |     &check;     | dp/mp | &check; | &check; | &check; |
| InternLM2-7B/20B  |  -   |       -        |     &check;     | dp/mp | &check; | &check; | &check; |
|     Yi-6B/34B     | Lora |       -        |     &check;     | dp/mp | &check; | &check; | &check; |
|   Mixtral-8x7B    | Lora |       -        |     &check;     | dp/mp | &check; |    -    |    -    |
|   DeepSeek-33B    | Lora |       -        |     &check;     | dp/mp | &check; |    -    |    -    |
