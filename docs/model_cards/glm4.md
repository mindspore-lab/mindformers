# GLM-4

## æ¨¡å‹æè¿°

GLM-4-9B æ˜¯æ™ºè°± AI æ¨å‡ºçš„æœ€æ–°ä¸€ä»£é¢„è®­ç»ƒæ¨¡å‹ GLM-4 ç³»åˆ—ä¸­çš„å¼€æºç‰ˆæœ¬ã€‚ åœ¨è¯­ä¹‰ã€æ•°å­¦ã€æ¨ç†ã€ä»£ç å’ŒçŸ¥è¯†ç­‰å¤šæ–¹é¢çš„æ•°æ®é›†æµ‹è¯„ä¸­ï¼ŒGLM-4-9B
åŠå…¶äººç±»åå¥½å¯¹é½çš„ç‰ˆæœ¬ GLM-4-9B-Chat å‡è¡¨ç°å‡ºè¾ƒé«˜çš„æ€§èƒ½ã€‚ é™¤äº†èƒ½è¿›è¡Œå¤šè½®å¯¹è¯ï¼ŒGLM-4-9B-Chat è¿˜å…·å¤‡ç½‘é¡µæµè§ˆã€ä»£ç æ‰§è¡Œã€è‡ªå®šä¹‰å·¥å…·è°ƒç”¨ï¼ˆFunction
Callï¼‰å’Œé•¿æ–‡æœ¬æ¨ç†ï¼ˆæ”¯æŒæœ€å¤§ 128K ä¸Šä¸‹æ–‡ï¼‰ç­‰é«˜çº§åŠŸèƒ½ã€‚ æœ¬ä»£æ¨¡å‹å¢åŠ äº†å¤šè¯­è¨€æ”¯æŒï¼Œæ”¯æŒåŒ…æ‹¬æ—¥è¯­ï¼ŒéŸ©è¯­ï¼Œå¾·è¯­åœ¨å†…çš„ 26 ç§è¯­è¨€ã€‚æˆ‘ä»¬è¿˜æ¨å‡ºäº†æ”¯æŒ
1M ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆçº¦ 200 ä¸‡ä¸­æ–‡å­—ç¬¦ï¼‰çš„æ¨¡å‹ã€‚

```text
@article{glm2024chatglm,
      title={ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools},
      author={Team GLM and Aohan Zeng and Bin Xu and Bowen Wang and Chenhui Zhang and Da Yin and Diego Rojas and Guanyu Feng and Hanlin Zhao and Hanyu Lai and Hao Yu and Hongning Wang and Jiadai Sun and Jiajie Zhang and Jiale Cheng and Jiayi Gui and Jie Tang and Jing Zhang and Juanzi Li and Lei Zhao and Lindong Wu and Lucen Zhong and Mingdao Liu and Minlie Huang and Peng Zhang and Qinkai Zheng and Rui Lu and Shuaiqi Duan and Shudan Zhang and Shulin Cao and Shuxun Yang and Weng Lam Tam and Wenyi Zhao and Xiao Liu and Xiao Xia and Xiaohan Zhang and Xiaotao Gu and Xin Lv and Xinghan Liu and Xinyi Liu and Xinyue Yang and Xixuan Song and Xunkai Zhang and Yifan An and Yifan Xu and Yilin Niu and Yuantao Yang and Yueyan Li and Yushi Bai and Yuxiao Dong and Zehan Qi and Zhaoyu Wang and Zhen Yang and Zhengxiao Du and Zhenyu Hou and Zihan Wang},
      year={2024},
      eprint={2406.12793},
      archivePrefix={arXiv},
      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}
```

## æ¨¡å‹æ€§èƒ½

ä»¥ä¸‹æ¨¡å‹æ€§èƒ½å‡ç”±Atlas 800T A2ç¡¬ä»¶ç¯å¢ƒä¸‹æµ‹è¯•å¾—å‡ºã€‚

| Config                                                   |      Task       | Datasets | SeqLength |  Phase  | Performance  |
|:---------------------------------------------------------|:---------------:|:--------:|:---------:|:-------:|:------------:|
| [GLM-4-9B](../../configs/glm4/predict_glm4_9b_chat.yaml) | text_generation |    -     |   8192    | Predict | 256 tokens/s |

ä»¥ä¸‹æ¨¡å‹æ€§èƒ½å‡ç”±Atlas 900 A2 PoDcç¡¬ä»¶ç¯å¢ƒä¸‹æµ‹è¯•å¾—å‡ºã€‚

| Config                                               |      Task       | Datasets | SeqLength |  Phase   |   Performance   |
|:-----------------------------------------------------|:---------------:|:--------:|:---------:|:--------:|:---------------:|
| [GLM-4-9B](../../configs/glm4/finetune_glm4_9b.yaml) | text_generation |  alpaca  |   8192    | Finetune | 2339 tokens/s/p |

## æ¨¡å‹æ–‡ä»¶

`GLM-4-9B-Chat`ã€`GLM-4-9B`  åŸºäº `mindformers` å®ç°ï¼Œä¸»è¦æ¶‰åŠçš„æ–‡ä»¶æœ‰ï¼š

1. æ¨¡å‹å…·ä½“å®ç°ï¼š

    ```text
    mindformers/models/glm2            # glm4å¤ç”¨glm2çš„ä»£ç å®ç°
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ convert_weight.py          # huggingfaceæƒé‡è½¬ckptå®ç°
        â”œâ”€â”€ glm2.py                    # æ¨¡å‹å®ç°
        â”œâ”€â”€ glm2_config.py             # æ¨¡å‹é…ç½®é¡¹
        â”œâ”€â”€ glm2_modules.py            # æ¨¡ç»„å®ç°
        â”œâ”€â”€ glm4_tokenizer.py          # tokenizer
        â””â”€â”€ glm2_transformer.py        # transformerå±‚å®ç°
    ```

2. æ¨¡å‹é…ç½®ï¼š

    ```text
    configs/glm4
        â”œâ”€â”€ predict_glm4_9b_chat.yaml        # Atlas 800T A2æ¨ç†é…ç½®
        â””â”€â”€ finetune_glm4_9b.yaml            # Atlas 800T A2å¾®è°ƒé…ç½®
    ```

## ç¯å¢ƒåŠæ•°æ®å‡†å¤‡

### å®‰è£…ç¯å¢ƒ

MindFormersè½¯ç¡¬ä»¶é…å¥—å…³ç³»ä»¥åŠå®‰è£…å‚è€ƒ[ç¯å¢ƒå®‰è£…æŒ‡å—](../../README.md#æºç ç¼–è¯‘å®‰è£…)
å’Œ[ç‰ˆæœ¬åŒ¹é…å…³ç³»](../../README.md#ç‰ˆæœ¬åŒ¹é…å…³ç³»)ã€‚

### æ•°æ®åŠæƒé‡å‡†å¤‡

#### æ•°æ®é›†ä¸‹è½½

MindFormersæä¾›`alpaca`æ•°æ®é›†ç¤ºä¾‹å¤„ç†è„šæœ¬åˆ¶ä½œ[å¾®è°ƒ](#å¾®è°ƒ)ç¤ºä¾‹æ•°æ®é›†ã€‚

| æ•°æ®é›†åç§°        |  é€‚ç”¨æ¨¡å‹   |   é€‚ç”¨é˜¶æ®µ   |                                            ä¸‹è½½é“¾æ¥                                            |
|:-------------|:-------:|:--------:|:------------------------------------------------------------------------------------------:|
| alpaca       | glm4-9b | Finetune |      [Link](https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json)       |

æ•°æ®é¢„å¤„ç†ä¸­æ‰€ç”¨çš„`tokenizer.model`å¯ä»¥å‚è€ƒ[æ¨¡å‹æƒé‡ä¸‹è½½](#æ¨¡å‹æƒé‡ä¸‹è½½)è¿›è¡Œä¸‹è½½ã€‚

- **alpaca æ•°æ®é¢„å¤„ç†**

  æ‰§è¡Œ`mindformers/tools/dataset_preprocess/glm4/alpaca_converter.py`ï¼Œå°†åŸå§‹æ•°æ®é›†è½¬æ¢ä¸ºjsonlæ ¼å¼ã€‚

  ```shell
  python mindformers/tools/dataset_preprocess/glm4/alpaca_converter.py \
   --data_path /path/alpaca_data.json \
   --output_path /path/alpaca_glm4_data.jsonl

  # å‚æ•°è¯´æ˜
  data_path:   è¾“å…¥ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„
  output_path: è¾“å‡ºæ–‡ä»¶çš„ä¿å­˜è·¯å¾„
  ```

  æ‰§è¡Œ`mindformers/tools/dataset_preprocess/glm4/glm4_preprocess.py`æ–‡ä»¶ï¼Œè¿›è¡Œæ•°æ®é¢„å¤„ç†å’ŒMindrecordæ•°æ®ç”Ÿæˆã€‚

  ```shell
  python mindformers/tools/dataset_preprocess/glm4/glm4_preprocess.py \
   --input_glob /path/alpaca_glm4_data.jsonl \
   --vocab_file /path/tokenizer.model \
   --seq_length 8192 \
   --output_file /path/alpaca-messages.mindrecord

  # å‚æ•°è¯´æ˜
  input_glob:   è½¬æ¢åçš„alpacaçš„æ–‡ä»¶è·¯å¾„
  vocab_file:   tokenizer.modelæ–‡ä»¶è·¯å¾„
  seq_length:   è¾“å‡ºæ•°æ®çš„åºåˆ—é•¿åº¦
  output_file:  è¾“å‡ºæ–‡ä»¶çš„ä¿å­˜è·¯å¾„
  ```

#### æ¨¡å‹æƒé‡ä¸‹è½½

MindFormersæä¾›å·²ç»è½¬æ¢å®Œæˆçš„é¢„è®­ç»ƒæƒé‡ã€è¯è¡¨æ–‡ä»¶ç”¨äºå¾®è°ƒå’Œæ¨ç†ï¼Œç”¨æˆ·ä¹Ÿå¯ä»¥ä¸‹è½½HuggingFaceå®˜æ–¹æƒé‡ç»è¿‡[æ¨¡å‹æƒé‡è½¬æ¢](#æ¨¡å‹æƒé‡è½¬æ¢)
åè¿›è¡Œä½¿ç”¨ã€‚

| æ¨¡å‹åç§°          | MindSporeæƒé‡ |                   HuggingFaceæƒé‡                    |
|:--------------|:-----------:|:--------------------------------------------------:|
| GLM-4-9B-Chat |      /      | [Link](https://huggingface.co/THUDM/glm-4-9b-chat) |
| GLM-4-9B      |      /      |   [Link](https://huggingface.co/THUDM/glm-4-9b)    |

æ³¨ï¼šè¯è¡¨æ–‡ä»¶ä¸ºå¯¹åº”æƒé‡æ–‡ä»¶ç›®å½•ä¸‹tokenizer.modelæ–‡ä»¶

#### æ¨¡å‹æƒé‡è½¬æ¢

æ‰§è¡Œ`convert_weight.py`è½¬æ¢è„šæœ¬ï¼Œå°†HuggingFaceçš„æƒé‡è½¬æ¢ä¸ºå®Œæ•´çš„ckptæƒé‡ã€‚

```shell
python convert_weight.py --torch_ckpt_path TORCH_CKPT_DIR --mindspore_ckpt_path {path}/MS_CKPT_NAME

# å‚æ•°è¯´æ˜
torch_ckpt_path:  ä¸‹è½½HuggingFaceæƒé‡çš„æ–‡ä»¶å¤¹è·¯å¾„
mindspore_ckpt_path: è½¬æ¢åçš„MindSporeæƒé‡æ–‡ä»¶ä¿å­˜è·¯å¾„
```

## å…¨å‚å¾®è°ƒ

MindFormersæä¾›`GLM4-9b`å•æœºå¤šå¡å¾®è°ƒç¤ºä¾‹ï¼Œè¿‡ç¨‹ä¸­ä½¿ç”¨`alpaca`æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œæ•°æ®é›†å¯ä»¥å‚è€ƒ[æ•°æ®é›†ä¸‹è½½](#æ•°æ®é›†ä¸‹è½½)è·å¾—ã€‚

è®¾ç½®å¦‚ä¸‹ç¯å¢ƒå˜é‡ï¼š

```bash
export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE
```

### å•æœºè®­ç»ƒ

ä»¥`GLM4-9b`å•æœº8å¡å¾®è°ƒä¸ºä¾‹ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶`configs/glm4/finetune_glm4_9b.yaml`ã€‚

æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤å¯åŠ¨å¾®è°ƒä»»åŠ¡ã€‚

```shell
bash scripts/msrun_launcher.sh "run_mindformer.py \
 --config configs/glm4/finetune_glm4_9b.yaml \
 --load_checkpoint /path/GLM4_9b.ckpt \
 --auto_trans_ckpt True \
 --train_dataset /path/alpaca.mindrecord \
 --run_mode finetune" 8
```

## æ¨ç†

MindFormersæä¾›`GLM-4-9B-Chat`çš„å¿«é€Ÿæ¨ç†è„šæœ¬ï¼Œè„šæœ¬ä¸»è¦é€šè¿‡generateé«˜é˜¶æ¥å£å®ç°ï¼Œæ”¯æŒå•å¡å¤šbatchæ¨ç†ã€‚
æ³¨æ„ï¼šéœ€æ·»åŠ ç¯å¢ƒå˜é‡ä½¿èƒ½atbçš„PAç®—å­ï¼šexport MS_INTERNAL_DISABLE_CUSTOM_KERNEL_LIST=PagedAttention;
                               export MS_LLM_SEQ_LENGTH_INDEX=1;
                               export MS_LLM_FORCE_RESIZE_KERNELS=PagedAttention

```shell
bash scripts/examples/glm4/run_glm4_predict.sh CONFIG_PATH CKPT_PATH TOKENIZER

# å‚æ•°è¯´æ˜
CONFIG_PATH: æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
CKPT_PATH:   æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
TOKENIZER:   æ¨¡å‹tokenizeræ–‡ä»¶è·¯å¾„
```

è¿è¡Œå¦‚ä¸‹å‘½ä»¤è¿›è¡Œæ¨ç†ï¼š

```shell
bash scripts/examples/glm4/run_glm4_predict.sh \
 path/to/glm4/predict_glm4_9b_chat.yaml \
 path/to/glm4.ckpt

# æ¨ç†ç»“æœ
# [gMASK] <sop> <|user|>
# æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠ <|assistant|>
# æ™šä¸Šç¡ä¸ç€è§‰å¯èƒ½ä¼šå½±å“ç¬¬äºŒå¤©çš„ç²¾ç¥çŠ¶æ€å’Œå·¥ä½œæ•ˆç‡ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å»ºè®®ï¼Œå¯ä»¥å¸®åŠ©æ”¹å–„ç¡çœ è´¨é‡ï¼š
#
# 1. **è§„å¾‹ä½œæ¯**ï¼šå°½é‡æ¯å¤©åŒä¸€æ—¶é—´ä¸ŠåºŠç¡è§‰å’Œèµ·åºŠï¼ŒåŒ…æ‹¬å‘¨æœ«ã€‚
#
# 2. **æ”¾æ¾èº«å¿ƒ**ï¼š
#    - **æ·±å‘¼å¸**ï¼šå°è¯•æ·±å‘¼å¸ç»ƒä¹ ï¼Œå¸®åŠ©èº«ä½“æ”¾æ¾ã€‚
#    - **å†¥æƒ³**ï¼šé€šè¿‡å†¥æƒ³æ”¾æ¾å¿ƒæƒ…ï¼Œå‡å°‘ç„¦è™‘ã€‚
#    - **çƒ­æ°´æ¾¡**ï¼šç¡å‰æ´—ä¸ªçƒ­æ°´æ¾¡æœ‰åŠ©äºèº«ä½“æ”¾æ¾ã€‚
#
# 3. **é¿å…åˆºæ¿€æ€§é¥®æ–™å’Œé£Ÿç‰©**ï¼šç¡å‰é¿å…å’–å•¡ã€èŒ¶ã€å·§å…‹åŠ›ç­‰å«æœ‰å’–å•¡å› çš„é£Ÿå“å’Œé¥®æ–™ã€‚
#
# 4. **å‡å°‘å±å¹•æ—¶é—´**ï¼šç¡å‰å‡å°‘ä½¿ç”¨æ‰‹æœºã€ç”µè„‘ç­‰ç”µå­è®¾å¤‡ï¼Œå› ä¸ºå±å¹•å‘å‡ºçš„è“å…‰å¯èƒ½ä¼šå¹²æ‰°ç¡çœ ã€‚
#
# 5. **èˆ’é€‚çš„ç¯å¢ƒ**ï¼šç¡®ä¿å§å®¤å®‰é™ã€é»‘æš—å’Œé€‚å®œçš„æ¸©åº¦ã€‚
#
# 6. **é€‚é‡è¿åŠ¨**ï¼šç™½å¤©è¿›è¡Œé€‚é‡çš„è¿åŠ¨æœ‰åŠ©äºæ™šä¸Šæ›´å¥½åœ°å…¥ç¡ï¼Œä½†é¿å…åœ¨ç¡å‰è¿›è¡Œå‰§çƒˆè¿åŠ¨ã€‚
#
# 7. **é¿å…ç™½å¤©æ‰“ç›¹**ï¼šå¦‚æœç™½å¤©éœ€è¦ä¼‘æ¯ï¼Œå°½é‡æ§åˆ¶åœ¨30åˆ†é’Ÿä»¥å†…ã€‚
#
# 8. **å»ºç«‹ç¡å‰ä»ªå¼**ï¼šå¦‚é˜…è¯»ã€å¬è½»éŸ³ä¹ç­‰ï¼Œå¸®åŠ©å¤§è„‘é€æ¸è¿›å…¥ç¡çœ çŠ¶æ€ã€‚
#
# 9. **å’¨è¯¢ä¸“ä¸šäººå£«**ï¼šå¦‚æœä¸Šè¿°æ–¹æ³•éƒ½æ— æ•ˆï¼Œå»ºè®®å’¨è¯¢åŒ»ç”Ÿæˆ–ç¡çœ ä¸“å®¶ã€‚
#
# 10. **å¿ƒç†è°ƒé€‚**ï¼šæœ‰æ—¶å€™ï¼Œå¤±çœ å¯èƒ½ä¸å¿ƒç†å› ç´ æœ‰å…³ï¼Œå¦‚ç„¦è™‘ã€æŠ‘éƒç­‰ï¼Œè¿™æ—¶éœ€è¦å¯»æ±‚å¿ƒç†å’¨è¯¢ã€‚
#
# è¯·æ ¹æ®è‡ªå·±çš„å®é™…æƒ…å†µå°è¯•è¿™äº›æ–¹æ³•ï¼Œå¹¶æ³¨æ„è§‚å¯Ÿæ•ˆæœã€‚å¦‚æœå¤±çœ é—®é¢˜æŒç»­å­˜åœ¨ï¼Œå»ºè®®åŠæ—¶å°±åŒ»ã€‚ <|user|>

# [gMASK] <sop> <|user|>
# ä½¿ç”¨pythonç¼–å†™å¿«é€Ÿæ’åºä»£ç  <|assistant|>
# ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨Pythonç¼–å†™çš„å¿«é€Ÿæ’åºç®—æ³•çš„å®ç°ã€‚å¿«é€Ÿæ’åºæ˜¯ä¸€ç§åˆ†è€Œæ²»ä¹‹çš„ç®—æ³•ï¼Œå®ƒé€šè¿‡ä¸€ä¸ªåŸºå‡†å€¼å°†æ•°ç»„åˆ†ä¸ºä¸¤ä¸ªå­æ•°ç»„ï¼Œä¸€ä¸ªåŒ…å«å°äºåŸºå‡†å€¼çš„å…ƒç´ ï¼Œå¦ä¸€ä¸ªåŒ…å«å¤§äºåŸºå‡†å€¼çš„å…ƒç´ ï¼Œç„¶åé€’å½’åœ°å¯¹è¿™ä¸¤ä¸ªå­æ•°ç»„è¿›è¡Œæ’åºã€‚
#
# ```python
# def quick_sort(arr):
#     if len(arr) <= 1:
#         return arr
#     else:
#         pivot = arr[0]
#         less = [x for x in arr[1:] if x <= pivot]
#         greater = [x for x in arr[1:] if x > pivot]
#         return quick_sort(less) + [pivot] + quick_sort(greater)
#
# # ç¤ºä¾‹
# array = [3, 6, 8, 10, 1, 2, 1]
# sorted_array = quick_sort(array)
# print(sorted_array)
# ```
#
# è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ª`quick_sort`å‡½æ•°ï¼Œå®ƒæ¥å—ä¸€ä¸ªåˆ—è¡¨`arr`ä½œä¸ºå‚æ•°ã€‚å¦‚æœåˆ—è¡¨çš„é•¿åº¦å°äºæˆ–ç­‰äº1ï¼Œåˆ™å®ƒå·²ç»æ˜¯æœ‰åºçš„ï¼Œæ‰€ä»¥ç›´æ¥è¿”å›ã€‚å¦åˆ™ï¼Œé€‰æ‹©åˆ—è¡¨çš„ç¬¬ä¸€ä¸ªå…ƒç´ ä½œä¸ºåŸºå‡†å€¼`pivot`ï¼Œç„¶ååˆ›å»ºä¸¤ä¸ªæ–°çš„åˆ—è¡¨`less`å’Œ`greater`ï¼Œåˆ†åˆ«åŒ…å«å°äºå’Œå¤§äºåŸºå‡†å€¼çš„å…ƒç´ ã€‚æœ€åï¼Œé€’å½’åœ°å¯¹`less`å’Œ`greater`è¿›è¡Œå¿«é€Ÿæ’åºï¼Œå¹¶å°†ç»“æœä¸åŸºå‡†å€¼è¿æ¥èµ·æ¥è¿”å›ã€‚
#
# ç¤ºä¾‹ä¸­çš„`array`æ˜¯ä¸€ä¸ªæœªæ’åºçš„åˆ—è¡¨ï¼Œè°ƒç”¨`quick_sort(array)`åï¼Œä¼šå¾—åˆ°ä¸€ä¸ªæ’åºåçš„åˆ—è¡¨`sorted_array`ã€‚ <|user|>
#
# [gMASK] <sop> <|user|>
# ä½ å¥½å‘€ï¼ <|assistant|>
# ä½ å¥½ğŸ‘‹ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ <|user|>
```
