# æ–­ç‚¹ç»­è®­

> ## ğŸš¨ å¼ƒç”¨è¯´æ˜
>
> æœ¬æ–‡æ¡£å·²è¿‡æ—¶ï¼Œä¸å†è¿›è¡Œç»´æŠ¤ï¼Œå¹¶å°†åœ¨ *1.5.0* ç‰ˆæœ¬ä¸‹æ¶ï¼Œå…¶ä¸­å¯èƒ½åŒ…å«è¿‡æ—¶çš„ä¿¡æ¯æˆ–å·²è¢«æ›´æ–°çš„åŠŸèƒ½æ›¿ä»£ã€‚å»ºè®®å‚è€ƒæœ€æ–°çš„ **[å®˜æ–¹æ–‡æ¡£](https://www.mindspore.cn/mindformers/docs/zh-CN/dev/index.html)** ï¼Œä»¥è·å–å‡†ç¡®çš„ä¿¡æ¯ã€‚
>
> å¦‚æœæ‚¨ä»éœ€ä½¿ç”¨æœ¬æ–‡æ¡£ä¸­çš„å†…å®¹ï¼Œè¯·ä»”ç»†æ ¸å¯¹å…¶é€‚ç”¨æ€§ï¼Œå¹¶ç»“åˆæœ€æ–°ç‰ˆæœ¬çš„ç›¸å…³èµ„æºè¿›è¡ŒéªŒè¯ã€‚
>
> å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ **[ç¤¾åŒºIssue](https://gitee.com/mindspore/mindformers/issues/new)** æäº¤åé¦ˆã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£ä¸æ”¯æŒï¼

## ä»‹ç»

Mindformersæ”¯æŒ**stepçº§æ–­ç‚¹ç»­è®­**ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¦‚æœé‡åˆ°æ„å¤–æƒ…å†µå¯¼è‡´è®­ç»ƒä¸­æ–­ï¼Œå¯ä»¥ä½¿ç”¨æ–­ç‚¹ç»­è®­çš„æ–¹å¼æ¢å¤ä¹‹å‰çš„çŠ¶æ€ç»§ç»­è®­ç»ƒã€‚

Mindformersåœ¨è¾“å‡ºç›®å½•ä¸‹ä¼šä¿å­˜`checkpoint`å’Œ`checkpoint_network`ä¸¤ä¸ªæƒé‡è¾“å‡ºæ–‡ä»¶å¤¹ï¼Œåªæœ‰`checkpoint`å¯ç”¨äºæ–­ç‚¹ç»­è®­ã€‚

| æ–‡ä»¶å¤¹             | æè¿°                                                         |
| ------------------ | ------------------------------------------------------------ |
| checkpoint         | ä¿å­˜æƒé‡ã€ä¼˜åŒ–å™¨ã€stepã€epochã€loss_scaleç­‰å‚æ•°ä¿¡æ¯ï¼Œä¸»è¦ç”¨äº**æ–­ç‚¹æ¢å¤è®­ç»ƒ**ï¼Œå¯å®Œå…¨æ¢å¤è‡³ä¸­æ–­å¤„çš„è®­ç»ƒçŠ¶æ€ã€‚ |
| checkpoint_network | ä»…ä¿å­˜æƒé‡å‚æ•°ï¼Œå¯ç”¨ä½œ**é¢„è®­ç»ƒæƒé‡**æˆ–**æ¨ç†è¯„ä¼°**ï¼Œä¸æ”¯æŒ**æ–­ç‚¹æ¢å¤è®­ç»ƒ**ã€‚ |

`checkpoint`ä¿å­˜æƒé‡çš„æ–‡ä»¶æ ¼å¼å¦‚ä¸‹ï¼š

```text
checkpoint
  â”œâ”€â”€ rank_0
    â”œâ”€â”€ meta.json
    â””â”€â”€ {prefix}-{epoch}_{step}.ckpt
  ...
  â””â”€â”€ rank_x
    â”œâ”€â”€ meta.json
    â””â”€â”€ {prefix}-{epoch}_{step}.ckpt
```

| æ–‡ä»¶                         | æè¿°                                                         |
| ---------------------------- | ------------------------------------------------------------ |
| meta.json                    | è®°å½•æœ€åä¿å­˜çš„æƒé‡çš„epochã€stepå’Œæƒé‡åï¼Œæ¯ä¸ªrankè¿›ç¨‹å•ç‹¬ç»´æŠ¤ä¸€ä¸ªmeta.jsonã€‚ |
| {prefix}-{epoch}_{step}.ckpt | ä¿å­˜çš„æƒé‡æ–‡ä»¶åï¼Œprefixä¸ºå”¯ä¸€çš„æƒé‡åå‰ç¼€ï¼ŒåŒ…å«äº†rank_idä¿¡æ¯ã€‚<br />å¦‚"llama_7b_rank_0"ï¼Œè‹¥ä¿å­˜æƒé‡æ—¶ä½¿ç”¨è¯¥prefixçš„æƒé‡å·²å­˜åœ¨ï¼Œåˆ™prefixè‡ªåŠ¨æ‰©å±•ä¸º"llama_7b_rank_0_1"ã€‚<br />è‹¥"llama_7b_rank_0_1"ç»§ç»­å­˜åœ¨ï¼Œåˆ™prefixä¸º"llama_7b_rank_0_2"ï¼Œä»¥æ­¤ç±»æ¨ã€‚ |

- **yamlå‚æ•°è¯´æ˜**

  | å‚æ•°                          | æè¿°                                                         | é»˜è®¤å€¼ |
  | ----------------------------- | ------------------------------------------------------------ | ------ |
  | load_checkpoint               | æ–­ç‚¹ç»­è®­åŠ è½½çš„æƒé‡è·¯å¾„ã€‚<br />- å¦‚æœåŠ è½½**åˆ†å¸ƒå¼æƒé‡**ï¼Œé…ç½®ä¸º`checkpoint`æ–‡ä»¶å¤¹è·¯å¾„ã€‚<br />- å¦‚æœåŠ è½½**å®Œæ•´æƒé‡**ï¼Œé…ç½®ä¸ºæƒé‡æ–‡ä»¶ç»å¯¹è·¯å¾„ã€‚ | ""     |
  | resume_training               | æ–­ç‚¹ç»­è®­å¼€å…³ï¼Œå¯ä»¥æ˜¯å¸ƒå°”å€¼æˆ–å­—ç¬¦ä¸²ã€‚<br />ä¸º**True**æ—¶ï¼Œå¼€å¯æ–­ç‚¹ç»­è®­åŠŸèƒ½ï¼Œæ”¯æŒæ•…éšœæ¢å¤åŠŸèƒ½ã€‚<br />ä¸ºå­—ç¬¦ä¸²æ—¶ï¼Œå¿…é¡»æŒ‡å®šä¸ºä»»æ„rankä¸‹ä»»ä¸€æƒé‡çš„æ–‡ä»¶å**"{prefix}-{epoch}_{step}.ckpt"**ï¼Œæ‰€æœ‰rankå°†åŸºäºè¯¥æƒé‡æ‰€æŒ‡å®šçš„epochå’Œstepè¿›è¡Œæ–­ç‚¹ç»­è®­ã€‚ | False  |
  | resume_by_last_timestamp_ckpt | ç»­è®­æ˜¯å¦åŠ è½½æœ€åæ—¶é—´æˆ³æƒé‡ã€‚<br />ä¸º**True**æ—¶ï¼Œæ‰€æœ‰rankå°†åŠ è½½å„è‡ªrankæ–‡ä»¶å¤¹ä¸‹æœ€åæ—¶é—´æˆ³çš„æƒé‡ç”¨äºç»­è®­ï¼Œ**æ— æ³•ä¿è¯æƒé‡çš„stepæ•°ä¸€è‡´**ã€‚ | None   |
  | load_ckpt_async               | ckptä¸æ¨¡å‹ç¼–è¯‘å¹¶è¡Œå¼€å…³ï¼ˆåœ¨çº¿åˆ‡åˆ†æƒé‡åœºæ™¯ä¸‹è¯¥é…ç½®ä¸ç”Ÿæ•ˆï¼‰ï¼Œå¸ƒå°”å€¼é»˜è®¤ä¸ºFalseä¸å¼€å¯ã€‚<br />ä¸º**True**æ—¶ï¼Œå¼€å¯ckptå’Œç¼–è¯‘å¹¶è¡ŒåŠŸèƒ½ï¼Œå°†å¼‚æ­¥æ‰§è¡ŒåŠ è½½æƒé‡ï¼Œå‡å°‘æ€»ä½“è€—æ—¶åŠ é€Ÿæ‹‰èµ·ç»­è®­<br />ä¸º**False**æ—¶ï¼Œä¸å¼€å¯ckptå’Œç¼–è¯‘å¹¶è¡ŒåŠŸèƒ½ï¼ŒåŠ è½½æƒé‡å’Œæ¨¡å‹ç¼–è¯‘ä¸²è¡Œæ‰§è¡Œ | False  |

- **æ•…éšœæ¢å¤**

  Mindformersæ”¯æŒæ–­ç‚¹ç»­è®­æ•…éšœæ¢å¤ï¼Œ`resume_training`ä¸º`True`æ—¶ï¼Œèµ·å§‹å°†ä¼šåŸºäº`meta.json`è®°å½•çš„æƒé‡ç»­è®­ï¼Œè‹¥æŸrankå¯¹åº”çš„æƒé‡æ–‡ä»¶ç¼ºå¤±ã€æŸåã€ä¸å®Œæ•´ï¼Œä¼šè‡ªåŠ¨æœç´¢ä¸Šä¸€ä¸ªstepçš„æƒé‡ç”¨äºç»­è®­ã€‚

  æ¯”å¦‚ä½¿ç”¨2å¡æ–­ç‚¹ç»­è®­ï¼Œå‡è®¾æƒé‡ä¿å­˜æƒ…å†µå¦‚ä¸‹ï¼š

  ```text
  checkpoint_file_or_dir_path
    â”œâ”€â”€ rank_0
      â”œâ”€â”€ xxx_rank_0-3_2.ckpt
      â”œâ”€â”€ xxx_rank_0-6_2.ckpt (ç¼ºå¤±ã€æŸåã€ä¸å®Œæ•´)
      â””â”€â”€ xxx_rank_0-9_2.ckpt
    â””â”€â”€ rank_1
      â”œâ”€â”€ xxx_rank_1-3_2.ckpt
      â”œâ”€â”€ xxx_rank_1-6_2.ckpt
      â””â”€â”€ xxx_rank_1-9_2.ckpt (ç¼ºå¤±ã€æŸåã€ä¸å®Œæ•´)
  ```

  æ­¤æ—¶é…ç½®`resume_training`ä¸º`True`ï¼Œæ‰€æœ‰rankå°†ä¼šåŸºäº`xxx_rank_x-3_2.ckpt`ç»­è®­ã€‚

  â‘  è¯¥åŠŸèƒ½åªåœ¨`resume_training`ä¸º`True`æ—¶ç”Ÿæ•ˆï¼Œ`resume_training`ä¸ºæƒé‡åæ—¶ï¼Œå°†ä¼šä¸¥æ ¼æŒ‰ç…§æŒ‡å®šepochå’Œstepçš„æƒé‡ç»­è®­ã€‚

  â‘¡ **å¤šæœº**åœºæ™¯ä¸‹ï¼Œè¯¥åŠŸèƒ½éœ€ä¿è¯æ‰€æœ‰èŠ‚ç‚¹çš„ç»­è®­æƒé‡åœ¨**åŒä¸€å…±äº«ç›®å½•**ä¸‹ã€‚

  å¯ä»¥æ‰‹åŠ¨é…ç½®ç¯å¢ƒå˜é‡`SHARED_PATHS`æ¥è®¾ç½®å…±äº«è·¯å¾„ã€‚

  ```bash
  # å°†"/mnt/shared1","/mnt/shared2"ä¸¤ä¸ªè·¯å¾„è®¾ç½®ä¸ºå…±äº«è·¯å¾„ï¼Œæƒé‡è·¯å¾„è‹¥åœ¨è¿™ä¸¤ä¸ªç›®å½•ä¸‹ï¼Œå‡è§†ä¸ºå…±äº«è·¯å¾„ã€‚
  export SHARED_PATHS="/mnt/shared1,/mnt/shared2"

  # Dockerå®¹å™¨å†…è®¾ç½®å…±äº«è·¯å¾„
  docker run -e SHARED_PATHS="/mnt/shared1,/mnt/shared2" -v /mnt/shared1:/mnt/shared1 -v /mnt/shared2:/mnt/shared2 my_container
  ```

- **åŠŸèƒ½è¯´æ˜**

  | load_checkpoint | resume_training | åŠŸèƒ½æè¿°                                                     | æ˜¯å¦ä¸ºæ¨èä½¿ç”¨æ–¹å¼ |
  | --------------- | --------------- | ------------------------------------------------------------ | ------------------ |
  | æƒé‡æ–‡ä»¶è·¯å¾„    | True            | åŸºäºload_checkpointæŒ‡ä»£çš„æƒé‡ç»­è®­                            | âˆš                  |
  | æƒé‡æ–‡ä»¶è·¯å¾„    | æƒé‡æ–‡ä»¶å      | resume_trainingæŒ‡ä»£çš„æ–‡ä»¶åæ— æ•ˆï¼ŒåŸºäºload_checkpointæŒ‡ä»£çš„æƒé‡ç»­è®­ | Ã—                  |
  | æƒé‡æ–‡ä»¶å¤¹è·¯å¾„  | True            | **åœºæ™¯â‘ ï¼š"å•æœº"\|"å¤šæœº+å…±äº«ç›®å½•"\|"ModelArts"**<br />â‘  åŸºäºmeta.jsonè®°å½•çš„æƒé‡ç»­è®­ï¼Œæ”¯æŒæ•…éšœæ¢å¤ã€‚<br />â‘¡ è‹¥ä»»ä¸€rankæ–‡ä»¶å¤¹ä¸‹ç¼ºå°‘meta.jsonï¼Œæ‰€æœ‰rankåŸºäºæœ€åæ—¶é—´æˆ³çš„æƒé‡ç»­è®­ã€‚<br />**åœºæ™¯â‘¡ï¼š"å¤šæœº+éå…±äº«ç›®å½•"**<br />æ‰€æœ‰rankåŸºäºæœ€åæ—¶é—´æˆ³çš„æƒé‡ç»­è®­ã€‚ | âˆš                  |
  | æƒé‡æ–‡ä»¶å¤¹è·¯å¾„  | æƒé‡æ–‡ä»¶å      | åŸºäºresume_trainingæŒ‡ä»£çš„æƒé‡ç»­è®­                            | âˆš                  |

## è„šæœ¬å¯åŠ¨åœºæ™¯

### yamlé…ç½®

```yaml
load_checkpoint: checkpoint_file_or_dir_path
resume_training: True # æˆ–è€…"{prefix}-{epoch}_{step}.ckpt"
```

### å•å¡å¯åŠ¨

```bash
python run_mindformer.py --config xxx.yaml --run_mode train --use_parallel False --train_dataset dataset_dir
```

### åˆ†å¸ƒå¼å¯åŠ¨

```bash
# ä»¥8å¡ä¸ºä¾‹
bash scripts/msrun_launcher.sh "run_mindformer.py --config xxx.yaml --run_mode train --use_parallel True --train_dataset dataset_dir" 8
```

è¯¦ç»†åˆ†å¸ƒå¼å¯åŠ¨æ–¹å¼å‚è€ƒ[Mindformersä¸»é¡µä»‹ç»](https://gitee.com/mindspore/mindformers/tree/r1.1.0/#å•æœºå¤šå¡)ã€‚

## Traineré«˜é˜¶æ¥å£å¯åŠ¨åœºæ™¯

åœ¨Trainer.train()ä¸­ï¼Œé…ç½®`resume_from_checkpoint`å‚æ•°ä¸º`checkpoint_file_or_dir_path`ï¼Œå°†`resume_training`å‚æ•°è®¾ç½®ä¸º`True`ï¼Œå¹¶å¯æŒ‡å®š`resume_ckpt`ã€‚

### è®­ç»ƒè„šæœ¬

```python
# æ–°å»ºrun_trainer.py
import mindspore as ms
from mindformers import TrainingArguments, Trainer, AutoModelForCausalLM
from mindformers import build_context

# åˆå§‹åŒ–å‚æ•°é…ç½®ï¼Œé™¤äº†modelå’Œprocessorï¼ŒåŸºæœ¬æ¶µç›–yamlä¸­çš„æ‰€æœ‰é…ç½®
# åŒ…æ‹¬ç¯å¢ƒé…ç½®ã€åˆ†å¸ƒå¼é…ç½®ã€è®­ç»ƒè¶…å‚é…ç½®ã€æ•°æ®é›†é…ç½®ã€è¯„ä¼°ã€æƒé‡ä¿å­˜é…ç½®ç­‰
train_args = TrainingArguments(
    ...
)

# åˆå§‹åŒ–ç¯å¢ƒ
build_context(train_args)

# åˆå§‹åŒ–æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("xxx")

# åˆå§‹åŒ–è®­ç»ƒå™¨
trainer = Trainer(args=train_args,
                  model=model,
                  train_dataset="train_dataset")

# å¯åŠ¨æ–­ç‚¹ç»­è®­
trainer.train(
    resume_from_checkpoint="checkpoint_file_or_dir_path",
    resume_training=True # æˆ–è€… "{prefix}-{epoch}_{step}.ckpt"
)
```

### å•å¡å¯åŠ¨

```python
python run_trainer.py
```

### åˆ†å¸ƒå¼å¯åŠ¨

```bash
# ä»¥8å¡ä¸ºä¾‹
bash scripts/msrun_launcher.sh "run_trainer.py" 8
```

## ä½¿ç”¨æ¡ˆä¾‹

### æ¦‚è¿°

æœ¬ç« èŠ‚ä¸»è¦æ¼”ç¤ºåŸºäºllama-7bçš„æ–­ç‚¹ç»­è®­æ¡ˆä¾‹ï¼Œåˆ†åˆ«ä»‹ç»**å•å¡æ–­ç‚¹ç»­è®­**ä»¥åŠ**åˆ†å¸ƒå¼æ–­ç‚¹ç»­è®­**ï¼Œå¯åŠ¨æ–¹å¼åˆ†ä¸º**è„šæœ¬å¯åŠ¨**å’Œ**Traineré«˜é˜¶æ¥å£å¯åŠ¨**ä¸¤ç§ã€‚

å•å¡è®­ç»ƒæ”¯æŒ**æ•°æ®ä¸‹æ²‰**å’Œ**éä¸‹æ²‰**ä¸¤ç§æ¨¡å¼ï¼Œåˆ†å¸ƒå¼è®­ç»ƒé»˜è®¤å¼€å¯**æ•°æ®ä¸‹æ²‰**ã€‚

- æ¡ˆä¾‹1ï¼šå•å¡æ–­ç‚¹ç»­è®­ï¼Œæ‰“å¼€æ•°æ®ä¸‹æ²‰ï¼Œé€šè¿‡run_mindformer.pyè„šæœ¬å¯åŠ¨ï¼›

- æ¡ˆä¾‹2ï¼šå•å¡æ–­ç‚¹ç»­è®­ï¼Œå…³é—­æ•°æ®ä¸‹æ²‰ï¼Œé€šè¿‡Traineré«˜é˜¶æ¥å£å¯åŠ¨ï¼›
- æ¡ˆä¾‹3ï¼šåˆ†å¸ƒå¼æ–­ç‚¹ç»­è®­ï¼Œé€šè¿‡run_mindformer.pyè„šæœ¬å¯åŠ¨ï¼ŒæŒ‡å®šç»­è®­æƒé‡ï¼›

> æ³¨ï¼šæ¡ˆä¾‹ä»…ä¸ºæ¼”ç¤ºä¸åŒåœºæ™¯ä¸‹å¦‚ä½•å¯åŠ¨æ–­ç‚¹ç»­è®­ï¼ŒéªŒè¯æ–­ç‚¹ç»­è®­çš„æ•ˆæœï¼Œè®­ç»ƒå‚æ•°/lossç­‰ä¸å…·å¤‡å‚è€ƒä»·å€¼ã€‚

### å‰æœŸå‡†å¤‡

#### æ•°æ®é›†

ä¸‹è½½å¹¶è§£å‹å·²ç»è½¬æˆMindRecordæ ¼å¼çš„[Wikitextæ•°æ®é›†](https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/MindFormers/features/resume_training/data/wikitext_512_llama1_40/wikitext_512_llama1_40.zip)ï¼Œè¯¥æ•°æ®é›†ä½¿ç”¨llamaçš„è¯è¡¨è½¬æ¢ï¼Œå…±åŒ…å«40æ¡æ–‡æœ¬æ•°æ®ï¼Œæ¯æ¡æ•°æ®çš„seq_lengthä¸º512ã€‚

#### å…¬å…±é…ç½®

ä¿®æ”¹`configs/llama/run_llama_7b.yaml`é…ç½®æ–‡ä»¶

```yaml
# è®¾ç½®è®­ç»ƒç›¸å…³å‚æ•°
runner_config:
  epochs: 5

# è®¾ç½®æ•°æ®é›†
train_dataset: &train_dataset
  data_loader:
    type: MindDataset
    dataset_dir: "path/to/wikitext_512_llama1_40" # å¡«å†™æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„
    shuffle: True

# è®¾ç½®æƒé‡ä¿å­˜å‚æ•°
callbacks:
  - type: CheckpointMonitor
    save_checkpoint_steps: 5 # æ¯éš”5stepä¿å­˜ä¸€æ¬¡
    keep_checkpoint_max: 20 # è®¾ç½®checkpointæœ€å¤§ä¿å­˜æ•°ï¼Œè®¾ç½®ä¸º20ä»¥ä¿å­˜å…¨éƒ¨çš„checkpointï¼Œå¦‚ä¸è®¾ç½®é»˜è®¤ä¸º5ã€‚

# è®¾ç½®æ¨¡å‹å‚æ•°ï¼Œå‡å°‘seq_lengthã€hidden_sizeå’Œnum_layersï¼Œä»¥ç¼©çŸ­è®­ç»ƒéªŒè¯æ—¶é—´ã€‚
seq_length: 512
hidden_size: 512
num_layers: 2
```

### æ¡ˆä¾‹1ï¼šå•å¡æ–­ç‚¹ç»­è®­ï¼Œæ‰“å¼€æ•°æ®ä¸‹æ²‰æ¨¡å¼ï¼Œé€šè¿‡è„šæœ¬å¯åŠ¨

#### â‘  å•å¡å®Œæ•´è®­ç»ƒ

**æè¿°**ï¼šè·å–å®Œæ•´è®­ç»ƒæ—¥å¿—å’Œä¿å­˜çš„æƒé‡æ–‡ä»¶ã€‚

**step1**ï¼šåœ¨[å‰æœŸå‡†å¤‡-å…¬å…±é…ç½®](#å…¬å…±é…ç½®)åŸºç¡€ä¸Šï¼Œä¿®æ”¹`configs/llama/run_llama_7b.yaml`é…ç½®æ–‡ä»¶

```yaml
# è®¾ç½®è®­ç»ƒç›¸å…³å‚æ•°
runner_config:
  batch_size: 4
  sink_mode: True # æ‰“å¼€æ•°æ®ä¸‹æ²‰
use_parallel: False
```

**step2**ï¼šå¯åŠ¨å•å¡è®­ç»ƒ

```shell
python run_mindformer.py --config configs/llama/run_llama_7b.yaml
```

**step3**ï¼šæŸ¥çœ‹è®­ç»ƒæ—¥å¿—

![llama7b_standalone_with_sinkmode](assets/Resume_Training/llama7b_standalone_with_sinkmode.png)

#### â‘¡ å•å¡æ–­ç‚¹ç»­è®­

**æè¿°**ï¼šéªŒè¯åŸºäºä¸­é—´ä¿å­˜çš„æƒé‡è¿›è¡Œæ–­ç‚¹ç»­è®­çš„losså’Œå®Œæ•´è®­ç»ƒå¯¹é½ã€‚

**step1**ï¼šåœ¨**â‘  å•å¡å®Œæ•´è®­ç»ƒ**é…ç½®åŸºç¡€ä¸Šï¼Œä¿®æ”¹`configs/llama/run_llama_7b.yaml`é…ç½®æ–‡ä»¶

```yaml
# è®¾ç½®æƒé‡åŠ è½½å‚æ•°
load_checkpoint: './output/checkpoint/rank_0/llama_7b_rank0-12_2.ckpt'
resume_training: True # æ‰“å¼€æ–­ç‚¹ç»­è®­å¼€å…³
```

>æ³¨ï¼šç”±äºå¼€å¯äº†æ•°æ®ä¸‹æ²‰ï¼Œepoch3-step4ä¿å­˜çš„æƒé‡åå¹¶é"llama_7b_rank_0-3_4.ckpt"ã€‚epochè®¡ç®—æ–¹å¼ä¸º"å½“å‰stepæ•°/sink_size = ((cur_epoch-1)\*steps_per_epoch+cur_step_in_epoch)/sink_size=((3-1)\*10+4)/2=12"ï¼Œstepå›ºå®šä¸º"sink_size=2"ï¼Œå³æ•°æ®ä¸‹æ²‰æ¨¡å¼ä¸‹ï¼Œepoch3-step4ä¿å­˜çš„æƒé‡ï¼Œæƒé‡åä¸º"llama_7b_rank_0-12_2.ckpt"

**step2**ï¼šå¯åŠ¨å•å¡è®­ç»ƒ

```shell
python run_mindformer.py --config configs/llama/run_llama_7b.yaml
```

**step3**ï¼šæŸ¥çœ‹è®­ç»ƒæ—¥å¿—ï¼Œlosså’Œå®Œæ•´è®­ç»ƒæ—¥å¿—å¯¹é½

![llama7b_standalone_with_sinkmode_resume](assets/Resume_Training/llama7b_standalone_with_sinkmode_resume.png)

### æ¡ˆä¾‹2ï¼šå•å¡æ–­ç‚¹ç»­è®­ï¼Œå…³é—­æ•°æ®ä¸‹æ²‰æ¨¡å¼ï¼Œé€šè¿‡é«˜é˜¶æ¥å£å¯åŠ¨

#### â‘  å•å¡å®Œæ•´è®­ç»ƒ

**æè¿°**ï¼šè·å–å®Œæ•´è®­ç»ƒæ—¥å¿—å’Œä¿å­˜çš„æƒé‡æ–‡ä»¶ã€‚

**step1**ï¼šæ–°å»º`run_trainer.py`æ–‡ä»¶

```python
# æ–°å»ºrun_trainer.py
from mindformers import TrainingArguments, Trainer, AutoModelForCausalLM
from mindformers import build_context

# åˆå§‹åŒ–å‚æ•°é…ç½®ï¼Œé™¤äº†modelå’Œprocessorï¼ŒåŸºæœ¬æ¶µç›–yamlä¸­çš„æ‰€æœ‰é…ç½®
# åŒ…æ‹¬ç¯å¢ƒé…ç½®ã€åˆ†å¸ƒå¼é…ç½®ã€è®­ç»ƒè¶…å‚é…ç½®ã€æ•°æ®é›†é…ç½®ã€è¯„ä¼°ã€æƒé‡ä¿å­˜é…ç½®ç­‰
train_args = TrainingArguments(
    use_parallel=False,
    num_train_epochs=5,
    sink_mode=False,
    save_steps=6,
    save_total_limit=20,
    logging_steps=2,
    per_device_train_batch_size=4,
    train_dataset_in_columns=["input_ids"],
    dataset_task="CausalLanguageModelDataset",
    dataset_type="MindDataset",
)

# åˆå§‹åŒ–ç¯å¢ƒ
build_context(train_args)

# åˆå§‹åŒ–æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("llama_7b", download_checkpoint=False)

# åˆå§‹åŒ–è®­ç»ƒå™¨
trainer = Trainer(args=train_args,
                  model=model,
                  train_dataset="path/to/wikitext_512_llama1_40")

# å¯åŠ¨è®­ç»ƒ
trainer.train()
```

**step2**ï¼šå¯åŠ¨å•å¡è®­ç»ƒ

```shell
python run_trainer.py
```

**step3**ï¼šæŸ¥çœ‹è®­ç»ƒæ—¥å¿—

![llama7b_standalone_no_sinkmode](assets/Resume_Training/llama7b_standalone_no_sinkmode.png)

#### â‘¡ å•å¡æ–­ç‚¹ç»­è®­

**æè¿°**ï¼šéªŒè¯åŸºäºä¸­é—´ä¿å­˜çš„æƒé‡è¿›è¡Œæ–­ç‚¹ç»­è®­çš„losså’Œå®Œæ•´è®­ç»ƒçš„losså¯¹é½ã€‚

**step1**ï¼šä¿®æ”¹`run_trainer.py`æ–‡ä»¶ï¼Œå¢åŠ æ–­ç‚¹ç»­è®­å‚æ•°é…ç½®

```python
trainer.train(
    resume_from_checkpoint="./output/checkpoint/rank_0/CKP_rank_0-3_4.ckpt",
    resume_training=True,
)
```

**step2**ï¼šå¯åŠ¨å•å¡è®­ç»ƒ

```shell
python run_trainer.py
```

**step3**ï¼šæŸ¥çœ‹è®­ç»ƒæ—¥å¿—ï¼Œlosså’Œå®Œæ•´è®­ç»ƒæ—¥å¿—å¯¹é½

![llama7b_standalone_no_sinkmode_resume](assets/Resume_Training/llama7b_standalone_no_sinkmode_resume.png)

### æ¡ˆä¾‹3ï¼šåˆ†å¸ƒå¼æ–­ç‚¹ç»­è®­ï¼Œé€šè¿‡è„šæœ¬å¯åŠ¨ï¼ŒæŒ‡å®šç»­è®­æƒé‡

#### â‘  åˆ†å¸ƒå¼å®Œæ•´è®­ç»ƒ

**æè¿°**ï¼šè·å–å®Œæ•´è®­ç»ƒæ—¥å¿—å’Œä¿å­˜çš„æƒé‡æ–‡ä»¶ã€‚

**step1**ï¼šåœ¨[å‰æœŸå‡†å¤‡-å…¬å…±é…ç½®](#å…¬å…±é…ç½®)åŸºç¡€ä¸Šï¼Œä¿®æ”¹`configs/llama/run_llama_7b.yaml`é…ç½®æ–‡ä»¶

```yaml
# è®¾ç½®è®­ç»ƒç›¸å…³å‚æ•°
runner_config:
  batch_size: 2 # batch_sizeè®¾ç½®ä¸º2
  sink_mode: True # æ‰“å¼€æ•°æ®ä¸‹æ²‰
use_parallel: True

# è®¾ç½®åˆ†å¸ƒå¼å¹¶è¡Œç­–ç•¥
parallel_config:
  data_parallel: 1
  model_parallel: 2
  pipeline_stage: 2
  micro_batch_num: 2
```

**step2**ï¼šé€šè¿‡`msrun`å¯åŠ¨4å¡åˆ†å¸ƒå¼è®­ç»ƒ

```shell
bash scripts/msrun_launcher.sh "run_mindformer.py --config ./output/configs/llama/run_llama_7b.yaml --run_mode train --use_parallel True --train_dataset path/to/wikitext_512_llama1_40" 4
```

**step3**ï¼šæŸ¥çœ‹è®­ç»ƒæ—¥å¿—

![llama7b_distribute_with_sinkmode](assets/Resume_Training/llama7b_distribute_with_sinkmode.png)

#### â‘¡ åˆ†å¸ƒå¼æ–­ç‚¹ç»­è®­ï¼šæŒ‡å®šæƒé‡

**æè¿°**ï¼šæŒ‡å®šä¸­é—´ä¿å­˜çš„æƒé‡è¿›è¡Œæ–­ç‚¹ç»­è®­ï¼ŒéªŒè¯losså’Œå®Œæ•´è®­ç»ƒçš„losså¯¹é½ã€‚

**step1**ï¼šåœ¨**â‘  åˆ†å¸ƒå¼å®Œæ•´è®­ç»ƒ**é…ç½®åŸºç¡€ä¸Šï¼Œä¿®æ”¹`configs/llama/run_llama_7b.yaml`é…ç½®æ–‡ä»¶

```yaml
# è®¾ç½®æƒé‡åŠ è½½å‚æ•°
load_checkpoint: './output/checkpoint'       # å¡«å†™checkpointæ–‡ä»¶å¤¹è·¯å¾„
resume_training: 'llama_7b_rank_0-12_2.ckpt' # æŒ‡å®šæ–­ç‚¹ç»­è®­çš„æƒé‡å
```

**step2**ï¼šé€šè¿‡`msrun`å¯åŠ¨4å¡åˆ†å¸ƒå¼è®­ç»ƒ

```shell
bash scripts/msrun_launcher.sh "run_mindformer.py --config ./output/configs/llama/run_llama_7b.yaml --run_mode train --use_parallel True --train_dataset path/to/wikitext_512_llama1_40" 4
```

**step3**ï¼šæŸ¥çœ‹è®­ç»ƒæ—¥å¿—

- losså’Œå®Œæ•´è®­ç»ƒæ—¥å¿—å¯¹é½

![llama7b_distribute_with_sinkmode_resume](assets/Resume_Training/llama7b_distribute_with_sinkmode_resume.png)

#### â‘¢ åˆ†å¸ƒå¼æ–­ç‚¹ç»­è®­ï¼šæ•…éšœæ¢å¤

**æè¿°**ï¼šåŸºäºmeta.jsonè®°å½•çš„æƒé‡è¿›è¡Œæ–­ç‚¹ç»­è®­ï¼ŒéªŒè¯æ•…éšœæ¢å¤ä»¥åŠlosså’Œå®Œæ•´è®­ç»ƒçš„losså¯¹é½ã€‚

**step1**ï¼šåˆ é™¤`output/checkpoint/rank_3/llama_7b_rank_3-12_2.ckpt`ã€‚

**step2**ï¼šåœ¨**â‘  åˆ†å¸ƒå¼å®Œæ•´è®­ç»ƒ**é…ç½®åŸºç¡€ä¸Šï¼Œä¿®æ”¹`configs/llama/run_llama_7b.yaml`é…ç½®æ–‡ä»¶

```yaml
# è®¾ç½®æƒé‡åŠ è½½å‚æ•°
load_checkpoint: './output/checkpoint'       # å¡«å†™checkpointæ–‡ä»¶å¤¹è·¯å¾„
resume_training: True
```

**step3**ï¼šé€šè¿‡`msrun`å¯åŠ¨4å¡åˆ†å¸ƒå¼è®­ç»ƒ

```shell
bash scripts/msrun_launcher.sh "run_mindformer.py --config ./output/configs/llama/run_llama_7b.yaml --run_mode train --use_parallel True --train_dataset path/to/wikitext_512_llama1_40" 4
```

**step3**ï¼šæŸ¥çœ‹è®­ç»ƒæ—¥å¿—

- æ•…éšœæ¢å¤ç›¸å…³æ—¥å¿—ï¼Œç”±äºrank_3ä¸‹çš„`llama_7b_rank_3-12_2.ckpt`ç¼ºå¤±ï¼Œæ‰€æœ‰rankè¿›ç¨‹åŸºäº`llama_7b_rank_x-9_2.ckpt`ç»­è®­ã€‚

![llama7b_distribute_with_sinkmode_log2](assets/Resume_Training/llama7b_distribute_with_sinkmode_log.png)

- losså’Œå®Œæ•´è®­ç»ƒæ—¥å¿—å¯¹é½

![llama7b_distribute_with_sinkmode_resume2](assets/Resume_Training/llama7b_distribute_with_sinkmode_resume2.png)

## æ³¨æ„äº‹é¡¹

1. åˆ†å¸ƒå¼æ–­ç‚¹ç»­è®­å¿…é¡»å¼€å¯æ•°æ®ä¸‹æ²‰æ¨¡å¼ï¼Œé…ç½®`sink_mode=True`ã€‚

2. å¦‚æœæ–­ç‚¹ç»­è®­åŠ è½½çš„æƒé‡å·²ç»æ˜¯æœ€åè®­ç»ƒå®Œä¿å­˜çš„æƒé‡ï¼Œå°†ä¼šæŠ¥ä»¥ä¸‹é”™è¯¯

   ```log
   RuntimeError: Exception thrown from dataset pipeline. Refer to 'Dataset Pipeline Error Message'.
   ```
