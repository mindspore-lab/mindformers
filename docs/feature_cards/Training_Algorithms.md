# è®­ç»ƒä¼˜åŒ–ç®—æ³•

> ## ğŸš¨ å¼ƒç”¨è¯´æ˜
>
> æœ¬æ–‡æ¡£å·²è¿‡æ—¶ï¼Œä¸å†è¿›è¡Œç»´æŠ¤ï¼Œå¹¶å°†åœ¨ *1.6.0* ç‰ˆæœ¬ä¸‹æ¶ï¼Œå…¶ä¸­å¯èƒ½åŒ…å«è¿‡æ—¶çš„ä¿¡æ¯æˆ–å·²è¢«æ›´æ–°çš„åŠŸèƒ½æ›¿ä»£ã€‚å»ºè®®å‚è€ƒæœ€æ–°çš„ **[å®˜æ–¹æ–‡æ¡£](https://www.mindspore.cn/mindformers/docs/zh-CN/r1.5.0/index.html)** ï¼Œä»¥è·å–å‡†ç¡®çš„ä¿¡æ¯ã€‚
>
> å¦‚æœæ‚¨ä»éœ€ä½¿ç”¨æœ¬æ–‡æ¡£ä¸­çš„å†…å®¹ï¼Œè¯·ä»”ç»†æ ¸å¯¹å…¶é€‚ç”¨æ€§ï¼Œå¹¶ç»“åˆæœ€æ–°ç‰ˆæœ¬çš„ç›¸å…³èµ„æºè¿›è¡ŒéªŒè¯ã€‚
>
> å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ **[ç¤¾åŒºIssue](https://gitee.com/mindspore/mindformers/issues/new)** æäº¤åé¦ˆã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£ä¸æ”¯æŒï¼

MindFormerså¥—ä»¶é›†æˆäº†è®¸å¤šæ¨¡å‹è®­ç»ƒä¸­é€šç”¨çš„ä¼˜åŒ–ç®—æ³•ï¼Œå¹¶æä¾›äº†ä¾¿æ·çš„ä½¿ç”¨æ–¹å¼ï¼Œåœ¨æœ¬æ–‡æ¡£ä¸­é›†ä¸­è¿›è¡Œè¯´æ˜ã€‚

ç›®å½•ï¼š

- [è®­ç»ƒä¼˜åŒ–ç®—æ³•](#è®­ç»ƒä¼˜åŒ–ç®—æ³•)
    - [æ¢¯åº¦ç´¯ç§¯](#æ¢¯åº¦ç´¯ç§¯)
    - [æ¢¯åº¦è£å‰ª](#æ¢¯åº¦è£å‰ª)
    - [Tokenåˆ†å¸ƒ](#tokenåˆ†å¸ƒ)
    - [Flash Attention](#flash-attention)
    - [Adaptive loss scaling](#adaptive-loss-scaling)
    - [Lazy Inline](#lazy-inline)
    - [MoEå†·çƒ­é—¨ä¸“å®¶ä¼˜åŒ–](#moeå†·çƒ­é—¨ä¸“å®¶ä¼˜åŒ–)

## æ¢¯åº¦ç´¯ç§¯

æ¢¯åº¦ç´¯ç§¯ç®—æ³•æ˜¯ä¸šç•Œå¸¸ç”¨çš„æ‰©å¤§batch_sizeï¼Œè§£å†³OOMçš„ä¸€ç§ç®—æ³•ï¼Œå¯å‚è€ƒ[MindSporeæ–‡æ¡£](https://www.mindspore.cn/docs/zh-CN/r2.4.0/model_train/parallel/distributed_gradient_accumulation.html)

MindSporeåœ¨2.1.1ä¹‹åçš„ç‰ˆæœ¬ä¸­å¢åŠ äº† `mindspore.nn.wrap.cell_wrapper.GradAccumulationCell` è¿™ä¸€æ¢¯åº¦ç´¯ç§¯å®ç°æ¥å£ï¼Œé€šè¿‡æ‹†åˆ†MiniBatchçš„å½¢å¼å®ç°äº†æ¢¯åº¦ç´¯ç§¯

MindFormerså¥—ä»¶å¯¹ä¸Šè¿°å®ç°æ¥å£è¿›è¡Œäº†é€‚é…ï¼Œåœ¨éœ€è¦å¼€å¯æ¢¯åº¦ç´¯ç§¯çš„åœºæ™¯ä¸‹ï¼Œåªéœ€åœ¨é…ç½®æ–‡ä»¶ä¸­çš„ `runner_config` é¡¹ä¸‹æ–°å¢ `gradient_accumulation_steps` é¡¹ï¼Œå¹¶é…ç½®ä¸ºæ‰€éœ€çš„æ¢¯åº¦ç´¯ç§¯æ­¥æ•°å³å¯ï¼Œå¦‚ä¸‹ï¼š

```yaml
runner_config:
  ...
  gradient_accumulation_steps: 4
  ...
```

é™¤é…ç½®æ–‡ä»¶å¤–ï¼Œå…¶ä½™å‡ ç§å¸¸ç”¨ä½¿ç”¨æ–¹å¼ä¹Ÿæä¾›äº†æ¢¯åº¦ç´¯ç§¯çš„é…ç½®æ¥å£ï¼š

1. run_mindformer.pyè„šæœ¬å¯åŠ¨æ—¶ï¼Œå¯æŒ‡å®š `--gradient_accumulation_steps` å…¥å‚ï¼›

2. traineræ¥å£å¯åŠ¨æ—¶ï¼Œå¯é€šè¿‡ `TrainingArguments` ç±»æŒ‡å®š `gradient_accumulation_steps` å…¥å‚ï¼›

**é™åˆ¶**ï¼šç”±äº `GradAccumulationCell` çš„å®ç°ä¾èµ–å¹¶è¡Œç‰¹æ€§ï¼Œæ¢¯åº¦ç´¯ç§¯å½“å‰ä»…æ”¯æŒåœ¨**åŠè‡ªåŠ¨å¹¶è¡Œæ¨¡å¼**ä¸‹ä½¿ç”¨ï¼›æ­¤å¤–ï¼Œpipelineå¹¶è¡Œåœºæ™¯ä¸‹ï¼Œæ¢¯åº¦ç´¯ç§¯å«ä¹‰ä¸micro_batchç›¸åŒï¼Œå°†ä¸ä¼šç”Ÿæ•ˆï¼Œè¯·é…ç½® `micro_batch_num` é¡¹ä»¥å¢å¤§è®­ç»ƒbatch_size

## æ¢¯åº¦è£å‰ª

æ¢¯åº¦è£å‰ªç®—æ³•å¯ä»¥é¿å…åå‘æ¢¯åº¦è¿‡å¤§ï¼Œè·³è¿‡æœ€ä¼˜è§£çš„æƒ…å†µ

MindFormersä¸­ï¼Œé»˜è®¤çš„è®­ç»ƒæµç¨‹ `MFTrainOneStepCell` ä¸­é›†æˆäº†æ¢¯åº¦è£å‰ªé€»è¾‘ï¼Œé€šè¿‡ `use_clip_grad` é…ç½®é¡¹æ¥æ§åˆ¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¯å¦å¼€å¯æ¢¯åº¦è£å‰ªï¼Œé»˜è®¤ä¸ºFalseï¼›å¹¶å¯é€šè¿‡ `max_grad_norm` é¡¹æ§åˆ¶æ¢¯åº¦è£å‰ªçš„æœ€å¤§normå€¼ï¼Œé»˜è®¤ä¸º1.0ï¼›å¦‚ä¸‹ä»¥å¼€å¯æ¢¯åº¦è£å‰ªï¼š

```yaml
runner_wrapper:
  type: MFTrainOneStepCell
  ...
  use_clip_grad: True
  max_grad_norm: 1.0
  ...
```

## Tokenåˆ†å¸ƒ

åœ¨MoEå¤§æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¸¸è§çš„TopK Routerç®—æ³•ä¼šå¯¼è‡´Tokenåˆ†å‘ä¸å‡åŒ€ï¼Œå­˜åœ¨Routerç»™å°‘æ•°çƒ­é—¨ä¸“å®¶åˆ†é…å¤§é‡Tokenï¼Œå¤šæ•°å†·é—¨ä¸“å®¶åˆ†é…å°‘é‡Tokençš„æƒ…å†µã€‚ä¸“å®¶å—é™äºä¸“å®¶å®¹é‡ï¼Œä¼šå°†è¶…è¿‡ä¸“å®¶å®¹é‡çš„Tokenä¸¢å¼ƒï¼Œä¸è¶³ä¸“å®¶å®¹é‡çš„Paddingã€‚æ‰€ä»¥è·å–Tokenåˆ†å¸ƒæƒ…å†µèƒ½å¸®åŠ©ç”¨æˆ·åˆç†ç¡®å®šä¸“å®¶å®¹é‡ã€‚
MindFormersé…ç½®æ–‡ä»¶ä¸­çš„`MoE_config`æ–°å¢äº†`save_token_distribution`é…ç½®é¡¹ï¼Œé»˜è®¤Falseï¼Œéœ€è¦æ­é…`callbacks`ä¸­çš„`SummaryMonitor`ä¸€åŒå¼€å¯ï¼Œå¦‚ä¸‹ï¼š

```yaml
moe_config:
  expert_num: 8
  save_token_distribution: true

callbacks:
- type: SummaryMonitor
  summary_dir: "../summary_dir/token_distribution_dir"
  keep_default_action: False
  collect_freq: 1
  collect_tensor_freq: 1
  export_options: {'tensor_format':'npy'}
```

åœ¨å¼€å¯è¯¥é…ç½®ä¹‹åï¼Œä¼šåœ¨`summary_dir`è·¯å¾„ä¸‹ç”Ÿæˆ`export_xxx/tensor`æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­åŒ…å«æ¯å±‚MoEä¸­Tokenåˆ†å¸ƒæ•°æ®ï¼Œå†ä½¿ç”¨`mindformers/tools/moe_token_distribution_tools.py`è„šæœ¬ï¼Œè¾“å…¥å‚æ•°ï¼š`num_layers`ã€`hot_expert_num`ã€`npy_files_load_path`ã€`save_path_prefix`ã€‚ä¼šåœ¨ä¿å­˜è·¯å¾„ä¸­ç”ŸæˆTokenåˆ†å¸ƒå›¾ã€‚

## Flash Attention

Flash Attentionï¼ˆç®€ç§°FAï¼‰ï¼Œæ˜¯æ·±åº¦å­¦ä¹ ä¸šç•Œä¸»æµçš„æ³¨æ„åŠ›è®¡ç®—åŠ é€Ÿç®—æ³•ï¼›MindSpore+Ascendæ¶æ„ä¹Ÿæä¾›äº†FAå®ç°ï¼Œå½“å‰MindFormerså¯¹éƒ¨åˆ†æ¨¡å‹è¿›è¡Œäº†FAçš„é€‚é…ï¼Œå¯ä½¿ç”¨ `model_config` ä¸­çš„ `use_flash_attention` é…ç½®é¡¹æ§åˆ¶æ¨¡å‹æ˜¯å¦ä½¿ç”¨FA

æ³¨æ„ï¼ŒFAç‰¹æ€§ä¾èµ–äºMindSpore 2.2.10+ç‰ˆæœ¬ï¼Œä¸”ç›®å‰ä»…é’ˆå¯¹Atlas A2è®­ç»ƒç³»åˆ—ç¡¬ä»¶è¿›è¡Œäº†é€‚é…ï¼Œè¯·ä½¿ç”¨æ­£ç¡®çš„ç‰ˆæœ¬é…å¥—

ç”±äºFAç‰¹æ€§å¹¶éå…¨ç‰ˆæœ¬å…¨ç¡¬ä»¶æ”¯æŒï¼Œå½“å‰é»˜è®¤å…³é—­FAï¼Œéœ€æ‰‹åŠ¨æ‰“å¼€é…ç½®é¡¹ä»¥ä½¿ç”¨FA

ä¸¾ä¾‹å¦‚ä¸‹ï¼Œllamaå¯é€šè¿‡ä¿®æ”¹é…ç½®é¡¹ä»¥ä½¿èƒ½FAï¼Œè€Œåå¯ä½¿ç”¨è¯¥é…ç½®é¡¹è¿›è¡Œè®­ç»ƒ

```yaml
# model config
model:
  model_config:
    type: LlamaConfig
    ...
    use_flash_attention: True   # True to enable FA, False to disable FA
    ...
  arch:
    type: LlamaForCausalLM
```

FAçš„æ¨¡å‹æ”¯æŒåº¦å¯å‚è§ [æ¨¡å‹èƒ½åŠ›è¡¨æ ¼](../model_support_list.md#llmå¤§æ¨¡å‹èƒ½åŠ›æ”¯æŒä¸€è§ˆ)

## Adaptive loss scaling

### Adaptive loss scaling åŸºæœ¬ä»‹ç»

ç°æœ‰dynamic loss scalingæ–¹æ¡ˆä½¿ç”¨å›ºå®šscale windowï¼Œåœ¨FP16æˆ–æ›´ä½ç²¾åº¦(8bitæµ®ç‚¹æ ¼å¼)æ··åˆç²¾åº¦è®­ç»ƒè®­ç»ƒæ—¶ï¼Œå¦‚æœé€‰ç”¨è¾ƒå¤§çš„scale windowï¼Œå­˜åœ¨loss scaling è°ƒæ•´ä¸åŠæ—¶çš„é£é™©ï¼Œå½±å“æ¨¡å‹æ”¶æ•›æ€§å’Œæ”¶æ•›é€Ÿåº¦ï¼›å¦‚æœé€‰ç”¨è¾ƒå°çš„scale windowï¼Œloss scaleè°ƒæ•´è‡³åˆé€‚çš„å€¼æ—¶ï¼Œä»ä¼šé¢‘ç¹ä¸Šè°ƒï¼ŒæŸå¤±å¤§é‡è®­ç»ƒæ•°æ®ã€‚ Adaptive loss scalingæ–¹æ¡ˆï¼Œé€šè¿‡åŠ¨æ€è°ƒèŠ‚scale windowï¼Œå®ç°è‡ªé€‚åº”è°ƒæ•´loss scaleï¼Œå®æ—¶å°†loss scaleè°ƒæ•´è‡³FP16å’Œ8bitæµ®ç‚¹æ ¼å¼æ­£å¸¸è®­ç»ƒæ‰€éœ€çš„åˆé€‚çš„å€¼ï¼ŒåŒæ—¶é¿å…æŸå¤±å¤§é‡è®­ç»ƒæ•°æ®ã€‚

### ä½¿ç”¨åœºæ™¯åŠé’ˆå¯¹çš„é—®é¢˜

#### ä½¿ç”¨åœºæ™¯

##### å¤§æ¨¡å‹é¢„è®­ç»ƒ

åŒ…å«ï¼šFP16æ··åˆç²¾åº¦è®­ç»ƒã€å…¨FP16è®­ç»ƒã€FP8æ··åˆç²¾åº¦è®­ç»ƒã€å…¶ä»–ä½ç²¾åº¦æµ®ç‚¹æ ¼å¼æ··åˆç²¾åº¦è®­ç»ƒ

##### å¤§æ¨¡å‹æ–­ç‚¹ç»­è®­

åŒ…å«ï¼šFP16æ··åˆç²¾åº¦è®­ç»ƒã€å…¨FP16è®­ç»ƒã€FP8æ··åˆç²¾åº¦è®­ç»ƒã€å…¶ä»–ä½ç²¾åº¦æµ®ç‚¹æ ¼å¼æ··åˆç²¾åº¦è®­ç»ƒ

##### å¾®è°ƒ

FTã€SFTã€RLHFç­‰æ¨¡å‹å¾®è°ƒåœºæ™¯

#### é’ˆå¯¹çš„é—®é¢˜

##### å¤§æ¨¡å‹è®­ç»ƒæ—©æœŸ

ç”±äºä½¿ç”¨FP16å’ŒFP8ç­‰ä½ç²¾åº¦æ•°æ®æ ¼å¼å¼•å…¥çš„æ•°å€¼åŠ¨æ€èŒƒå›´ä¸è¶³æˆ–ç²¾åº¦ä¸è¶³å¯¼è‡´çš„æ¢¯åº¦å¼¥æ•£åŠlosså›å‡é—®é¢˜

##### å¤§æ¨¡å‹è®­ç»ƒä¸­åæœŸ

loss scaleä¸ç¨³å®šï¼Œå¼‚å¸¸æ³¢åŠ¨ï¼Œéœ€é¢‘ç¹æ‰‹åŠ¨è°ƒæ•´scale windowè¿›è¡Œæ–­ç‚¹é‡è®­çš„ç°è±¡

### è®¾è®¡æ¦‚è¿°

æ ¹æ®ç”¨æˆ·è¾“å…¥çš„max scale windowï¼Œå’Œé»˜è®¤çš„min scale window 20ã€‚æ ¹æ®æœ€å¤§å’Œæœ€å°scale windowï¼Œ è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªscale window listï¼ŒåŒ…å«å¤šä¸ªæ¡£ä½çš„scale windowã€‚

scale window 1ä¸ºéšè—çª—å£ï¼Œå…¶ä¸‹ä¸€æ¡£scale windowä¸º min scale window 20ã€‚

é’ˆå¯¹æ¨¡å‹è®­ç»ƒè¿‡ç¨‹loss scaleå˜åŒ–è¶‹åŠ¿ï¼Œè®¾è®¡ä¸¤ç§æ£€æµ‹æœºåˆ¶ï¼š

scale windowä¸Šè°ƒæ£€æµ‹æœºåˆ¶ï¼šè®­ç»ƒå¼€å§‹åˆå§‹ä½¿ç”¨ç¬¬ä¸€æ¡£scale window 20è¿›è¡Œè®­ç»ƒï¼Œæ–°å¢ä¸€ä¸ªä¸Šè°ƒè®¡æ•°growth_numï¼Œåˆå§‹ä¸º0ï¼Œæ¯æ¬¡ä¸Šè°ƒloss scaleæ—¶ï¼Œè®¡æ•°+1ï¼›æ¯ä¸Šè°ƒä¸‰æ¬¡loss scale (ä¸Šè°ƒè®¡æ•°ä¸º3æ—¶)ï¼Œçª—å£éšä¹‹ä¸Šè°ƒï¼ŒåŒæ—¶é‡ç½®ä¸Šè°ƒè®¡æ•°ï¼Œç›´åˆ°è¾¾åˆ°æœ€å¤§çª—å£ï¼›

scale windowä¸‹è°ƒæ£€æµ‹æœºåˆ¶ï¼šæ–°å¢ä¸€ä¸ªä¸‹è°ƒè®¡æ•°down_numï¼Œåˆå§‹ä¸º0ï¼Œæ¯æ¬¡ä¸‹è°ƒloss scaleæ—¶ï¼Œè®¡æ•°+1ï¼Œå‡ºç°è¿ç»­ä¸‰æ¬¡loss scaleä¸‹é™ (è‹¥ä¸­é—´å‡ºç°loss scaleä¸Šè°ƒï¼Œåˆ™é‡ç½®ä¸‹è°ƒè®¡æ•°)ï¼Œä¸”å½“å‰çª—å£ä¸ä¸ºmin scale windowï¼Œåˆ™å°†çª—å£è°ƒåˆ°1ï¼ŒåŒæ—¶é‡ç½®ä¸‹è°ƒè®¡æ•°ã€‚

![Adaptive_loss_scale_process](assets/Adaptive_loss_scale/Adaptive_loss_scale_process.png)

### ä½¿ç”¨ç¤ºä¾‹

ä½¿ç”¨æ–¹æ³•ä¸Mindsporeä¸­æ”¯æŒçš„dynamic loss scalingå’Œfixed loss scaleç±»ä¼¼ï¼Œæ–°å¢ç”¨æˆ·æŒ‡å®šçš„è¶…å‚max_scale_windowå’Œmin_scale_window

Mindformersç”¨æ³•:

```python
import numpy as np
from mindspore.dataset import GeneratorDataset
from mindspore.nn import Momentum
from mindformers import Trainer, TrainingArguments, AutoModel
from mindformers import init_context, ContextConfig
from mindformers.wrapper import MFTrainOneStepCell, AdaptiveLossScaleUpdateCell


def context_init():
    """init context for mindspore."""
    context_config = ContextConfig(mode=0, device_target="Ascend", device_id=0)
    rank_id, device_num = init_context(use_parallel=False, context_config=context_config)


def generator():
    """text dataset generator."""
    seq_len = 1025
    input_ids = np.random.randint(low=0, high=15, size=(seq_len,)).astype(np.int32)
    for _ in range(512):
        yield input_ids

# ç¯å¢ƒåˆå§‹åŒ–
context_init()
# è‡ªå®šä¹‰è®­ç»ƒè¶…å‚æ•°
training_args = TrainingArguments(num_train_epochs=3, batch_size=2, learning_rate=0.001,
                                  warmup_steps=1000, sink_mode=True)
# è‡ªå®šä¹‰æ¨¡å‹
pangu_model = AutoModel.from_pretrained("pangualpha_2_6b")
opt = Momentum(learning_rate=0.1, momentum=0.9,
               params=pangu_model.trainable_params(),)
manager = AdaptiveLossScaleUpdateCell(1, 2, 20, 1000, 20)
train_network = MFTrainOneStepCell(pangu_model, opt, scale_sense=manager)
train_network.set_train()
# è‡ªå®šä¹‰æ•°æ®é›†
dataset = GeneratorDataset(generator, column_names=["input_ids"])
train_dataset = dataset.batch(batch_size=4)
eval_dataset = dataset.batch(batch_size=4)
# å®šä¹‰æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼Œä¼ å…¥è‡ªå®šä¹‰æ¨¡å‹ã€æ•°æ®é›†ã€è¶…å‚æ•°
text_generation = Trainer(task='text_generation', model_name='pangualpha_2_6b',
                          wrapper=train_network, args=training_args,
                          train_dataset=train_dataset, eval_dataset=eval_dataset)
```

æ¨¡å‹è®­ç»ƒyamlä¸­è®¾ç½®æ–¹å¼runner_configä¸­å£°æ˜ä½¿ç”¨adaptive loss scaling

```yaml
# runner
runner_config:
  epochs: 3
  batch_size: 4
  sink_mode: True
  sink_size: 2
runner_wrapper:
  type: MFTrainOneStepCell
  scale_sense:
    type: AdaptiveLossScaleUpdateCell
    loss_scale_value: 4294967296
    scale_factor: 2
    scale_window: 20
    max_scale_window: 1000
    min_scale_window: 20
  use_clip_grad: True
```

## Lazy Inline

### Lazy Inline åŸºæœ¬ä»‹ç»

ç¥ç»ç½‘ç»œæ¨¡å‹çš„ç¼–è¯‘è¿‡ç¨‹å¾€å¾€é‡‡ç”¨é»˜è®¤inlineçš„æ–¹å¼ï¼ŒæŠŠå±‚çº§çš„ä»£ç è¡¨è¾¾æœ€ç»ˆå±•å¼€æˆä¸€å¼ æ‰å¹³çš„è®¡ç®—å›¾ï¼Œä¸€æ–¹é¢å¯»æ±‚æœ€å¤§çš„ç¼–è¯‘ä¼˜åŒ–æœºä¼šï¼Œå¦ä¸€æ–¹é¢ä¹Ÿå¯ä»¥ç®€åŒ–è‡ªåŠ¨å¾®åˆ†ä»¥åŠæ‰§è¡Œçš„é€»è¾‘ã€‚inlineåå½¢æˆçš„è®¡ç®—å›¾åŒ…å«äº†æ‰€æœ‰çš„è®¡ç®—èŠ‚ç‚¹ï¼Œå¯ä»¥åœ¨æ›´å¤§çš„èŒƒå›´å†…è¿›è¡Œä¼˜åŒ–ï¼Œæ¯”å¦‚å¸¸é‡æŠ˜å ã€èŠ‚ç‚¹èåˆã€å¹¶è¡Œåˆ†æç­‰ï¼Œä¹Ÿå¯ä»¥æ›´å¥½åœ°å®ç°å†…å­˜åˆ†é…ï¼Œå‡å°‘å†…å­˜ç”³è¯·å’Œæ€§èƒ½å¼€é”€ã€‚è™½ç„¶inlineä¼˜åŒ–å¯¹äºè¿è¡ŒæœŸæ€§èƒ½æå‡å¸®åŠ©éå¸¸å¤§ï¼Œä½†è¿‡åº¦inlineä¹Ÿå¸¦æ¥äº†ç¼–è¯‘æœŸçš„è´Ÿæ‹…ã€‚ä¾‹å¦‚éšç€è®¡ç®—å›¾èŠ‚ç‚¹æ•°é‡è†¨èƒ€ï¼Œæ‰§è¡Œpassçš„è€—æ—¶ä¹Ÿåœ¨æ€¥å‰§å¢é•¿ã€‚

ä¸ºäº†å‡è½»inlineå¯¹ç¼–è¯‘æ€§èƒ½å¸¦æ¥çš„æŸè€—ï¼Œå¯¹äºé‡å¤è°ƒç”¨ç›¸åŒè®¡ç®—å•å…ƒçš„åœºæ™¯ï¼ˆå…¸å‹çš„åœºæ™¯æ˜¯åœ¨forå¾ªç¯ä¸­è°ƒç”¨åŒä¸€ä¸ªCellç±»çš„ä¸åŒå®ä¾‹ï¼‰ï¼Œæˆ‘ä»¬æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡çš„æ–¹å¼è°ƒç”¨Mindsporeçš„`lazy_inline`æ–¹æ³•æ¥å‡å°‘ç¼–è¯‘æ—¶é—´ã€‚

mindsporeå®ç°å‚è€ƒï¼š

[mindspore.lazy_inline](https://www.mindspore.cn/docs/zh-CN/r2.2/api_python/mindspore/mindspore.lazy_inline.html)

å…·ä½“åŸç†å‚è€ƒï¼š

[Lazy inline-ç™¾äº¿/åƒäº¿å¤§è¯­è¨€æ¨¡å‹é™æ€å›¾ç¼–è¯‘æ€§èƒ½æå‡Nå€çš„çš„æ€è·¯å’Œå®è·µ](https://www.mindspore.cn/news/newschildren?id=2657)

å½“å¯ç”¨`pipeline`å¹¶è¡Œæ—¶ï¼Œæ¨¡å‹è§„æ¨¡å’ŒèŠ‚ç‚¹æ•°åŠ å¤§ï¼Œå¦‚æœåŸæ¥å›¾çš„è§„æ¨¡æ˜¯`O`ï¼Œé‚£å¼€å¯`pipeline`å¹¶è¡Œï¼Œå•èŠ‚ç‚¹å›¾çš„è§„æ¨¡å˜ä¸º`(O/X)*Y`ï¼Œå…¶ä¸­`X`ä¸º`pipeline`çš„`stage`æ•°é‡ï¼Œ`Y`ä¸º`microbatch`çš„æ•°é‡ï¼Œåœ¨å®é™…çš„é…ç½®è¿‡ç¨‹ä¸­ï¼Œ`Y`æ¯”`X`å¤§å¾ˆå¤šï¼Œæ¯”å¦‚`X`ä¸º`16`ï¼Œè€Œ`Y`ä¸€èˆ¬è®¾ç½®åˆ°`64-192`ï¼Œè¿™æ ·å¼€å¯æµæ°´çº¿å¹¶è¡Œåï¼Œå›¾ç¼–è¯‘çš„è§„æ¨¡ä¼šè¿›ä¸€æ­¥å¢å¤§åˆ°åŸæ¥çš„`4-12`å€ã€‚

å¼€å¯æµæ°´çº¿å¹¶è¡Œï¼Œå„ä¸ª`micro batch`çš„`Layer`å±‚æ˜¯å®Œå…¨ä¸€æ ·çš„ã€‚æŒ‰ç…§`micro batch`ä¸ºè¾¹ç•Œï¼Œä¿ç•™`micro batch`çš„å­å›¾ç»“æ„ï¼Œé‚£ä¹ˆç†è®ºä¸Šç¼–è¯‘æ—¶é—´å¯ä»¥å˜ä¸ºåŸæ¥çš„`Y`åˆ†ä¹‹ä¸€ã€‚å…·ä½“åšæ³•ä¸ºåœ¨ç›¸å…³çš„`layer`ç±»ä¸Šæ‰“æ ‡è®°ï¼Œç»™ç¼–è¯‘å™¨æç¤ºï¼Œæ‰“ä¸Šæ ‡è®°çš„`layer`ä¸è®ºæ˜¯åœ¨å¾ªç¯ä½“å†…è¢«è°ƒç”¨ï¼Œè¿˜æ˜¯å…¶ä»–æ–¹å¼è¢«è°ƒç”¨ï¼Œåœ¨ç¼–è¯‘æœŸé—´éƒ½ä¸å†…è”ï¼Œç›´åˆ°æ‰§è¡Œå‰ï¼Œæ‰è¿›è¡Œå†…è”å±•å¼€ï¼Œä»è€Œå¤§å¹…æå‡äº†ç¼–è¯‘æ€§èƒ½ã€‚

### ä½¿ç”¨è¯´æ˜

**æ³¨ï¼šæ­¤ç‰¹æ€§åœ¨mindsporeâ‰¥2.2.0ä¸‹é€‚ç”¨ã€‚é€šå¸¸åœ¨`pipeline`å¹¶è¡Œæ—¶ä½¿ç”¨ä»¥æé«˜ç¼–è¯‘æ€§èƒ½ã€‚**

å¯¹äºæ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡åœ¨`__init__`å‡½æ•°ä¸Šæ³¨å†Œè£…é¥°å™¨`lazy_inline`ï¼ŒæŒ‡å®šä¸€ä¸ªcellæ˜¯å¯å¤ç”¨çš„ã€‚æ­¤è£…é¥°å™¨ä¼šæŒ‰ç…§`attrs`çš„å€¼å»æ·»åŠ `__init__`å‡½æ•°å¯¹åº”çš„å…¥å‚ä½œä¸ºcellçš„å±æ€§ã€‚ç¤ºä¾‹å¦‚ä¸‹ï¼š

```python
from mindformers.models.utils import lazy_inline
from mindformers.modules.transformer.op_parallel_config import _check_config
from mindformers.models import PreTrainedModel
from mindformers.models.llama.llama_config import LlamaConfig

class Baichuan7BV2ForCausalLM(PreTrainedModel):
    #æ³¨å†Œè£…é¥°å™¨
    @lazy_inline
    def __init__(self, config: LlamaConfig = None):
        super(Baichuan7BV2ForCausalLM, self).__init__(config, auto_prefix=True)
        _check_config(config.parallel_config)
        self.ignore_token_id = config.ignore_token_id
```

åœ¨pipelineå¹¶è¡Œæ¨¡å¼ä¸‹å°†é»˜è®¤ä½¿èƒ½lazy inlineç‰¹æ€§ï¼Œå¯é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡`ENABLE_LAZY_INLINE=0`å…³é—­ï¼›  
åœ¨épipelineå¹¶è¡Œæ¨¡å¼ä¸‹ï¼Œlazy inlineç‰¹æ€§é»˜è®¤ä¸ç”Ÿæ•ˆï¼Œå¦‚éœ€åœ¨épipelineå¹¶è¡Œæ¨¡å¼ä¸‹ä½¿èƒ½lazy inlineç‰¹æ€§ï¼Œå¯ä»¥é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡ `ENABLE_LAZY_INLINE_NO_PIPELINE=1` ï¼Œå¹¶å¼€å¯æ¢¯åº¦ç´¯ç§¯åŠŸèƒ½ä»¥å¯ç”¨ï¼›
è¯¦æƒ…è¯·å‚è€ƒ[ç¯å¢ƒå˜é‡ä½¿ç”¨è¯´æ˜](../readthedocs/source_zh_cn/docs/practice/Environment.md)

## MoEå†·çƒ­é—¨ä¸“å®¶ä¼˜åŒ–

åœ¨MoEå¤§æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¸¸è§çš„TopK Routerç®—æ³•ä¼šå¯¼è‡´Tokenåˆ†å‘ä¸å‡åŒ€ï¼Œå­˜åœ¨Routerç»™å°‘æ•°çƒ­é—¨ä¸“å®¶åˆ†é…å¤§é‡Tokenï¼Œå¤šæ•°å†·é—¨ä¸“å®¶åˆ†é…å°‘é‡Tokençš„æƒ…å†µã€‚ä¸“å®¶å—é™äºä¸“å®¶å®¹é‡ï¼Œä¼šå°†è¶…è¿‡ä¸“å®¶å®¹é‡çš„Tokenä¸¢å¼ƒï¼Œä¸è¶³ä¸“å®¶å®¹é‡çš„Paddingã€‚æ‰€ä»¥æå‡ºçƒ­é—¨ä¸“å®¶å®¹é‡å’Œå†·é—¨ä¸“å®¶å®¹é‡ï¼Œå‡å°‘çƒ­é—¨ä¸“å®¶Tokenä¸¢å¼ƒå’Œå†·é—¨ä¸“å®¶Paddingã€‚åŒæ—¶å°†çƒ­é—¨ä¸“å®¶è¿ç§»åˆ°æ‰€æœ‰è®­ç»ƒè®¾å¤‡ä¸Šï¼Œå‡å°‘å…¶Tokençš„AllToAllä¼ è¾“ï¼Œæ‰€æœ‰è®¾å¤‡ä¸Šçš„çƒ­é—¨ä¸“å®¶å‰¯æœ¬é‡‡ç”¨æ•°æ®å¹¶è¡Œï¼Œå¹¶é€šè¿‡AllReduceåŒæ­¥å‚æ•°ã€‚

MindFormersé…ç½®æ–‡ä»¶ä¸­çš„`MoE_config`æ–°å¢ä»¥ä¸‹é…ç½®é¡¹ï¼š

`enable_cold_hot_expert`ï¼šé»˜è®¤ä¸ºFalseï¼Œè®¾ç½®ä¸ºTrueå¯å¼€å¯MoEå†·çƒ­é—¨ä¸“å®¶ä¼˜åŒ–ï¼›

`hot_expert_num`ï¼šé»˜è®¤ä¸º0ï¼Œå½“å¼€å¯enable_cold_hot_expertæ—¶éœ€è¦é…ç½®è¿ç§»çš„çƒ­é—¨ä¸“å®¶æ•°é‡ï¼›

`cold_token_percent`ï¼šé»˜è®¤ä¸º1.0ï¼Œå–å€¼èŒƒå›´(0.0, 1.0]ï¼Œå†·é—¨ä¸“å®¶å®¹é‡å› å­ä¸ºcapacity_factor * cold_token_percentï¼Œçƒ­é—¨ä¸“å®¶å®¹é‡å› å­ä»ä¸ºcapacity_factorï¼›

`moe_module_name`ï¼šæœ¬ä¼˜åŒ–æä¾›è‡ªåŠ¨è°ƒæ•´çƒ­é—¨ä¸“å®¶å‰¯æœ¬åŠŸèƒ½ï¼Œéœ€è¦æŒ‡æ˜MoEæ¨¡å‹è·¯å¾„ã€‚

```yaml
moe_config:
  expert_num: 8
  capacity_factor: 2.0
  enable_cold_hot_expert: True
  hot_expert_num: 1
  cold_token_percent: 0.7
  moe_module_name: "network._backbone.backbone.blocks"
```

åœ¨æ¨¡å‹æ–¹é¢ï¼Œéœ€è¦åœ¨ä¼ å…¥moe_configå‰é…ç½®æ¯å±‚MoEçš„cur_layer:

```python
if config.moe_config.save_token_distribution or config.moe_config.enable_cold_hot_expert:
    moe_config = [copy.deepcopy(config.moe_config) for i in range(config.num_layers)]
    for i in range(config.num_layers):
        moe_config[i].cur_layer = i

    self.blocks = nn.CellList()
    for i in range(config.num_layers):
        block = GPTTransformerDecoderLayer(
            ......
            moe_config=moe_config if not (config.moe_config.save_token_distribution or
                                          config.moe_config.enable_cold_hot_expert) else moe_config[i],
            ......
        )
```

åœ¨è®­ç»ƒçš„å‰æœŸï¼Œçƒ­é—¨Expertä¼šå‘ç”Ÿå˜åŒ–ï¼Œéœ€è¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´Expertå‰¯æœ¬æ‰€ä»£è¡¨çš„Expertã€‚ä½¿ç”¨æœ¬ä¼˜åŒ–éœ€è¦åœ¨callbacksä¸­ä¼ å…¥ColdHotExpertMonitorï¼ŒColdHotExpertMonitorä¸­éœ€è¦ä¼ å…¥ä»¥ä¸‹å‚æ•°:

`moe_config`ï¼šconfig.moe_config

`hidden_size`ï¼šconfig.model.model_config.hidden_size

`ffn_hidden_size`ï¼šconfig.model.model_config.ffn_hidden_size ï¼Œå¯¹äºmodel_configä¸­æ²¡æœ‰é…ç½®ffn_hidden_sizeçš„æ¨¡å‹ï¼Œå¯ä»¥æ·»åŠ è¯¥é…ç½®æˆ–ä¿®æ”¹æ­¤å¤„ä¼ å…¥ä»£ç 

`expert_parallel`ï¼šconfig.parallel_config.expert_parallel

`model_parallel`ï¼šconfig.parallel_config.model_parallel

`save_checkpoint_steps`ï¼šCheckpointMonitorä¸­é…ç½®çš„'save_checkpoint_steps'

```python
from mindformers.core.callback.callback import ColdHotExpertMonitor

if config.moe_config.enable_cold_hot_expert:
    save_checkpoint_steps = -1
    for callback in config.callbacks:
        if callback['type'] == 'CheckpointMonitor':
            save_checkpoint_steps = callback['save_checkpoint_steps']
    cold_hot_monitor = ColdHotExpertMonitor(
        moe_config=config.moe_config,
        hidden_size=config.model.model_config.hidden_size,
        ffn_hidden_size=config.model.model_config.ffn_hidden_size,
        expert_parallel=config.parallel_config.expert_parallel,
        model_parallel=config.parallel_config.model_parallel,
        save_checkpoint_steps=save_checkpoint_steps)
    # ColdHotExpertMonitor needs to be placed before CheckpointMonitor
    callbacks.insert(1, cold_hot_monitor)
```

éœ€è¦æ³¨æ„ï¼šåœ¨callbacksä¸­ColdHotExpertMonitoréœ€è¦æ”¾ç½®åœ¨CheckpointMonitorå‰é¢ï¼Œå…ˆæ‰§è¡ŒColdHotExpertMonitorï¼Œä¸ç„¶å‰¯æœ¬çš„æƒé‡è¿˜æ²¡å¤åˆ¶å›å…¶ä»£è¡¨çš„Expertå°±ä¿å­˜ckptï¼Œå¯¼è‡´ckptä¿å­˜çš„Expertæƒé‡å¹¶éæœ€æ–°è®­ç»ƒç»“æœã€‚
