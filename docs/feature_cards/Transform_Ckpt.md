# æƒé‡è½¬æ¢

> ## ğŸš¨ å¼ƒç”¨è¯´æ˜
>
> æœ¬æ–‡æ¡£å·²è¿‡æ—¶ï¼Œä¸å†è¿›è¡Œç»´æŠ¤ï¼Œå¹¶å°†åœ¨ *1.6.0* ç‰ˆæœ¬ä¸‹æ¶ï¼Œå…¶ä¸­å¯èƒ½åŒ…å«è¿‡æ—¶çš„ä¿¡æ¯æˆ–å·²è¢«æ›´æ–°çš„åŠŸèƒ½æ›¿ä»£ã€‚å»ºè®®å‚è€ƒæœ€æ–°çš„ **[å®˜æ–¹æ–‡æ¡£](https://www.mindspore.cn/mindformers/docs/zh-CN/r1.5.0/index.html)** ï¼Œä»¥è·å–å‡†ç¡®çš„ä¿¡æ¯ã€‚
>
> å¦‚æœæ‚¨ä»éœ€ä½¿ç”¨æœ¬æ–‡æ¡£ä¸­çš„å†…å®¹ï¼Œè¯·ä»”ç»†æ ¸å¯¹å…¶é€‚ç”¨æ€§ï¼Œå¹¶ç»“åˆæœ€æ–°ç‰ˆæœ¬çš„ç›¸å…³èµ„æºè¿›è¡ŒéªŒè¯ã€‚
>
> å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ **[ç¤¾åŒºIssue](https://gitee.com/mindspore/mindformers/issues/new)** æäº¤åé¦ˆã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£ä¸æ”¯æŒï¼

## æ¦‚è¿°

ç›®å‰åˆ†å¸ƒå¼è®­ç»ƒ/æ¨ç†ï¼Œå½“é¢„è®­ç»ƒæƒé‡ä¸åˆ†å¸ƒå¼ç­–ç•¥ä¸åŒ¹é…æ—¶ï¼Œéœ€è¦**å°†é¢„è®­ç»ƒæƒé‡è½¬æ¢ä¸ºå¯¹åº”åˆ†å¸ƒå¼ç­–ç•¥çš„æƒé‡**ï¼Œä¸»è¦é€‚ç”¨åœºæ™¯å¦‚ä¸‹ï¼š

- åŸºäºå®Œæ•´æƒé‡çš„åˆ†å¸ƒå¼è®­ç»ƒ/æ¨ç†ï¼šéœ€è¦å°†å®Œæ•´æƒé‡è½¬æ¢ä¸ºå¤šå¡åˆ†å¸ƒå¼æƒé‡ã€‚
- ä¿®æ”¹åˆ†å¸ƒå¼ç­–ç•¥è¿›è¡Œè®­ç»ƒ/æ¨ç†ï¼šéœ€è¦å°†æƒé‡è½¬æ¢ä¸ºå¯¹åº”åˆ†å¸ƒå¼ç­–ç•¥çš„æƒé‡ã€‚
- åŸºäºè®­ç»ƒå®Œçš„åˆ†å¸ƒå¼æƒé‡è¿›è¡Œå•å¡æ¨ç†ï¼šéœ€è¦å°†åˆ†å¸ƒå¼æƒé‡åˆå¹¶ä¸ºå®Œæ•´æƒé‡ã€‚

## è‡ªåŠ¨æƒé‡è½¬æ¢

Mindformeræ”¯æŒ**è‡ªåŠ¨æƒé‡è½¬æ¢**ï¼Œå½“é¢„è®­ç»ƒæƒé‡ä¸åˆ†å¸ƒå¼ç­–ç•¥ä¸åŒ¹é…æ—¶ï¼Œå°†`auto_trans_ckpt`å¼€å…³ç½®ä¸ºTrueï¼Œå¹¶é…ç½®æƒé‡è½¬æ¢ç›¸å…³å‚æ•°ï¼Œç”±Mindformerè‡ªåŠ¨å®Œæˆæƒé‡è½¬æ¢ï¼Œç›¸æ¯”[ç¦»çº¿æƒé‡è½¬æ¢](#ç¦»çº¿æƒé‡è½¬æ¢)æå‡äº†ä»»åŠ¡å¯åŠ¨æ•ˆç‡ã€‚

**è‡ªåŠ¨æƒé‡è½¬æ¢**ç›¸å…³å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š

| å‚æ•°åç§°              | æè¿°                                                         |
| --------------------- | ------------------------------------------------------------ |
| load_checkpoint       | é¢„åŠ è½½æƒé‡çš„ç»å¯¹è·¯å¾„æˆ–æ–‡ä»¶å¤¹è·¯å¾„ã€‚<br />- å¦‚æœæ˜¯å®Œæ•´æƒé‡ï¼Œåˆ™å¡«å†™ç»å¯¹è·¯å¾„ï¼›<br />- å¦‚æœæ˜¯åˆ†å¸ƒå¼æƒé‡ï¼Œåˆ™å¡«å†™æ–‡ä»¶å¤¹è·¯å¾„ï¼Œåˆ†å¸ƒå¼æƒé‡é¡»æŒ‰ç…§`model_dir/rank_x/xxx.ckpt`æ ¼å¼å­˜æ”¾ï¼Œæ–‡ä»¶å¤¹è·¯å¾„å¡«å†™ä¸º`model_dir`ã€‚**å¦‚æœrank_xæ–‡ä»¶å¤¹ä¸‹å­˜åœ¨å¤šä¸ªckptï¼Œå°†ä¼šä½¿ç”¨æ–‡ä»¶åé»˜è®¤æ’åºæœ€åçš„ckptæ–‡ä»¶ç”¨äºè½¬æ¢ã€‚** |
| src_strategy          | é¢„åŠ è½½æƒé‡å¯¹åº”çš„åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶è·¯å¾„ã€‚<br />- å¦‚æœé¢„åŠ è½½æƒé‡æ˜¯å®Œæ•´æƒé‡ï¼Œåˆ™**ä¸å¡«å†™**ï¼›<br />- å¦‚æœé¢„åŠ è½½æƒé‡æ˜¯åˆ†å¸ƒå¼æƒé‡ï¼Œä¸”é¢„åŠ è½½æƒé‡ä¿å­˜æ—¶ä½¿ç”¨äº†æµæ°´çº¿å¹¶è¡Œï¼Œåˆ™å¡«å†™**åˆå¹¶çš„ç­–ç•¥æ–‡ä»¶è·¯å¾„**æˆ–**åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶å¤¹è·¯å¾„**ï¼›<br />- å¦‚æœé¢„åŠ è½½æƒé‡æ˜¯åˆ†å¸ƒå¼æƒé‡ï¼Œä¸”é¢„åŠ è½½æƒé‡ä¿å­˜æ—¶æœªä½¿ç”¨æµæ°´çº¿å¹¶è¡Œï¼Œåˆ™å¡«å†™ä»»ä¸€**ckpt_strategy_rank_x.ckpt**è·¯å¾„ï¼› |
| auto_trans_ckpt       | æƒé‡è‡ªåŠ¨è½¬æ¢å¼€å…³ï¼Œä¸ºTrueå¼€å¯ï¼Œé»˜è®¤Falseã€‚                    |
| transform_process_num | æƒé‡è‡ªåŠ¨è½¬æ¢ä½¿ç”¨çš„è¿›ç¨‹æ•°ï¼Œé»˜è®¤ä¸º1ã€‚<br />- å¦‚æœtransform_process_num = 1ï¼Œä½¿ç”¨**å•è¿›ç¨‹è½¬æ¢**ï¼Œè½¬æ¢æ—¶åªæœ‰rank_0è´Ÿè´£æƒé‡è½¬æ¢ï¼Œå…¶å®ƒè¿›ç¨‹ç­‰å¾…rank_0è½¬æ¢ç»“æŸï¼›<br />- å¦‚æœtransform_process_num > 1ï¼Œä½¿ç”¨**å¤šè¿›ç¨‹è½¬æ¢**ï¼Œæ¯”å¦‚8å¡ä»»åŠ¡ï¼Œtransform_process_num=2æ—¶ï¼Œè½¬æ¢æ—¶rank_0è´Ÿè´£rank_0/1/2/3åˆ‡ç‰‡æƒé‡çš„è½¬æ¢ï¼Œrank_4è´Ÿè´£rank_4/5/6/7åˆ‡ç‰‡æƒé‡çš„è½¬æ¢ï¼Œå…¶å®ƒè¿›ç¨‹ç­‰å¾…rank_0/4è½¬æ¢ç»“æŸï¼›<br />**æ³¨æ„**ï¼š<br />â‘  transform_process_numè¶Šå¤§ï¼Œè½¬æ¢æ—¶é—´è¶ŠçŸ­ï¼Œ**è½¬æ¢æ‰€å ç”¨çš„hostå†…å­˜è¶Šå¤§**ï¼›å½“å‡ºç°hostä¾§å†…å­˜ä¸è¶³æ—¶ï¼Œéœ€è¦å‡å°‘transform_process_numã€‚<br />â‘¡ transform_process_numå¿…é¡»èƒ½å¤Ÿæ•´é™¤NPUå¡æ•°ï¼Œä¸”æœ€å¤§ä¸å¾—è¶…è¿‡NPUå¡æ•°ã€‚ |
| transform_by_rank     | æ˜¯å¦ä½¿ç”¨mindspore.transform_checkpoint_by_rankæ¥å£åšæƒé‡è½¬æ¢ã€‚<br />transform_process_num > 1æ—¶ï¼Œè‡ªåŠ¨è®¾ç½®ä¸º`True`ï¼›<br />transform_process_num = 1æ—¶ï¼Œå¦‚æœç›®æ ‡æƒé‡ä¸ºåˆ†å¸ƒå¼æƒé‡ï¼Œåˆ™å¾ªç¯è°ƒç”¨mindspore.transform_checkpoint_by_rankä¸²è¡Œè½¬æ¢æ¯ä¸€ä¸ªrankåˆ‡ç‰‡æƒé‡ã€‚<br />transform_process_num = 1æ—¶ï¼Œå¦‚æœç›®æ ‡æƒé‡ä¸ºå®Œæ•´æƒé‡ï¼Œåˆ™è‡ªåŠ¨è®¾ç½®ä¸º`False`ï¼Œä½¿ç”¨mindspore.transform_checkpointsæ¥å£åšæƒé‡è½¬æ¢ï¼› |

### é€‚ç”¨åœºæ™¯

Mindformerçš„**è‡ªåŠ¨æƒé‡è½¬æ¢**ç‰¹æ€§é€‚ç”¨äºä»¥ä¸‹ä¸‰å¤§ä»»åŠ¡åœºæ™¯ï¼ŒåŸºæœ¬å¯ä»¥æ»¡è¶³å„ç§æƒé‡è½¬æ¢éœ€æ±‚ï¼š

- **å®Œæ•´æƒé‡è½¬æ¢ä¸ºåˆ†å¸ƒå¼æƒé‡ï¼Œå¯åŠ¨åˆ†å¸ƒå¼ä»»åŠ¡**
- **ä¿®æ”¹åˆ†å¸ƒå¼ç­–ç•¥ï¼Œåˆ†å¸ƒå¼æƒé‡è½¬æ¢ä¸ºå…¶ä»–åˆ†å¸ƒå¼æƒé‡ï¼Œå¯åŠ¨åˆ†å¸ƒå¼ä»»åŠ¡**
- **åˆ†å¸ƒå¼æƒé‡åˆå¹¶ä¸ºå®Œæ•´æƒé‡ï¼Œå¯åŠ¨å•å¡ä»»åŠ¡**

å…·ä½“æ“ä½œå¯ä»¥å‚è€ƒ[è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹](#è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹)ç« èŠ‚ã€‚

### æ³¨æ„äº‹é¡¹

å¼€å¯**è‡ªåŠ¨æƒé‡è½¬æ¢**åï¼Œä»»åŠ¡é¦–å…ˆä¼šåˆ é™¤`output`ä¸‹æ—§çš„`strategy`å’Œ`transformed_checkpoint`æ–‡ä»¶å¤¹ï¼Œç„¶åä¿å­˜å½“å‰ä»»åŠ¡çš„è¾“å‡ºç»“æœã€‚å› æ­¤è½¬æ¢ä»»åŠ¡ç»“æŸåï¼Œå»ºè®®**å°†strategyå’Œtransformed_checkpointä¿å­˜åˆ°è‡ªå®šä¹‰æ–‡ä»¶å¤¹ï¼Œé¿å…è¯¯åˆ **ã€‚

### è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹

æ¡ˆä¾‹ä¸»è¦ä¸ºæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æƒé‡è‡ªåŠ¨è½¬æ¢ï¼ŒåŸºäº2å±‚çš„llama-7bæƒé‡è¿›è¡Œè½¬æ¢æ¼”ç¤ºï¼ŒåŒæ—¶æä¾›äº†å·²è½¬ä¸ºmindrecordæ ¼å¼çš„WikiText2æ•°æ®é›†ã€‚

#### å‰æœŸå‡†å¤‡

- æƒé‡ï¼šä¸‹è½½ä½¿ç”¨2å±‚çš„[llama-7bæƒé‡](https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/MindFormers/features/transform_checkpoint/llama_7b_2layer/llama_7b.ckpt)ã€‚

![checkpoint](assets/Transform_Ckpt/checkpoint.png)

- æ•°æ®é›†: å‚ç…§[Llamaå¯¹Wikitext-2](../model_cards/llama2.md#æ•°æ®åŠæƒé‡å‡†å¤‡)æ•°æ®å¤„ç†ï¼Œè®²wikitext-2æ•°æ®é›†å¤„ç†æˆåºåˆ—é•¿åº¦ä¸º512çš„mindrecordæ•°æ®é›†ã€‚

![wiki_dataset](assets/Transform_Ckpt/wiki_dataset.png)

- è¯è¡¨ï¼šä¸‹è½½llama-7bçš„[tokenizer.model](https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/llama/tokenizer.model)ã€‚

![tokenizer_model](assets/Transform_Ckpt/tokenizer_model.png)

- rank_table_fileï¼šè¿è¡Œä»¥ä¸‹å‘½ä»¤è·å–8å¡ã€4å¡ã€2å¡å¯¹åº”çš„rank_table_fileã€‚

  ```bash
  # ç”Ÿæˆ8å¡çš„rank_table_fileï¼šè‡ªè¡Œé‡å‘½åä¸ºrank_table_8.jsonï¼ŒåŸæ–‡ä»¶ä¸ºhccl_xxx.json
  python mindformers/tools/hccl_tools.py --device_num [0,8]
  mv hccl*.json rank_table_8.json

  # ç”Ÿæˆ4å¡çš„rank_table_fileï¼šè‡ªè¡Œé‡å‘½åä¸ºrank_table_4_id04.jsonï¼ŒåŸæ–‡ä»¶ä¸ºhccl_xxx.json
  python mindformers/tools/hccl_tools.py --device_num [0,4]
  mv hccl*.json rank_table_4_id04.json

  # ç”Ÿæˆ2å¡çš„rank_table_fileï¼šè‡ªè¡Œé‡å‘½åä¸ºrank_table_2_id02.jsonï¼ŒåŸæ–‡ä»¶ä¸ºhccl_xxx.json
  python mindformers/tools/hccl_tools.py --device_num [0,2]
  mv hccl*.json rank_table_2_id02.json
  ```

#### è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹ä¸€ï¼šå®Œæ•´æƒé‡è½¬æ¢ä¸ºåˆ†å¸ƒå¼æƒé‡

**æ¡ˆä¾‹æè¿°**ï¼šä½¿ç”¨[å‰æœŸå‡†å¤‡](#è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹)ä¸‹è½½çš„å®Œæ•´æƒé‡ï¼Œè½¬æ¢ä¸º8å¡åˆ†å¸ƒå¼æƒé‡è¿›è¡Œè®­ç»ƒã€‚

- **å•è¿›ç¨‹è½¬æ¢**

â‘  é…ç½®å‚æ•°

```yaml
# configs/llama/run_llama_7b.yaml
# é…ç½®é¢„è®­ç»ƒæƒé‡è·¯å¾„ï¼Œå¡«å†™æƒé‡æ–‡ä»¶è·¯å¾„
load_checkpoint: "/worker/llama_7b_2layer/rank_0/llama_7b.ckpt"

# æ‰“å¼€æƒé‡è‡ªåŠ¨è½¬æ¢å¼€å…³
auto_trans_ckpt: True

# é…ç½®æ•°æ®é›†
train_dataset: &train_dataset
  data_loader:
    type: MindDataset
    dataset_dir: "/worker/dataset/wikitext_512/"
    shuffle: True

# é…ç½®8å¡åˆ†å¸ƒå¼ç­–ç•¥ï¼Œä»¥dp=2,mp=2,pp=2ä¸ºä¾‹
parallel_config:
  data_parallel: 2
  model_parallel: 2
  pipeline_stage: 2
  micro_batch_num: 2

# ä¿®æ”¹æ¨¡å‹é…ç½®
model:
  model_config:
    seq_length: 512
    num_layers: 2
```

â‘¡ å¯åŠ¨è®­ç»ƒ

```shell
cd scripts
bash run_distribute.sh ../rank_table_8.json ../configs/llama/run_llama_7b.yaml [0,8] train
```

â‘¢ æŸ¥çœ‹æƒé‡è½¬æ¢ç›¸å…³æ—¥å¿—

![auto_trans_single_1to8_log](assets/Transform_Ckpt/auto_trans_single_1to8_log.png)

â‘£ æŸ¥çœ‹è½¬æ¢ç”Ÿæˆçš„æ–‡ä»¶

**åˆ†å¸ƒå¼æƒé‡**ï¼šä¿å­˜åœ¨`output/transformed_checkpoint`æ–‡ä»¶å¤¹ä¸‹ã€‚

![auto_trans_single_1to8_transformed_ckpt](assets/Transform_Ckpt/auto_trans_single_1to8_transformed_ckpt.png)

**åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶**ï¼šä¿å­˜åœ¨`output/strategy`æ–‡ä»¶å¤¹ä¸‹ï¼Œç”±äºå¼€å¯äº†**æµæ°´çº¿å¹¶è¡Œ**ï¼Œæƒé‡è‡ªåŠ¨è½¬æ¢è¿‡ç¨‹ä¸­ä¼šå¯¹æ‰€æœ‰`ckpt_strategy_rank_x.ckpt`è¿›è¡Œåˆå¹¶ï¼Œå¾—åˆ°`merged_ckpt_strategy.ckpt`ã€‚è‹¥ä¸å¼€å¯æµæ°´çº¿å¹¶è¡Œï¼Œåˆ™ä¸ä¼šåˆå¹¶ã€‚

![auto_trans_single_1to8_strategy](assets/Transform_Ckpt/auto_trans_single_1to8_strategy.png)

- **å¤šè¿›ç¨‹è½¬æ¢**ï¼ˆå¯é€‰ï¼‰

â‘  é…ç½®å‚æ•°ï¼šåŸºäº**å•è¿›ç¨‹è½¬æ¢**çš„é…ç½®ï¼Œé¢å¤–é…ç½®`transform_process_num`å‚æ•°ã€‚

```bash
# è®¾ç½®å‚ä¸æƒé‡è½¬æ¢çš„è¿›ç¨‹æ•°é‡ä¸º2ï¼šç”±rank_0è´Ÿè´£rank_0/1/2/3åˆ‡ç‰‡æƒé‡è½¬æ¢ï¼Œrank_4è´Ÿè´£rank_4/5/6/7åˆ‡ç‰‡æƒé‡è½¬æ¢
transform_process_num: 2
```

â‘¡ å¯åŠ¨è®­ç»ƒï¼š

```bash
cd scripts
bash run_distribute.sh ../rank_table_8.json ../configs/llama/run_llama_7b.yaml [0,8] train
```

â‘¢ æŸ¥çœ‹æƒé‡è½¬æ¢ç›¸å…³æ—¥å¿—

- rank_0

  ![auto_trans_multi_1to8_log0](assets/Transform_Ckpt/auto_trans_multi_1to8_log0.png)

- rank_4

  ![auto_trans_multi_1to8_log1](assets/Transform_Ckpt/auto_trans_multi_1to8_log1.png)

â‘£ æŸ¥çœ‹è½¬æ¢ç”Ÿæˆçš„æ–‡ä»¶

**åˆ†å¸ƒå¼æƒé‡**ï¼šä¿å­˜åœ¨`output/transformed_checkpoint`æ–‡ä»¶å¤¹ä¸‹ã€‚

![auto_trans_multi_1to8_transformed_ckpt](assets/Transform_Ckpt/auto_trans_multi_1to8_transformed_ckpt.png)

**åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶**ï¼šä¿å­˜åœ¨`output/strategy`æ–‡ä»¶å¤¹ä¸‹ï¼Œç”±äºå¼€å¯äº†**æµæ°´çº¿å¹¶è¡Œ**ï¼Œæƒé‡è‡ªåŠ¨è½¬æ¢è¿‡ç¨‹ä¸­ä¼šå¯¹æ‰€æœ‰`ckpt_strategy_rank_x.ckpt`è¿›è¡Œåˆå¹¶ï¼Œå¾—åˆ°`merged_ckpt_strategy.ckpt`ã€‚è‹¥ä¸å¼€å¯æµæ°´çº¿å¹¶è¡Œï¼Œåˆ™ä¸ä¼šåˆå¹¶ã€‚

![auto_trans_multi_1to8_strategy](assets/Transform_Ckpt/auto_trans_multi_1to8_strategy.png)

- **é‡æ–°ä¿å­˜æƒé‡å’Œç­–ç•¥æ–‡ä»¶**

è½¬æ¢å®Œæˆåï¼Œå»ºè®®**é‡æ–°ä¿å­˜è½¬æ¢å¾—åˆ°çš„æƒé‡å’Œç­–ç•¥æ–‡ä»¶åˆ°è‡ªå®šä¹‰æ–‡ä»¶å¤¹**ä¸‹ï¼Œåç»­ä»»åŠ¡ä¸­è‹¥åˆ†å¸ƒå¼ç­–ç•¥ä¸å˜ï¼Œå¯ä»¥ç›´æ¥åŠ è½½è¯¥æƒé‡ï¼Œä¹Ÿå¯ä»¥åŸºäºè¯¥æƒé‡ä»¥åŠç­–ç•¥æ–‡ä»¶è½¬æ¢ä¸ºå…¶ä»–åˆ†å¸ƒå¼ç­–ç•¥çš„æƒé‡ã€‚æœ¬æ¡ˆä¾‹é‡æ–°ä¿å­˜äº†æƒé‡å’Œç­–ç•¥æ–‡ä»¶ï¼Œå¹¶åœ¨[è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹äºŒ](#è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹äºŒï¼šåˆ†å¸ƒå¼æƒé‡è½¬æ¢ä¸ºå…¶ä»–åˆ†å¸ƒå¼æƒé‡)å’Œ[ç¦»çº¿è½¬æ¢æ¡ˆä¾‹äºŒ](#ç¦»çº¿è½¬æ¢æ¡ˆä¾‹äºŒï¼šåˆ†å¸ƒå¼æƒé‡è½¬æ¢ä¸ºå…¶ä»–åˆ†å¸ƒå¼æƒé‡)ä¸­ä½¿ç”¨ã€‚

![auto_trans_1to8_save](assets/Transform_Ckpt/auto_trans_1to8_save.png)

#### è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹äºŒï¼šåˆ†å¸ƒå¼æƒé‡è½¬æ¢ä¸ºå…¶ä»–åˆ†å¸ƒå¼æƒé‡

**æ¡ˆä¾‹æè¿°**ï¼šä½¿ç”¨[è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹ä¸€](#è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹ä¸€å®Œæ•´æƒé‡è½¬æ¢ä¸ºåˆ†å¸ƒå¼æƒé‡)ä¸­ä¿å­˜çš„8å¡åˆ†å¸ƒå¼æƒé‡ï¼Œè½¬æ¢ä¸º4å¡åˆ†å¸ƒå¼æƒé‡è¿›è¡Œè®­ç»ƒã€‚

- **å•è¿›ç¨‹è½¬æ¢**

â‘  é…ç½®å‚æ•°

```yaml
# configs/llama/run_llama_7b.yaml
# é…ç½®é¢„è®­ç»ƒæƒé‡è·¯å¾„ï¼Œå¡«å†™åˆ†å¸ƒå¼æƒé‡æ–‡ä»¶å¤¹è·¯å¾„model_dirï¼Œæƒé‡æŒ‰ç…§model_dir/rank_x/xxx.ckptæ ¼å¼å­˜æ”¾
load_checkpoint: "/worker/checkpoint/llama-7b-2layer-dp2mp2pp2"

# é…ç½®åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶è·¯å¾„
src_strategy_path_or_dir: "/worker/checkpoint/llama-7b-2layer-dp2mp2pp2/strategy/merged_ckpt_strategy.ckpt"

# è®¾ç½®auto_trans_ckptä¸ºTrue
auto_trans_ckpt: True

# è®¾ç½®æ•°æ®é›†
train_dataset: &train_dataset
  data_loader:
    type: MindDataset
    dataset_dir: "/worker/dataset/wikitext_2048/"
    shuffle: True

# 4å¡åˆ†å¸ƒå¼é…ç½®å‚è€ƒ
# default parallel of device num = 8 for Atlas 800
parallel_config:
  data_parallel: 1
  model_parallel: 2
  pipeline_stage: 2
  micro_batch_num: 2
  vocab_emb_dp: True
  gradient_aggregation_group: 4
# when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process.
micro_batch_interleave_num: 1
```

â‘¡ å¯åŠ¨è®­ç»ƒ

```shell
cd scripts
bash run_distribute.sh ../rank_table_4_id04.json ../configs/llama/run_llama_7b.yaml [0,4] train
```

â‘¢ æŸ¥çœ‹æƒé‡è½¬æ¢ç›¸å…³æ—¥å¿—

![auto_trans_single_8to4_log](assets/Transform_Ckpt/auto_trans_single_8to4_log.png)

â‘£ æŸ¥çœ‹è½¬æ¢ç”Ÿæˆçš„æ–‡ä»¶

**åˆ†å¸ƒå¼æƒé‡**ï¼šä¿å­˜åœ¨`output/transformed_checkpoint`æ–‡ä»¶å¤¹ä¸‹ã€‚

![auto_trans_single_8to4_transformed_ckpt](assets/Transform_Ckpt/auto_trans_single_8to4_transformed_ckpt.png)

**åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶**ï¼šä¿å­˜åœ¨`output/strategy`æ–‡ä»¶å¤¹ä¸‹ï¼Œç”±äºå¼€å¯äº†**æµæ°´çº¿å¹¶è¡Œ**ï¼Œä¼šå¯¹æ‰€æœ‰`ckpt_strategy_rank_x.ckpt`è¿›è¡Œåˆå¹¶ï¼Œå¾—åˆ°`merged_ckpt_strategy.ckpt`ã€‚è‹¥ä¸å¼€å¯æµæ°´çº¿å¹¶è¡Œï¼Œåˆ™ä¸ä¼šåˆå¹¶ã€‚

![auto_trans_single_8to4_strategy](assets/Transform_Ckpt/auto_trans_single_8to4_strategy.png)

- **å¤šè¿›ç¨‹è½¬æ¢**ï¼ˆå¯é€‰ï¼‰

â‘  é…ç½®å‚æ•°ï¼šåŸºäº**å•è¿›ç¨‹è½¬æ¢**çš„é…ç½®ï¼Œé¢å¤–é…ç½®`transform_process_num`å‚æ•°ã€‚

```bash
# è®¾ç½®å‚ä¸æƒé‡è½¬æ¢çš„è¿›ç¨‹æ•°é‡ä¸º2ï¼šç”±rank_0è´Ÿè´£rank_0/1/2/3åˆ‡ç‰‡æƒé‡è½¬æ¢ï¼Œrank_4è´Ÿè´£rank_4/5/6/7åˆ‡ç‰‡æƒé‡è½¬æ¢
transform_process_num: 2
```

â‘¡ å¯åŠ¨è®­ç»ƒï¼š

```bash
cd scripts
bash run_distribute.sh ../rank_table_4_id04.json ../configs/llama/run_llama_7b.yaml [0,4] train
```

â‘¢ æŸ¥çœ‹æƒé‡è½¬æ¢ç›¸å…³æ—¥å¿—

- rank_0

  ![auto_trans_multi_8to4_log0](assets/Transform_Ckpt/auto_trans_multi_8to4_log0.png)

- rank_2

  ![auto_trans_multi_8to4_log1](assets/Transform_Ckpt/auto_trans_multi_8to4_log1.png)

â‘£ æŸ¥çœ‹è½¬æ¢ç”Ÿæˆçš„æ–‡ä»¶

**åˆ†å¸ƒå¼æƒé‡**ï¼šä¿å­˜åœ¨`output/transformed_checkpoint`æ–‡ä»¶å¤¹ä¸‹ã€‚

![auto_trans_multi_8to4_transformed_ckpt](assets/Transform_Ckpt/auto_trans_multi_8to4_transformed_ckpt.png)

**åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶**ï¼šä¿å­˜åœ¨`output/strategy`æ–‡ä»¶å¤¹ä¸‹ï¼Œç”±äºå¼€å¯äº†**æµæ°´çº¿å¹¶è¡Œ**ï¼Œä¼šå¯¹æ‰€æœ‰`ckpt_strategy_rank_x.ckpt`è¿›è¡Œåˆå¹¶ï¼Œå¾—åˆ°`merged_ckpt_strategy.ckpt`ã€‚è‹¥ä¸å¼€å¯æµæ°´çº¿å¹¶è¡Œï¼Œåˆ™ä¸ä¼šåˆå¹¶ã€‚

![auto_trans_multi_8to4_strategy](assets/Transform_Ckpt/auto_trans_multi_8to4_strategy.png)

- **é‡æ–°ä¿å­˜æƒé‡å’Œç­–ç•¥æ–‡ä»¶**

è½¬æ¢å®Œæˆåï¼Œå»ºè®®**é‡æ–°ä¿å­˜è½¬æ¢å¾—åˆ°çš„æƒé‡å’Œç­–ç•¥æ–‡ä»¶åˆ°è‡ªå®šä¹‰æ–‡ä»¶å¤¹**ä¸‹ï¼Œåç»­ä»»åŠ¡ä¸­è‹¥åˆ†å¸ƒå¼ç­–ç•¥ä¸å˜ï¼Œå¯ä»¥ç›´æ¥åŠ è½½è¯¥æƒé‡ï¼Œä¹Ÿå¯ä»¥åŸºäºè¯¥æƒé‡ä»¥åŠç­–ç•¥æ–‡ä»¶è½¬æ¢ä¸ºå…¶ä»–åˆ†å¸ƒå¼ç­–ç•¥çš„æƒé‡ã€‚è¯¥æƒé‡å’Œç­–ç•¥æ–‡ä»¶åœ¨[è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹ä¸‰](#è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹ä¸‰ï¼šåˆ†å¸ƒå¼æƒé‡è½¬æ¢ä¸ºå…¶ä»–åˆ†å¸ƒå¼æƒé‡)å’Œ[ç¦»çº¿è½¬æ¢æ¡ˆä¾‹ä¸‰](#ç¦»çº¿è½¬æ¢æ¡ˆä¾‹ä¸‰ï¼šåˆ†å¸ƒå¼æƒé‡è½¬æ¢ä¸ºå…¶ä»–åˆ†å¸ƒå¼æƒé‡)ä¸­å‡æœ‰ç”¨åˆ°ã€‚

![auto_trans_8to4_save](assets/Transform_Ckpt/auto_trans_8to4_save.png)

#### è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹ä¸‰ï¼šåˆ†å¸ƒå¼æƒé‡åˆå¹¶ä¸ºå®Œæ•´æƒé‡

**æ¡ˆä¾‹æè¿°**ï¼šä½¿ç”¨[è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹äºŒ](#è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹äºŒåˆ†å¸ƒå¼æƒé‡è½¬æ¢ä¸ºå…¶ä»–åˆ†å¸ƒå¼æƒé‡)ä¸­ä¿å­˜çš„4å¡åˆ†å¸ƒå¼æƒé‡ï¼Œåˆå¹¶ä¸ºå®Œæ•´æƒé‡è¿›è¡Œå•å¡æ¨ç†ï¼Œ**è¯¥åœºæ™¯ä»…æ”¯æŒå•è¿›ç¨‹è½¬æ¢**ã€‚

â‘  é…ç½®å‚æ•°

```yaml
# configs/llama/run_llama_7b.yaml
# é…ç½®æƒé‡è·¯å¾„ï¼Œå¡«å†™åˆ†å¸ƒå¼æƒé‡æ–‡ä»¶å¤¹è·¯å¾„model_dirï¼Œæƒé‡æŒ‰ç…§model_dir/rank_x/xxx.ckptæ ¼å¼å­˜æ”¾
load_checkpoint: "/worker/checkpoint/llama-7b-2layer-dp1mp2pp2"

# é…ç½®åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶è·¯å¾„
src_strategy_path_or_dir: "/worker/checkpoint/llama-7b-2layer-dp1mp2pp2/strategy/merged_ckpt_strategy.ckpt"

# è®¾ç½®auto_trans_ckptä¸ºTrue
auto_trans_ckpt: True

# è®¾ç½®use_paralleä¸ºFalse
use_parallel: False

# è®¾ç½®run_modeä¸ºpredict
run_mode: 'predict'

# é…ç½®è¯è¡¨è·¯å¾„ï¼ˆå¦‚æœé…ç½®æ–‡ä»¶æ²¡æœ‰vocab_fileå…³é”®å­—è¯·è‡ªè¡Œè¡¥ä¸Šï¼‰
processor:
  tokenizer:
    vocab_file: "/worker/checkpoint/llama-7b-2layer/tokenizer.model"
```

â‘¢ å¯åŠ¨æ¨ç†

```shell
python run_mindformer.py --config configs/llama/run_llama_7b.yaml --predict_data "I love beijing, because"
```

â‘¢ æŸ¥çœ‹æƒé‡è½¬æ¢ç›¸å…³æ—¥å¿—

![llama7b_autotrans_8to1_predict_log1](assets/Transform_Ckpt/auto_trans_single_4to1_log.png)

â‘£ æŸ¥çœ‹åˆå¹¶åçš„æƒé‡

**å•å¡æƒé‡**ï¼šä¿å­˜åœ¨`output/transformed_checkpoint`æ–‡ä»¶å¤¹ä¸‹

![auto_trans_4to1_transformed_ckpt](assets/Transform_Ckpt/auto_trans_single_4to1_transformed_ckpt.png)

â‘¤ é‡æ–°ä¿å­˜æƒé‡

è½¬æ¢å®Œæˆåï¼Œå»ºè®®**é‡æ–°ä¿å­˜è½¬æ¢å¾—åˆ°çš„æƒé‡åˆ°è‡ªå®šä¹‰æ–‡ä»¶å¤¹**ä¸‹ï¼Œåç»­å¯ç›´æ¥ç”¨äºå•å¡æ¨ç†ã€‚

## ç¦»çº¿æƒé‡è½¬æ¢

Mindformersæä¾›äº†æƒé‡è½¬æ¢å·¥å…·ï¼Œæ”¯æŒ**ç¦»çº¿æƒé‡è½¬æ¢**ã€‚

- è‹¥ç›®æ ‡æƒé‡æ˜¯**å®Œæ•´æƒé‡**ï¼Œå¯ç›´æ¥è¿è¡Œæƒé‡è½¬æ¢è„šæœ¬è·å¾—ç›®æ ‡æƒé‡ã€‚

- è‹¥ç›®æ ‡æƒé‡æ˜¯**åˆ†å¸ƒå¼æƒé‡**ï¼Œé¦–å…ˆè·å–ç›®æ ‡æƒé‡çš„åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶ï¼Œç„¶åè¿è¡Œæƒé‡è½¬æ¢è„šæœ¬è·å¾—ç›®æ ‡æƒé‡ã€‚

  **è·å–åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶**ï¼šåœ¨yamlæ–‡ä»¶ä¸­é…ç½®`only_save_strategy=True`ï¼Œæ­£å¸¸å¯åŠ¨åˆ†å¸ƒå¼ä»»åŠ¡ï¼Œç”Ÿæˆå¯¹åº”çš„åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶åï¼Œä»»åŠ¡å°†ä¼šä¸»åŠ¨é€€å‡ºã€‚

  åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶ä¿å­˜ä¸º`output/strategy/ckpt_strategy_rank_x.ckpt`ã€‚

  ```bash
  only_save_strategy: True
  ```

æƒé‡è½¬æ¢å·¥å…·æ”¯æŒ**å•è¿›ç¨‹è½¬æ¢**å’Œ**å¤šè¿›ç¨‹è½¬æ¢**ï¼Œæƒé‡è½¬æ¢è„šæœ¬å¯åŠ¨æ–¹å¼å‚è€ƒå¦‚ä¸‹ã€‚

- å•è¿›ç¨‹è½¬æ¢

  ```bash
  python mindformers/tools/ckpt_transform/transform_checkpoint.py \
  --src_checkpoint=src_checkpoint \
  --src_strategy=src_strategy \
  --dst_checkpoint=dst_checkpoint \
  --dst_strategy=dst_strategy \
  --prefix=prefix
  ```

- å¤šè¿›ç¨‹è½¬æ¢

  ```bash
  bash mindformers/tools/ckpt_transform/transform_checkpoint.sh src_checkpoint src_strategy dst_checkpoint dst_strategy world_size process_num [prefix]
  ```

**ç¦»çº¿æƒé‡è½¬æ¢**ç›¸å…³å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š

| å‚æ•°åç§°       | æè¿°                                                         |
| -------------- | ------------------------------------------------------------ |
| src_checkpoint | æºæƒé‡çš„ç»å¯¹è·¯å¾„æˆ–æ–‡ä»¶å¤¹è·¯å¾„ã€‚<br />- å¦‚æœæ˜¯**å®Œæ•´æƒé‡**ï¼Œåˆ™å¡«å†™**ç»å¯¹è·¯å¾„**ï¼›<br />- å¦‚æœæ˜¯**åˆ†å¸ƒå¼æƒé‡**ï¼Œåˆ™å¡«å†™**æ–‡ä»¶å¤¹è·¯å¾„**ï¼Œåˆ†å¸ƒå¼æƒé‡é¡»æŒ‰ç…§`model_dir/rank_x/xxx.ckpt`æ ¼å¼å­˜æ”¾ï¼Œæ–‡ä»¶å¤¹è·¯å¾„å¡«å†™ä¸º`model_dir`ã€‚**å¦‚æœrank_xæ–‡ä»¶å¤¹ä¸‹å­˜åœ¨å¤šä¸ªckptï¼Œå°†ä¼šä½¿ç”¨æ–‡ä»¶åé»˜è®¤æ’åºæœ€åçš„ckptæ–‡ä»¶ç”¨äºè½¬æ¢ã€‚** |
| src_strategy   | æºæƒé‡å¯¹åº”çš„åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶è·¯å¾„ã€‚<br />- å¦‚æœæ˜¯å®Œæ•´æƒé‡ï¼Œåˆ™**ä¸å¡«å†™**ï¼›<br />- å¦‚æœæ˜¯åˆ†å¸ƒå¼æƒé‡ï¼Œä¸”ä½¿ç”¨äº†æµæ°´çº¿å¹¶è¡Œï¼Œåˆ™å¡«å†™**åˆå¹¶çš„ç­–ç•¥æ–‡ä»¶è·¯å¾„**æˆ–**åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶å¤¹è·¯å¾„**ï¼›<br />- å¦‚æœæ˜¯åˆ†å¸ƒå¼æƒé‡ï¼Œä¸”æœªä½¿ç”¨æµæ°´çº¿å¹¶è¡Œï¼Œåˆ™å¡«å†™ä»»ä¸€**ckpt_strategy_rank_x.ckpt**è·¯å¾„ï¼› |
| dst_checkpoint | ä¿å­˜ç›®æ ‡æƒé‡çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚                                   |
| dst_strategy   | ç›®æ ‡æƒé‡å¯¹åº”çš„åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶è·¯å¾„ï¼Œåˆ†å¸ƒå¼æƒé‡çš„ç­–ç•¥æ–‡ä»¶å‚è€ƒ[è·å–åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶](#è·å–åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶)å°èŠ‚è·å–ã€‚<br />- å¦‚æœæ˜¯å®Œæ•´æƒé‡ï¼Œåˆ™**ä¸å¡«å†™**ï¼›<br />- å¦‚æœæ˜¯åˆ†å¸ƒå¼æƒé‡ï¼Œä¸”ä½¿ç”¨äº†æµæ°´çº¿å¹¶è¡Œï¼Œåˆ™å¡«å†™**åˆå¹¶çš„ç­–ç•¥æ–‡ä»¶è·¯å¾„**æˆ–**åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶å¤¹è·¯å¾„**ï¼›<br />- å¦‚æœæ˜¯åˆ†å¸ƒå¼æƒé‡ï¼Œä¸”æœªä½¿ç”¨æµæ°´çº¿å¹¶è¡Œï¼Œåˆ™å¡«å†™ä»»ä¸€**ckpt_strategy_rank_x.ckpt**è·¯å¾„ï¼› |
| prefix         | ç›®æ ‡æƒé‡ä¿å­˜çš„å‰ç¼€åï¼Œæƒé‡ä¿å­˜ä¸º"{prefix}rank_x.ckpt"ï¼Œé»˜è®¤"checkpoint_"ã€‚ |
| world_size     | ç›®æ ‡æƒé‡çš„åˆ‡ç‰‡æ€»æ•°ï¼Œä¸€èˆ¬ç­‰äºdp * mp * ppã€‚                   |
| process_num    | ç¦»çº¿æƒé‡è½¬æ¢ä½¿ç”¨çš„è¿›ç¨‹æ•°ï¼Œé»˜è®¤ä¸º1ã€‚<br />- å¦‚æœprocess_num = 1ï¼Œä½¿ç”¨**å•è¿›ç¨‹è½¬æ¢**ï¼›<br />- å¦‚æœprocess_num > 1ï¼Œä½¿ç”¨**å¤šè¿›ç¨‹è½¬æ¢**ï¼Œæ¯”å¦‚è½¬æ¢çš„ç›®æ ‡æƒé‡ä¸º8å¡åˆ†å¸ƒå¼æƒé‡ï¼Œprocess_num=2æ—¶ï¼Œä¼šå¯åŠ¨ä¸¤ä¸ªè¿›ç¨‹åˆ†åˆ«è´Ÿè´£rank_0/1/2/3å’Œrank_4/5/6/7åˆ‡ç‰‡æƒé‡çš„è½¬æ¢ï¼› |

### ç¦»çº¿è½¬æ¢æ¡ˆä¾‹

æ¡ˆä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æƒé‡è½¬æ¢å·¥å…·åšç¦»çº¿æƒé‡è½¬æ¢ï¼ŒåŸºäº2å±‚çš„llama-7bæƒé‡è¿›è¡Œè½¬æ¢æ¼”ç¤ºã€‚

#### å‰æœŸå‡†å¤‡

å‚è€ƒ[è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹-å‰æœŸå‡†å¤‡](#è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹)ç« èŠ‚ï¼Œå‡†å¤‡æƒé‡ï¼Œæ•°æ®é›†ä»¥åŠrank_table_fileã€‚

#### ç¦»çº¿è½¬æ¢æ¡ˆä¾‹ä¸€ï¼šå®Œæ•´æƒé‡è½¬æ¢ä¸ºåˆ†å¸ƒå¼æƒé‡

**æ¡ˆä¾‹æè¿°**ï¼šä½¿ç”¨[å‰æœŸå‡†å¤‡](#ç¦»çº¿è½¬æ¢æ¡ˆä¾‹)ä¸‹è½½çš„å®Œæ•´æƒé‡ï¼Œè½¬æ¢ä¸º8å¡åˆ†å¸ƒå¼æƒé‡ã€‚

- **è·å–åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶**

â‘  é…ç½®å‚æ•°

```yaml
# æ‰“å¼€ç­–ç•¥æ–‡ä»¶ä¿å­˜å¼€å…³
only_save_strategy: True

# é…ç½®æ•°æ®é›†
train_dataset: &train_dataset
  data_loader:
    type: MindDataset
    dataset_dir: "/worker/dataset/wikitext_512/"
    shuffle: True

# é…ç½®8å¡åˆ†å¸ƒå¼ç­–ç•¥ï¼Œä»¥dp=2,mp=2,pp=2ä¸ºä¾‹
parallel_config:
  data_parallel: 2
  model_parallel: 2
  pipeline_stage: 2
  micro_batch_num: 2

# ä¿®æ”¹æ¨¡å‹é…ç½®
model:
  model_config:
    seq_length: 512
    num_layers: 2
```

â‘¡ å¯åŠ¨è®­ç»ƒ

```shell
cd scripts
bash run_distribute.sh ../rank_table_8.json ../configs/llama/run_llama_7b.yaml [0,8] train
```

â‘¢ æŸ¥çœ‹ç”Ÿæˆçš„ç­–ç•¥æ–‡ä»¶

![manual_trans_1to8_strategy](assets/Transform_Ckpt/manual_trans_1to8_strategy.png)

- **å•è¿›ç¨‹è½¬æ¢**

â‘  è¿è¡Œå‘½ä»¤

å¼€å¯äº†æµæ°´çº¿å¹¶è¡Œï¼Œ`dst_strategy`ä½¿ç”¨æ–‡ä»¶å¤¹è·¯å¾„ã€‚

```bash
python mindformers/tools/ckpt_transform/transform_checkpoint.py \
--src_checkpoint=/worker/checkpoint/llama-7b-2layer/rank_0/llama_7b.ckpt \
--dst_checkpoint=/worker/transform_ckpt/llama_7b_1to8/ \
--dst_strategy=/worker/mindformers/output/strategy/
```

â‘¡ æŸ¥çœ‹æƒé‡è½¬æ¢ç›¸å…³æ—¥å¿—

![manual_trans_single_1to8_log](assets/Transform_Ckpt/manual_trans_single_1to8_log.png)

â‘¢ æŸ¥çœ‹è½¬æ¢ç”Ÿæˆçš„æ–‡ä»¶

![manual_trans_single_1to8_transformed_ckpt](assets/Transform_Ckpt/manual_trans_single_1to8_transformed_ckpt.png)

- **å¤šè¿›ç¨‹è½¬æ¢**ï¼ˆå¯é€‰ï¼‰

â‘  è¿è¡Œå‘½ä»¤

```bash
# ä½¿ç”¨2ä¸ªè¿›ç¨‹è½¬æ¢
bash mindformers/tools/ckpt_transform/transform_checkpoint.sh \
/worker/checkpoint/llama-7b-2layer/rank_0/llama_7b.ckpt \
None \
/worker/transform_ckpt/llama_7b_1to8/ \
/worker/mindformers/output/strategy/ \
8 2
```

â‘¡ æŸ¥çœ‹æƒé‡è½¬æ¢ç›¸å…³æ—¥å¿—

è½¬æ¢æ—¥å¿—ä¿å­˜ä¸º`mindformers/tools/ckpt_transform/log/transform_x.log`ã€‚

- transform_0

  ![manual_trans_multi_1to8_log0](assets/Transform_Ckpt/manual_trans_multi_1to8_log0.png)

- transform_1

  ![manual_trans_multi_1to8_log1](assets/Transform_Ckpt/manual_trans_multi_1to8_log1.png)

â‘¢ æŸ¥çœ‹è½¬æ¢ç”Ÿæˆçš„æ–‡ä»¶

![manual_trans_multi_1to8_transformed_ckpt](assets/Transform_Ckpt/manual_trans_multi_1to8_transformed_ckpt.png)

#### ç¦»çº¿è½¬æ¢æ¡ˆä¾‹äºŒï¼šåˆ†å¸ƒå¼æƒé‡è½¬æ¢ä¸ºå…¶ä»–åˆ†å¸ƒå¼æƒé‡

**æ¡ˆä¾‹æè¿°**ï¼šä½¿ç”¨[è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹ä¸€](#è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹ä¸€å®Œæ•´æƒé‡è½¬æ¢ä¸ºåˆ†å¸ƒå¼æƒé‡)å¾—åˆ°çš„8å¡åˆ†å¸ƒå¼æƒé‡ï¼Œè½¬æ¢ä¸º4å¡åˆ†å¸ƒå¼æƒé‡ã€‚

- **è·å–åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶**

â‘  é…ç½®å‚æ•°

```yaml
# æ‰“å¼€ç­–ç•¥æ–‡ä»¶ä¿å­˜å¼€å…³
only_save_strategy: True

# é…ç½®æ•°æ®é›†
train_dataset: &train_dataset
  data_loader:
    type: MindDataset
    dataset_dir: "/worker/dataset/wikitext_512/"
    shuffle: True

# é…ç½®8å¡åˆ†å¸ƒå¼ç­–ç•¥ï¼Œä»¥dp=2,mp=2,pp=2ä¸ºä¾‹
parallel_config:
  data_parallel: 1
  model_parallel: 2
  pipeline_stage: 2
  micro_batch_num: 2

# ä¿®æ”¹æ¨¡å‹é…ç½®
model:
  model_config:
    seq_length: 512
    num_layers: 2
```

â‘¡ å¯åŠ¨è®­ç»ƒ

```shell
cd scripts
bash run_distribute.sh ../rank_table_4_id04.json ../configs/llama/run_llama_7b.yaml [0,4] train
```

â‘¢ æŸ¥çœ‹ç”Ÿæˆçš„ç­–ç•¥æ–‡ä»¶

![manual_trans_1to8_strategy](assets/Transform_Ckpt/manual_trans_8to4_strategy.png)

- **å•è¿›ç¨‹è½¬æ¢**

â‘  è¿è¡Œå‘½ä»¤

å¼€å¯äº†æµæ°´çº¿å¹¶è¡Œï¼Œ`dst_strategy`ä½¿ç”¨æ–‡ä»¶å¤¹è·¯å¾„ã€‚

```bash
python mindformers/tools/ckpt_transform/transform_checkpoint.py \
--src_checkpoint=/worker/checkpoint/llama-7b-2layer-dp2mp2pp2/ \
--src_strategy=/worker/checkpoint/llama-7b-2layer-dp2mp2pp2/strategy/merged_ckpt_strategy.ckpt \
--dst_checkpoint=/worker/transform_ckpt/llama_7b_8to4/ \
--dst_strategy=/worker/mindformers/output/strategy/
```

â‘¡ æŸ¥çœ‹æƒé‡è½¬æ¢ç›¸å…³æ—¥å¿—

![manual_trans_single_8to4_log](assets/Transform_Ckpt/manual_trans_single_8to4_log.png)

â‘¢ æŸ¥çœ‹è½¬æ¢ç”Ÿæˆçš„æ–‡ä»¶

![manual_trans_single_8to4_transformed_ckpt](assets/Transform_Ckpt/manual_trans_single_8to4_transformed_ckpt.png)

- **å¤šè¿›ç¨‹è½¬æ¢**ï¼ˆå¯é€‰ï¼‰

â‘  è¿è¡Œå‘½ä»¤

```bash
# ä½¿ç”¨2ä¸ªè¿›ç¨‹è½¬æ¢
bash mindformers/tools/ckpt_transform/transform_checkpoint.sh \
/worker/checkpoint/llama-7b-2layer-dp2mp2pp2/ \
/worker/checkpoint/llama-7b-2layer-dp2mp2pp2/strategy/merged_ckpt_strategy.ckpt \
/worker/transform_ckpt/llama_7b_8to4/ \
/worker/mindformers/output/strategy/ \
4 2
```

â‘¡ æŸ¥çœ‹æƒé‡è½¬æ¢ç›¸å…³æ—¥å¿—

è½¬æ¢æ—¥å¿—ä¿å­˜ä¸º`mindformers/tools/ckpt_transform/log/transform_x.log`ã€‚

- transform_0

  ![manual_trans_multi_8to4_log0](assets/Transform_Ckpt/manual_trans_multi_8to4_log0.png)

- transform_1

  ![manual_trans_multi_8to4_log1](assets/Transform_Ckpt/manual_trans_multi_8to4_log1.png)

â‘¢ æŸ¥çœ‹è½¬æ¢ç”Ÿæˆçš„æ–‡ä»¶

![manual_trans_multi_8to4_transformed_ckpt](assets/Transform_Ckpt/manual_trans_multi_8to4_transformed_ckpt.png)

#### ç¦»çº¿è½¬æ¢æ¡ˆä¾‹ä¸‰ï¼šåˆ†å¸ƒå¼æƒé‡åˆå¹¶ä¸ºå®Œæ•´æƒé‡

**æ¡ˆä¾‹æè¿°**ï¼šä½¿ç”¨[è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹äºŒ](#è‡ªåŠ¨è½¬æ¢æ¡ˆä¾‹äºŒåˆ†å¸ƒå¼æƒé‡è½¬æ¢ä¸ºå…¶ä»–åˆ†å¸ƒå¼æƒé‡)å¾—åˆ°çš„4å¡åˆ†å¸ƒå¼æƒé‡ï¼Œåˆå¹¶ä¸ºå®Œæ•´æƒé‡ã€‚

â‘  è¿è¡Œå‘½ä»¤

```shell
python mindformers/tools/ckpt_transform/transform_checkpoint.py \
--src_checkpoint=/worker/checkpoint/llama-7b-2layer-dp1mp2pp2/ \
--src_strategy=/worker/checkpoint/llama-7b-2layer-dp1mp2pp2/strategy/merged_ckpt_strategy.ckpt \
--dst_checkpoint=/worker/transform_ckpt/llama_7b_4to1/
```

â‘¡ æŸ¥çœ‹æƒé‡è½¬æ¢ç›¸å…³æ—¥å¿—

![manual_trans_single_4to1_log](assets/Transform_Ckpt/manual_trans_single_4to1_log.png)

â‘¢ æŸ¥çœ‹è½¬æ¢ç”Ÿæˆçš„æ–‡ä»¶

![manual_trans_single_4to1_transformed_ckpt](assets/Transform_Ckpt/manual_trans_single_4to1_transformed_ckpt.png)

## ç‰©ç†æœºå¤šæœºå¤šå¡è®­ç»ƒ

å¤§æ¨¡å‹é€šå¸¸ä½¿ç”¨å¤šå°æœåŠ¡å™¨ç»„æˆçš„é›†ç¾¤è¿›è¡Œè®­ç»ƒï¼ŒåŒæ ·æ¶‰åŠåˆ°æƒé‡åŠ è½½å’Œè½¬æ¢çš„é—®é¢˜ã€‚æœ¬å°èŠ‚æ ¹æ®æœåŠ¡å™¨ä¹‹é—´**æœ‰å…±äº«ç›˜**å’Œ**æ— å…±äº«ç›˜**ä¸¤ç§ä½¿ç”¨åœºæ™¯ï¼Œæè¿°åŠ è½½é¢„è®­ç»ƒæƒé‡çš„å¤šæœºå¤šå¡è®­ç»ƒæµç¨‹ï¼Œä»¥2æœº16å¡è®­ç»ƒllama-13bæ¨¡å‹ä¸ºä¾‹ã€‚

### å‰æœŸå‡†å¤‡

- è·å–å¤šæœºçš„rank_table_file

```bash
# step1ï¼šæ¯å°æœºå™¨ç”Ÿæˆå„è‡ªçš„rank_table_file
python mindformers/tools/hccl_tools.py --device_num [0,8]

# step2ï¼šå°†æ‰€æœ‰æœºå™¨çš„rank_table_fileä¿å­˜åˆ°ä¸€å°æœºå™¨ï¼Œè¿›è¡Œåˆå¹¶
python mindformers/tools/merge_hccl.py hccl*.json

# step3ï¼šå°†åˆå¹¶åçš„rank_table_fileå¤åˆ¶åˆ°æ‰€æœ‰æœºå™¨
```

### ä¸€ã€æœåŠ¡å™¨ä¹‹é—´æœ‰å…±äº«ç›˜ï¼šä½¿ç”¨è‡ªåŠ¨æƒé‡è½¬æ¢

å‡è®¾`/data`ä¸ºæœåŠ¡å™¨å…±äº«ç›˜ï¼Œmindformerå·¥ç¨‹ä»£ç ä¸º`/data/mindformers`ã€‚

- **å•è¿›ç¨‹è½¬æ¢**

å‚æ•°é…ç½®

```yaml
# é…ç½®é¢„è®­ç»ƒæƒé‡è·¯å¾„ï¼Œå¡«å†™æƒé‡æ–‡ä»¶è·¯å¾„
load_checkpoint: "/worker/checkpoint/llama-7b/rank_0/llama_7b.ckpt"

# è®¾ç½®auto_trans_ckptä¸ºTrue
auto_trans_ckpt: True

# é…ç½®æ•°æ®é›†
train_dataset: &train_dataset
  data_loader:
    type: MindDataset
    dataset_dir: "/worker/dataset/wikitext_2048/"
    shuffle: True

# é…ç½®16å¡åˆ†å¸ƒå¼ç­–ç•¥ï¼Œä»…ä¾›å‚è€ƒ
parallel_config:
  data_parallel: 2
  model_parallel: 4
  pipeline_stage: 2
  micro_batch_num: 2
  vocab_emb_dp: True
  gradient_aggregation_group: 4
# when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process.
micro_batch_interleave_num: 1
```

- **å¤šè¿›ç¨‹è½¬æ¢**ï¼ˆå¯é€‰ï¼‰

è‹¥éœ€è¦ä½¿ç”¨å¤šè¿›ç¨‹è½¬æ¢ï¼Œå¯é…ç½®`transform_process_num`å‚æ•°

```yaml
# å¦‚ï¼šä½¿ç”¨2è¿›ç¨‹è½¬æ¢ï¼Œç¬¬1å°èŠ‚ç‚¹çš„0å¡è´Ÿè´£rank_0~7åˆ‡ç‰‡çš„è½¬æ¢ï¼Œç¬¬2å°èŠ‚ç‚¹çš„0å¡è´Ÿè´£rank_8~15åˆ‡ç‰‡çš„è½¬æ¢
transform_process_num: 2
```

- **å¯åŠ¨ä»»åŠ¡**

```shell
cd scripts
# ç¬¬ä¸€å°æœºå™¨ï¼ˆ0èŠ‚ç‚¹ï¼‰
bash run_distribute.sh RANK_TABLE_FILE ../configs/llama/run_llama_7b.yaml [0,8] train 16
# ç¬¬äºŒå°æœºå™¨ï¼ˆ0èŠ‚ç‚¹ï¼‰
bash run_distribute.sh RANK_TABLE_FILE ../configs/llama/run_llama_7b.yaml [8,16] train 16
```

### äºŒã€ æœåŠ¡å™¨ä¹‹é—´æ— å…±äº«ç›˜ï¼šä½¿ç”¨ç¦»çº¿æƒé‡è½¬æ¢

#### 1. è·å–åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶

â‘  é…ç½®å‚æ•°

```yaml
# é…ç½®only_save_strategy=Trueï¼Œæ‹‰èµ·åˆ†å¸ƒå¼ä»»åŠ¡ä»¥è·å–æ‰€æœ‰èŠ‚ç‚¹çš„åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶
only_save_strategy: True

# é…ç½®æ•°æ®é›†
train_dataset: &train_dataset
  data_loader:
    type: MindDataset
    dataset_dir: "/worker/dataset/wikitext_2048/"
    shuffle: True

# é…ç½®16å¡åˆ†å¸ƒå¼ç­–ç•¥ï¼Œä»…ä¾›å‚è€ƒ
parallel_config:
  data_parallel: 2
  model_parallel: 4
  pipeline_stage: 2
  micro_batch_num: 2
  vocab_emb_dp: True
  gradient_aggregation_group: 4
# when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process.
micro_batch_interleave_num: 1
```

â‘¡ å¯åŠ¨è®­ç»ƒä»»åŠ¡

```shell
cd scripts
# ç¬¬ä¸€å°æœºå™¨ï¼ˆ0èŠ‚ç‚¹ï¼‰
bash run_distribute.sh RANK_TABLE_FILE ../configs/llama/run_llama_7b.yaml [0,8] train 16
# ç¬¬äºŒå°æœºå™¨ï¼ˆ1èŠ‚ç‚¹ï¼‰
bash run_distribute.sh RANK_TABLE_FILE ../configs/llama/run_llama_7b.yaml [8,16] train 16
```

å„èŠ‚ç‚¹çš„ç­–ç•¥æ–‡ä»¶ä¿å­˜åœ¨å„è‡ªçš„`output/strategy`ç›®å½•ä¸‹ï¼Œå…¶ä¸­0èŠ‚ç‚¹ä¿å­˜`ckpt_strategy_rank_0-7.ckpt`ï¼Œ1èŠ‚ç‚¹ä¿å­˜`ckpt_strategy_rank_8-15.ckpt`ã€‚

â‘¢ å°†æ‰€æœ‰ç­–ç•¥æ–‡ä»¶æ”¶é›†åˆ°åŒä¸€å°æœºå™¨ä¸Šã€‚

#### 2. ç¦»çº¿æƒé‡è½¬æ¢

åœ¨ä¿å­˜æœ‰æ‰€æœ‰ç­–ç•¥æ–‡ä»¶çš„æœºå™¨ä¸Šå®Œæˆå¯¹**æƒé‡ç¦»çº¿è½¬æ¢**ã€‚

- **å•è¿›ç¨‹è½¬æ¢**

```bash
python mindformers/tools/ckpt_transorm/transform_checkpoint.py \
--src_checkpoint=/worker/checkpoint/llama-7b/rank_0/llama_7b.ckpt \
--dst_checkpoint=./output/llama_7b_dp2mp4pp2 \
--dst_strategy=./output/strategy
```

- **å¤šè¿›ç¨‹è½¬æ¢**ï¼ˆå¯é€‰ï¼‰

```bash
# ä½¿ç”¨2ä¸ªè¿›ç¨‹è½¬æ¢
bash mindformers/tools/ckpt_transorm/transform_checkpoint.sh \
/worker/checkpoint/llama-7b/rank_0/llama_7b.ckpt \
None \
./output/llama_7b_dp2mp4pp2 \
./output/strategy \
16 2
```

#### 3. å¤åˆ¶æƒé‡åˆ°å…¶ä»–èŠ‚ç‚¹

å°†åˆ†ç‰‡æƒé‡åˆ†åˆ«å¤åˆ¶åˆ°å¯¹åº”çš„èŠ‚ç‚¹ä¸Šï¼Œ0èŠ‚ç‚¹åªéœ€è¦**rank_0åˆ°rank_7**åˆ‡ç‰‡æƒé‡ï¼Œ1èŠ‚ç‚¹åªéœ€è¦**rank_8åˆ°rank_15**åˆ‡ç‰‡æƒé‡ã€‚

#### 4. å¯åŠ¨ä»»åŠ¡

â‘   åŸºäº[è·å–åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶](#1. è·å–åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶)å°èŠ‚é…ç½®çš„å‚æ•°åŸºç¡€ä¸Šï¼Œä½œå¦‚ä¸‹ä¿®æ”¹

```yaml
# é…ç½®é¢„è®­ç»ƒæƒé‡è·¯å¾„ï¼Œå¡«å†™åˆ†å¸ƒå¼æƒé‡æ–‡ä»¶å¤¹è·¯å¾„model_dirï¼Œæƒé‡æŒ‰ç…§model_dir/rank_x/xxx.ckptæ ¼å¼å­˜æ”¾
load_checkpoint: "/worker/checkpoint/llama_7b_dp2mp4pp2"

# only_save_strategyæ”¹ä¸ºFalse
only_save_strategy: False
```

â‘¢ å¯åŠ¨è®­ç»ƒ

```shell
cd scripts
# ç¬¬ä¸€å°æœºå™¨ï¼ˆ0èŠ‚ç‚¹ï¼‰
bash run_distribute.sh RANK_TABLE_FILE ../configs/llama/run_llama_7b.yaml [0,8] train 16
# ç¬¬äºŒå°æœºå™¨ï¼ˆ1èŠ‚ç‚¹ï¼‰
bash run_distribute.sh RANK_TABLE_FILE ../configs/llama/run_llama_7b.yaml [8,16] train 16
```

## ModelArtsè®­ç»ƒ

ModelArtsè®­ç»ƒå’Œç‰©ç†æœºç±»ä¼¼ï¼Œ**å¤šæœºå¤šå¡è®­ç»ƒæ”¯æŒå¼€å¯æƒé‡è‡ªåŠ¨è½¬æ¢**ã€‚

åœ¨**è®­ç»ƒä½œä¸š-->è¶…å‚**ä¸­é…ç½®`auto_trans_ckpt=True`å¼€å¯è‡ªåŠ¨æƒé‡è½¬æ¢ï¼Œé…ç½®`transform_process_num > 1`å¯å¼€å¯å¤šè¿›ç¨‹è½¬æ¢ã€‚

**æ³¨æ„**ï¼šè‹¥ModelArtsèµ„æºæ± çš„æœåŠ¡å™¨èŠ‚ç‚¹çš„å¡æ•°ä¸ä¸º8ï¼Œéœ€è¦é¢å¤–é…ç½®`npu_num_per_node=èŠ‚ç‚¹NPUå¡æ•°`ï¼Œæ¯”å¦‚æ¯å°èŠ‚ç‚¹æœ‰16ä¸ªNPUï¼Œåˆ™`npu_num_per_node=16`ã€‚

## AutoModelåŠ è½½åˆ†å¸ƒå¼æ¨¡å‹

AutoModelæ¥å£å·²é€‚é…æƒé‡è‡ªåŠ¨è½¬æ¢ï¼Œæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒåœºæ™¯ä¸‹è¾“å‡ºåˆ†å¸ƒå¼æ¨¡å‹ï¼Œä½¿ç”¨æ–¹å¼å¦‚ä¸‹ï¼š

```python
from mindformers import AutoModelForCausalLM, build_context

# é…ç½®åˆ†å¸ƒå¼ç­–ç•¥
train_args = TrainingArguments(
    use_parallel=True,
    data_parallel=1,
    model_parallel=2,
    pipeline_stage=2,
    micro_batch_num=2,
    recompute=True,
    enable_parallel_optimizer=True,
    ...
)

# åˆå§‹åŒ–åˆ†å¸ƒå¼æƒé‡
build_context(train_args)

# åˆå§‹åŒ–åˆ†å¸ƒå¼æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "repo_id",
    auto_trans_ckpt=True,
    parallel_config=train_args.get_parallel_config()
)
```

**æ³¨**ï¼šAutoModelçš„æƒé‡è‡ªåŠ¨è½¬æ¢ç‰¹æ€§ä»…æ”¯æŒä¼ å…¥"repo_id"çš„å½¢å¼ï¼Œå³ä»openMindæˆ–æœ¬åœ°ä»“åº“åŠ è½½æƒé‡ï¼Œä¸æ”¯æŒæ¨¡å‹ååŠå…¶ä»–æ–¹å¼ã€‚
