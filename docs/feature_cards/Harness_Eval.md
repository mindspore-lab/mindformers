# Harnessè¯„æµ‹

> ## ğŸš¨ å¼ƒç”¨è¯´æ˜
>
> æœ¬æ–‡æ¡£å·²è¿‡æ—¶ï¼Œä¸å†è¿›è¡Œç»´æŠ¤ï¼Œå¹¶å°†åœ¨ *1.5.0* ç‰ˆæœ¬ä¸‹æ¶ï¼Œå…¶ä¸­å¯èƒ½åŒ…å«è¿‡æ—¶çš„ä¿¡æ¯æˆ–å·²è¢«æ›´æ–°çš„åŠŸèƒ½æ›¿ä»£ã€‚å»ºè®®å‚è€ƒæœ€æ–°çš„ **[å®˜æ–¹æ–‡æ¡£](https://www.mindspore.cn/mindformers/docs/zh-CN/dev/index.html)** ï¼Œä»¥è·å–å‡†ç¡®çš„ä¿¡æ¯ã€‚
>
> å¦‚æœæ‚¨ä»éœ€ä½¿ç”¨æœ¬æ–‡æ¡£ä¸­çš„å†…å®¹ï¼Œè¯·ä»”ç»†æ ¸å¯¹å…¶é€‚ç”¨æ€§ï¼Œå¹¶ç»“åˆæœ€æ–°ç‰ˆæœ¬çš„ç›¸å…³èµ„æºè¿›è¡ŒéªŒè¯ã€‚
>
> å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ **[ç¤¾åŒºIssue](https://gitee.com/mindspore/mindformers/issues/new)** æäº¤åé¦ˆã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£ä¸æ”¯æŒï¼

## åŸºæœ¬ä»‹ç»

[LM Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness)
æ˜¯ä¸€ä¸ªå¼€æºè¯­è¨€æ¨¡å‹è¯„æµ‹æ¡†æ¶ï¼Œæä¾›60å¤šç§æ ‡å‡†å­¦æœ¯æ•°æ®é›†çš„è¯„æµ‹ï¼Œæ”¯æŒHuggingFaceæ¨¡å‹è¯„æµ‹ã€PEFTé€‚é…å™¨è¯„æµ‹ã€vLLMæ¨ç†è¯„æµ‹ç­‰å¤šç§è¯„æµ‹æ–¹å¼ï¼Œæ”¯æŒè‡ªå®šä¹‰promptå’Œè¯„æµ‹æŒ‡æ ‡ï¼ŒåŒ…å«loglikelihoodã€generate_untilã€loglikelihood_rollingä¸‰ç§ç±»å‹çš„è¯„æµ‹ä»»åŠ¡ã€‚åŸºäºHarnessè¯„æµ‹æ¡†æ¶å¯¹MindFormersè¿›è¡Œé€‚é…åï¼Œæ”¯æŒåŠ è½½MindFormersæ¨¡å‹è¿›è¡Œè¯„æµ‹ã€‚

## å®‰è£…

```shell
pip install lm_eval==0.4.4
```

## ä½¿ç”¨æ–¹å¼

### æŸ¥çœ‹æ•°æ®é›†è¯„æµ‹ä»»åŠ¡

```shell
#!/bin/bash

python toolkit/benchmarks/eval_with_harness.py --tasks list
```

### å¯åŠ¨å•å¡è¯„æµ‹è„šæœ¬

```shell
#!/bin/bash

python toolkit/benchmarks/eval_with_harness.py --model mf --model_args "pretrained=MODEL_DIR,device_id=0" --tasks TASKS
```

### å¯åŠ¨å¤šå¡å¹¶è¡Œè¯„æµ‹è„šæœ¬

```shell
#!/bin/bash

export ASCEND_RT_VISIBLE_DEVICES=0,1,2,3

bash  mindformers/scripts/msrun_launcher.sh "toolkit/benchmarks/eval_with_harness.py \
    --model mf \
    --model_args pretrained=MODEL_DIR,use_parallel=True,tp=1,dp=4 \
    --tasks TASKS \
    --batch_size 4" 4
```

å¯é€šè¿‡ç¯å¢ƒå˜é‡ASCEND_RT_VISIBLE_DEVICESè®¾ç½®å¤šå¡å¡å·ã€‚

### è¯„æµ‹å‚æ•°

#### Harnessä¸»è¦å‚æ•°

| å‚æ•°            | ç±»å‹  | å‚æ•°ä»‹ç»                      | æ˜¯å¦å¿…é¡» |
|---------------|-----|---------------------------|------|
| --model       | str | é¡»è®¾ç½®ä¸ºmfï¼Œå¯¹åº”ä¸ºMindFormersè¯„ä¼°ç­–ç•¥ | æ˜¯    |
| --model_args  | str | æ¨¡å‹åŠè¯„ä¼°ç›¸å…³å‚æ•°ï¼Œè§ä¸‹æ–¹æ¨¡å‹å‚æ•°ä»‹ç»       | æ˜¯    |
| --tasks       | str | æ•°æ®é›†åç§°ï¼Œå¯ä¼ å…¥å¤šä¸ªæ•°æ®é›†ï¼Œé€—å·åˆ†å‰²       | æ˜¯    |
| --batch_size  | int | æ‰¹å¤„ç†æ ·æœ¬æ•°                    | å¦    |
| --num_fewshot | int | Few_shotçš„æ ·æœ¬æ•°              | å¦    |
| --limit       | int | æ¯ä¸ªä»»åŠ¡çš„æ ·æœ¬æ•°ï¼Œå¤šç”¨äºåŠŸèƒ½æµ‹è¯•          | å¦    |

#### MindFormersæ¨¡å‹å‚æ•°

| å‚æ•°           | ç±»å‹   | å‚æ•°ä»‹ç»                              | æ˜¯å¦å¿…é¡» |
|--------------|------|-----------------------------------|------|
| pretrained   | str  | æ¨¡å‹ç›®å½•è·¯å¾„                            | æ˜¯    |
| use_past     | bool | æ˜¯å¦å¼€å¯å¢é‡æ¨ç†ï¼Œgenerate_untilç±»å‹çš„è¯„æµ‹ä»»åŠ¡é¡»å¼€å¯ | å¦    |
| device_id    | int  | è®¾å¤‡id                              | å¦    |
| use_parallel | bool | å¼€å¯å¹¶è¡Œç­–ç•¥                            | å¦    |
| dp           | int  | æ•°æ®å¹¶è¡Œ                              | å¦    |
| tp           | int  | æ¨¡å‹å¹¶è¡Œ                              | å¦    |

### è¯„æµ‹å‰å‡†å¤‡

1. åˆ›å»ºæ¨¡å‹ç›®å½•MODEL_DIRï¼›
2. æ¨¡å‹ç›®å½•ä¸‹é¡»æ”¾ç½®MindFormersæƒé‡ã€yamlé…ç½®æ–‡ä»¶ã€åˆ†è¯å™¨æ–‡ä»¶ï¼Œè·å–æ–¹å¼å‚è€ƒMindFormersæ¨¡å‹READMEæ–‡æ¡£ï¼›
3. é…ç½®yamlé…ç½®æ–‡ä»¶ã€‚

yamlé…ç½®å‚è€ƒï¼š

```yaml
run_mode: 'predict'
model:
  model_config:
    checkpoint_name_or_path: "model.ckpt"
processor:
  tokenizer:
    vocab_file: "tokenizer.model"
```

## è¯„æµ‹æ ·ä¾‹

```shell
#!/bin/bash

python toolkit/benchmarks/eval_with_harness.py --model mf --model_args "pretrained=./llama3-8b,use_past=True" --tasks gsm8k

# è¯„ä¼°ç»“æœå¦‚ä¸‹ï¼Œå…¶ä¸­Filterå¯¹åº”åŒ¹é…æ¨¡å‹è¾“å‡ºç»“æœçš„æ–¹å¼ï¼ŒMetricå¯¹åº”è¯„ä¼°æŒ‡æ ‡ï¼ŒValueå¯¹åº”è¯„ä¼°åˆ†æ•°ï¼Œstderrå¯¹åº”åˆ†æ•°è¯¯å·®ã€‚
# mf (pretrained=./llama3-8b), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 1
# |Tasks|Version|     Filter     |n-shot|  Metric   |   |Value |   |Stderr|
# |-----|------:|----------------|-----:|-----------|---|-----:|---|-----:|
# |gsm8k|      3|flexible-extract|     5|exact_match|â†‘  |0.5034|Â±  |0.0138|
# |     |       |strict-match    |     5|exact_match|â†‘  |0.5011|Â±  |0.0138|
```

## æ”¯æŒç‰¹æ€§è¯´æ˜

æ”¯æŒHarnesså…¨é‡è¯„æµ‹ä»»åŠ¡ï¼ŒåŒ…å«å¦‚ä¸‹ä»»åŠ¡ç»„åŠå…¶å­ä»»åŠ¡ï¼š

<details>
<summary>ç‚¹å‡»å±•å¼€Harnessè¯„æµ‹ä»»åŠ¡è¡¨</summary>

| Group           | Task                                                                      |
|-----------------|---------------------------------------------------------------------------|
| aclue           | aclue_ancient_chinese_culture, aclue_ancient_literature ...               |
| aexams          | aexams_Biology, aexams_IslamicStudies ...                                 |
| agieval         | agieval_aqua_rat, agieval_math ...                                        |
| arabicmmlu      | arabicmmlu_driving_test, arabicmmlu_general_knowledge ...                 |
| bbh             | bbh_cot_fewshot_boolean_expressions, bbh_cot_fewshot_causal_judgement ... |
| belebele        | belebele_acm_Arab, belebele_afr_Latn, ...                                 |
| blimp           | blimp_adjunct_island, blimp_anaphor_gender_agreement ...                  |
| ceval-valid     | ceval-valid_accountant, ceval-valid_advanced_mathematics ...              |
| cmmlu           | cmmlu_agronomy, cmmlu_anatomy ...                                         |
| csatqa          | csatqa_gr, csatqa_li ...                                                  |
| flan            | anli_r1_flan, anli_r2_flan ...                                            |
| haerae          | haerae_general_knowledge, haerae_history ...                              |
| hendrycks_math  | hendrycks_math_algebra, hendrycks_math_counting_and_prob ...              |
| kormedmcqa      | kormedmcqa_doctor, kormedmcqa_nurse ...                                   |
| leaderboard     | leaderboard_bbh_boolean_expressions, leaderboard_bbh_causal_judgement ... |
| lingoly         | lingoly_context, lingoly_nocontext ...                                    |
| med_concepts_qa | med_concepts_qa_atc_easy, med_concepts_qa_atc_hard ...                    |
| mela            | mela_ar, mela_de ...                                                      |
| minerva_math    | minerva_math_algebra, minerva_math_counting_and_prob ...                  |
| mmlu            | mmlu_abstract_algebra, mmlu_abstract_algebra_generative ...               |
| multimedqa      | mmlu_anatomy, mmlu_clinical_knowledge ...                                 |
| openllm         | arc_challenge, hellaswag ...                                              |
| pawsx           | paws_de, paws_en ...                                                      |
| pythia          | lambada_openai, logiqa ...                                                |
| t0_eval         | anli_r1, anli_r2 ...                                                      |
| tinyBenchmarks  | tinyGSM8k, tinyHellaswag ...                                              |
| tmlu            | tmlu_AST_biology, tmlu_AST_chemistry ...                                  |
| tmmluplus       | tmmluplus_accounting, tmmluplus_administrative_law ...                    |
| wmdp            | wmdp_bio, wmdp_chem ...                                                   |
| xcopa           | xcopa_et, xcopa_ht ...                                                    |
| xnli            | xnli_ar, xnli_bg ...                                                      |
| xstorycloze     | xstorycloze_ar, xstorycloze_en ...                                        |
| xwinograd       | xwinograd_en, xwinograd_fr ...                                            |

</details>

å…·ä½“è¯„æµ‹ä»»åŠ¡è§[æŸ¥çœ‹æ•°æ®é›†è¯„æµ‹ä»»åŠ¡](https://gitee.com/mindspore/mindformers/blob/dev/docs/feature_cards/Harness_Eval.md#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%84%E6%B5%8B%E4%BB%BB%E5%8A%A1)ã€‚