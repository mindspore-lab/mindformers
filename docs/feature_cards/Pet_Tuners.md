# ä½å‚å¾®è°ƒ

> ## ğŸš¨ å¼ƒç”¨è¯´æ˜
>
> æœ¬æ–‡æ¡£å·²è¿‡æ—¶ï¼Œä¸å†è¿›è¡Œç»´æŠ¤ï¼Œå¹¶å°†åœ¨ *1.5.0* ç‰ˆæœ¬ä¸‹æ¶ï¼Œå…¶ä¸­å¯èƒ½åŒ…å«è¿‡æ—¶çš„ä¿¡æ¯æˆ–å·²è¢«æ›´æ–°çš„åŠŸèƒ½æ›¿ä»£ã€‚å»ºè®®å‚è€ƒæœ€æ–°çš„ **[å®˜æ–¹æ–‡æ¡£](https://www.mindspore.cn/mindformers/docs/zh-CN/dev/index.html)** ï¼Œä»¥è·å–å‡†ç¡®çš„ä¿¡æ¯ã€‚
>
> å¦‚æœæ‚¨ä»éœ€ä½¿ç”¨æœ¬æ–‡æ¡£ä¸­çš„å†…å®¹ï¼Œè¯·ä»”ç»†æ ¸å¯¹å…¶é€‚ç”¨æ€§ï¼Œå¹¶ç»“åˆæœ€æ–°ç‰ˆæœ¬çš„ç›¸å…³èµ„æºè¿›è¡ŒéªŒè¯ã€‚
>
> å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ **[ç¤¾åŒºIssue](https://gitee.com/mindspore/mindformers/issues/new)** æäº¤åé¦ˆã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£ä¸æ”¯æŒï¼

MindPetï¼ˆPetï¼šParameter-Efficient Tuningï¼‰æ˜¯å±äºMindsporeé¢†åŸŸçš„å¾®è°ƒç®—æ³•å¥—ä»¶ã€‚éšç€è®¡ç®—ç®—åŠ›ä¸æ–­å¢åŠ ï¼Œå¤§æ¨¡å‹æ— é™çš„æ½œåŠ›ä¹Ÿè¢«æŒ–æ˜å‡ºæ¥ã€‚ä½†éšä¹‹åœ¨åº”ç”¨å’Œè®­ç»ƒä¸Šå¸¦æ¥äº†å·¨å¤§çš„èŠ±é”€ï¼Œå¯¼è‡´å•†ä¸šè½åœ°å›°éš¾ã€‚å› æ­¤ï¼Œå‡ºç°ä¸€ç§æ–°çš„å‚æ•°é«˜æ•ˆï¼ˆparameter-efficientï¼‰ç®—æ³•ï¼Œä¸æ ‡å‡†çš„å…¨å‚æ•°å¾®è°ƒç›¸æ¯”ï¼Œè¿™äº›ç®—æ³•ä»…éœ€è¦å¾®è°ƒå°éƒ¨åˆ†å‚æ•°ï¼Œå¯ä»¥å¤§å¤§é™ä½è®¡ç®—å’Œå­˜å‚¨æˆæœ¬ï¼ŒåŒæ—¶å¯åª²ç¾å…¨å‚å¾®è°ƒçš„æ€§èƒ½ã€‚

ç›®å‰ä½å‚å¾®è°ƒé’ˆå¯¹MindFormersä»“åº“å·²æœ‰çš„å¤§æ¨¡å‹è¿›è¡Œç»Ÿä¸€æ¶æ„è®¾è®¡ï¼Œå¯¹äºLLMç±»è¯­è¨€æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ç»Ÿä¸€è°ƒåº¦ä¿®æ”¹ï¼Œåšåˆ°åªéœ€è¦è°ƒç”¨æ¥å£æˆ–è€…æ˜¯è‡ªå®šä¹‰ç›¸å…³é…ç½®æ–‡ä»¶ï¼Œå³å¯å®Œæˆå¯¹LLMç±»æ¨¡å‹çš„ä½å‚å¾®è°ƒç®—æ³•çš„é€‚é…ã€‚

## [å¾®è°ƒæ”¯æŒåˆ—è¡¨](../model_support_list.md#å¾®è°ƒæ”¯æŒåˆ—è¡¨)

## Loraä½¿ç”¨ç¤ºä¾‹

1. ç¡®å®šéœ€è¦æ›¿æ¢çš„æ¨¡å—ï¼Œloraæ¨¡å—ä¸€èˆ¬æ›¿æ¢transformersæ¨¡å—çš„queryï¼Œkeyï¼Œvalueç­‰çº¿æ€§å±‚ï¼Œæ›¿æ¢æ—¶éœ€è¦æ‰¾åˆ°ï¼ˆquery, key, valueï¼‰ç­‰æ¨¡å—çš„å˜é‡é‡ï¼Œåœ¨ç»Ÿä¸€æ¡†æ¶ä¸­é‡‡ç”¨çš„æ˜¯æ­£åˆ™åŒ¹é…è§„åˆ™å¯¹éœ€è¦æ›¿æ¢çš„æ¨¡å—è¿›è¡Œloraå¾®è°ƒç®—æ³•çš„æ›¿æ¢ã€‚

```python
# ä»¥GPTä¸ºä¾‹ï¼Œåœ¨GPTçš„attentionå®šä¹‰ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹åˆ°qkvçš„å®šä¹‰å¦‚ä¸‹ï¼š
class MultiHeadAttention(Cell):
    ...
    # Query
    self.dense1 = Linear(hidden_size,
                          hidden_size,
                          compute_dtype=compute_dtype,
                          param_init_type=param_init_type)
    # Key
    self.dense2 = Linear(hidden_size,
                          hidden_size,
                          compute_dtype=compute_dtype,
                          param_init_type=param_init_type)
    # Value
    self.dense3 = Linear(hidden_size,
                          hidden_size,
                          compute_dtype=compute_dtype,
                          param_init_type=param_init_type)
    ...
```

æ‰¾åˆ°å¦‚ä¸Šå®šä¹‰åï¼Œåœ¨æ­¥éª¤2ä¸­åˆ™å¯ä»¥å®šä¹‰loraçš„æ­£åˆ™åŒ¹é…è§„åˆ™ä¸ºï¼š`r'.*dense1|.*dense2|.*dense3'`

2. å®šä¹‰loraçš„é…ç½®å‚æ•°ä¿®æ”¹å·²æœ‰çš„é…ç½®æ–‡ä»¶ï¼Œå¦‚æ ¹æ®`configs/gpt2/run_gpt2.yaml`ï¼Œåœ¨`model_config`ä¸­å¢åŠ loraç›¸å…³çš„é…ç½®ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```yaml
model:
  model_config:
    type: GPT2Config
    ...
    pet_config: # configurition of lora
      pet_type: lora
      lora_rank: 8
      lora_alpha: 16
      lora_dropout: 0.1
      target_modules: ".*dense1|.*dense2|.*dense3"
  arch:
    type: GPT2LMHeadModel
```

ä¿®æ”¹å®Œæ¯•åï¼Œå¯ä»¥å‚è€ƒè®­ç»ƒæµç¨‹ä½¿ç”¨è¯¥é…ç½®æ–‡ä»¶è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚

3. ä½¿ç”¨MindFormerçš„Trainerè¿›è¡Œæ¨¡å‹è®­ç»ƒï¼š

```python
import mindspore as ms
from mindformers.trainer.trainer import Trainer

ms.set_context(mode=0) # è®¾å®šä¸ºå›¾æ¨¡å¼åŠ é€Ÿ

gpt2_trainer = Trainer(
    task='text_generation',
    model='gpt2',
    pet_method='lora',
    train_dataset="/data/wikitext-2/train",
)

gpt2_trainer.finetune()
```

è‡³æ­¤ï¼Œå®Œæˆäº†ä¸€ä¸ªå¾®è°ƒç®—æ³•é€‚é…è¿‡ç¨‹ï¼Œæœ€åæ‰§è¡Œä¸Šè¿°æ­¥éª¤3ä¸­çš„ä»£ç å³å¯æ‹‰èµ·å¾®è°ƒç®—æ³•çš„è®­ç»ƒæµç¨‹ã€‚

## P-Tuning v2ä½¿ç”¨ç¤ºä¾‹

ä¿®æ”¹è®­ç»ƒä»»åŠ¡å‚æ•°ï¼Œä¸»è¦ä¿®æ”¹æ¨¡å‹é…ç½®yaml, æ·»åŠ pet_configé…ç½®ï¼š

```yaml
model:
  model_config:
    type: LlamaConfig
    ...
    num_layers: 32
    kv_channels: 128
    num_attention_heads: 32
    pet_config:
      pet_type: ptuning2 # æ¨¡å‹ç±»åˆ«ï¼Œä¼šæ ¹æ®å­—ç¬¦æ˜ å°„åˆ°ç›¸åº”å¾®è°ƒç®—æ³•
      pre_seq_len: 16 # å‰ç¼€é•¿åº¦ï¼Œå–å†³äºæ•°æ®é›†è§„æ¨¡
      prefix_projection: True # æ˜¯å¦åŠ æŠ•å½±å±‚
      projection_dim: 128 # ä¸­é—´æŠ•å½±ç»´åº¦
      dropout_rate: 0.01 # èŠ‚ç‚¹å¼ƒç½®ç‡
  arch:
    # æ›¿æ¢ä¸ºé€‚é…å¾®è°ƒç®—æ³•çš„æ¨¡å‹
    type: LlamaForCausalLM
```

æ³¨æ„ï¼šP-Tuning v2å‰ç¼€é•¿åº¦è¦å’Œæ•°æ®é›†è§„æ¨¡ç›¸åŒ¹é…ï¼Œå…·ä½“å®éªŒè¿‡ç¨‹ä¸­åœ¨5000æ¡æ•°æ®ä¸‹å‰ç¼€é•¿åº¦è¶…è¿‡60ä¼šå¯¼è‡´lossæ”¶æ•›æ¬ ä½³ï¼Œé¢„æµ‹è¾“å‡ºä¹±ç 

## Prefix-Tuning ä½¿ç”¨ç¤ºä¾‹

ä¿®æ”¹è®­ç»ƒä»»åŠ¡å‚æ•°ï¼Œä¸P-Tuning v2ä½¿ç”¨æ–¹æ³•ç›¸åŒä¸»è¦ä¿®æ”¹æ¨¡å‹é…ç½®yaml, æ·»åŠ pet_configé…ç½®ï¼š

```yaml
model:
  model_config:
    type: LlamaConfig
    ...
    num_layers: 32
    kv_channels: 128
    num_attention_heads: 32
    pet_config:
      pet_type: prefixtuning # æ¨¡å‹ç±»åˆ«ï¼Œä¼šæ ¹æ®å­—ç¬¦æ˜ å°„åˆ°ç›¸åº”å¾®è°ƒç®—æ³•
      prefix_token_num: 32 # å‰ç¼€é•¿åº¦ï¼Œå–å†³äºæ•°æ®é›†è§„æ¨¡
      mid_dim: 512 # ä¸­é—´æŠ•å½±ç»´åº¦
      dropout_rate: 0.05 # èŠ‚ç‚¹å¼ƒç½®ç‡
  arch:
    # æ›¿æ¢ä¸ºé€‚é…å¾®è°ƒç®—æ³•çš„æ¨¡å‹
    type: LlamaForCausalLM
```

æ³¨æ„ï¼šPrefix-Tuningå‰ç¼€é•¿åº¦è¦å’Œæ•°æ®é›†è§„æ¨¡ç›¸åŒ¹é…ï¼Œå…·ä½“å®éªŒè¿‡ç¨‹ä¸­åœ¨5000æ¡æ•°æ®ä¸‹å‰ç¼€é•¿åº¦è¶…è¿‡60ä¼šå¯¼è‡´lossæ”¶æ•›æ¬ ä½³ï¼Œé¢„æµ‹è¾“å‡ºä¹±ç 

## æ³¨æ„äº‹é¡¹

å½“ä½¿ç”¨å¾®è°ƒç®—æ³•æ—¶éœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­å°†`parallel.strategy_ckpt_config.only_trainable_params`è®¾ä¸º`False`ï¼Œé€šè¿‡è¯¥é…ç½®é¡¹ä½¿èƒ½åœ¨æ¨¡å‹ç¼–è¯‘è¿‡ç¨‹ä¸­ä¿å­˜æ‰€æœ‰å‚æ•°çš„åˆ‡åˆ†ç­–ç•¥ï¼Œä¿è¯åœ¨æƒé‡è‡ªåŠ¨è½¬æ¢ï¼Œä»¥åŠåç»­æƒé‡åˆå¹¶æ—¶èƒ½å¤Ÿæ­£ç¡®æ‰§è¡Œï¼Œå…·ä½“è®¾ç½®å¦‚ä¸‹æ‰€ç¤ºï¼š

```yaml
parallel:
  strategy_ckpt_config:
    save_file: "./ckpt_strategy.ckpt"
    only_trainable_params: False # è®¾ç½®æˆ Falseï¼Œä½¿èƒ½ç­–ç•¥æ–‡ä»¶ä¸­ä¿å­˜æ‰€æœ‰å‚æ•°çš„åˆ‡åˆ†ç­–ç•¥ï¼Œä¿è¯åœ¨æƒé‡è‡ªåŠ¨è½¬æ¢ï¼Œä»¥åŠåç»­æƒé‡åˆå¹¶æ—¶èƒ½å¤Ÿæ­£ç¡®æ‰§è¡Œ
```
