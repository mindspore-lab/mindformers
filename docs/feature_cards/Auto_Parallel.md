# è‡ªåŠ¨å¹¶è¡Œ

> ## ğŸš¨ å¼ƒç”¨è¯´æ˜
>
> æœ¬æ–‡æ¡£å·²è¿‡æ—¶ï¼Œä¸å†è¿›è¡Œç»´æŠ¤ï¼Œå¹¶å°†åœ¨ *1.5.0* ç‰ˆæœ¬ä¸‹æ¶ï¼Œå…¶ä¸­å¯èƒ½åŒ…å«è¿‡æ—¶çš„ä¿¡æ¯æˆ–å·²è¢«æ›´æ–°çš„åŠŸèƒ½æ›¿ä»£ã€‚å»ºè®®å‚è€ƒæœ€æ–°çš„ **[å®˜æ–¹æ–‡æ¡£](https://www.mindspore.cn/mindformers/docs/zh-CN/dev/index.html)** ï¼Œä»¥è·å–å‡†ç¡®çš„ä¿¡æ¯ã€‚
>
> å¦‚æœæ‚¨ä»éœ€ä½¿ç”¨æœ¬æ–‡æ¡£ä¸­çš„å†…å®¹ï¼Œè¯·ä»”ç»†æ ¸å¯¹å…¶é€‚ç”¨æ€§ï¼Œå¹¶ç»“åˆæœ€æ–°ç‰ˆæœ¬çš„ç›¸å…³èµ„æºè¿›è¡ŒéªŒè¯ã€‚
>
> å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ **[ç¤¾åŒºIssue](https://gitee.com/mindspore/mindformers/issues/new)** æäº¤åé¦ˆã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£ä¸æ”¯æŒï¼

è‡ªåŠ¨å¹¶è¡Œæ¨¡å¼è®©ç”¨æˆ·å¯ä»¥æ— éœ€ä¸ºç½‘ç»œä¸­çš„æ¯ä¸€ä¸ªç®—å­é…ç½®å¹¶è¡Œç­–ç•¥ï¼Œå³å¯è¾¾åˆ°é«˜æ•ˆå¹¶è¡Œè®­ç»ƒçš„æ•ˆæœã€‚å½“å‰MindSporeæ”¯æŒå¦‚ä¸‹ä¸¤ç§ä¸åŒçš„è‡ªåŠ¨å¹¶è¡Œæ–¹æ¡ˆï¼š

- [åˆ‡åˆ†ç­–ç•¥ä¼ æ’­ç®—æ³•(sharding_propagation)](https://www.mindspore.cn/docs/zh-CN/master/model_train/parallel/sharding_propagation.html)ï¼šç”±å°‘é‡ä½¿ç”¨shardæ¥å£é…ç½®å¹¶è¡Œç­–ç•¥çš„ç®—å­ï¼Œå‘æœªé…ç½®çš„ç®—å­ä¼ æ’­å¹¶è¡Œç­–ç•¥ã€‚åœ¨ä¼ æ’­æ—¶ï¼Œç®—æ³•ä¼šå°½é‡é€‰å–æœ€å°‘å¼•å‘å¼ é‡é‡æ’å¸ƒé€šä¿¡çš„ç­–ç•¥ã€‚
- [åŒé€’å½’ç­–ç•¥æœç´¢ç®—æ³•(recursive_programming)](https://www.mindspore.cn/docs/zh-CN/master/model_train/parallel/sapp.html)ï¼šç”¨æˆ·æ— éœ€è¿›è¡Œä»»ä½•ç®—å­å¹¶è¡Œç­–ç•¥é…ç½®ã€‚å…¶åŸºäºç¬¦å·è¿ç®—çš„ä»£ä»·æ¨¡å‹å¯ä»¥è‡ªç”±é€‚é…ä¸åŒçš„åŠ é€Ÿå™¨é›†ç¾¤ï¼Œå¯¹äºå·¨å¤§ç½‘ç»œä»¥åŠå¤§è§„æ¨¡å¤šå¡åˆ‡åˆ†èƒ½å¤Ÿä¿è¯å¿«é€Ÿç”Ÿæˆæœ€ä¼˜ç­–ç•¥ã€‚

è¯¦æƒ…å‚è€ƒå®˜ç½‘å…³äº[è‡ªåŠ¨å¹¶è¡Œ](https://www.mindspore.cn/docs/zh-CN/master/model_train/parallel/auto_parallel.html)çš„è¯´æ˜ã€‚

## ä½¿ç”¨è¯´æ˜

**å½“å‰æœ¬ç‰¹æ€§ä¸ºå®éªŒæ€§ç‰¹æ€§ã€‚**
å½“å‰MindFormersä»“æ”¯æŒä½¿ç”¨åŒé€’å½’ç­–ç•¥æœç´¢ç®—æ³•(recursive_programming)ï¼Œè¿›è¡Œè‡ªåŠ¨åŒ–çš„å¹¶è¡Œç­–ç•¥ç”Ÿæˆã€‚åç»­ä¼šæ–°å¢æ”¯æŒåˆ‡åˆ†ç­–ç•¥ä¼ æ’­ç®—æ³•(sharding_propagation)ã€‚ç›®å‰éªŒè¯è¿‡çš„æ¨¡å‹å¦‚ä¸‹æ‰€ç¤ºï¼š

|    æ¨¡å‹    |    è‡ªåŠ¨å¹¶è¡Œç®—æ³•        |          å‚æ•°é‡           |
| :--------: | :-------------------: | :-----------------------: |
|   LLaMA2   | recursive_programming | 7B<br>13B<br>70B<br>lora |
|  Baichuan2 | recursive_programming | 7B<br>13B<br>lora |
|    Qwen    | recursive_programming | 7B<br>14B<br>lora |
| PanguAlpha | recursive_programming | 2.6B<br>13B       |

åœ¨æ¨¡å‹å¯¹åº”çš„configsè·¯å¾„ä¸‹ï¼Œæä¾›äº†auto_parallelçš„yamlé…ç½®æ–‡ä»¶ï¼Œç”¨æˆ·å¯ä»¥å¿«é€Ÿå¯åŠ¨å•æœºå¤šå¡æˆ–å¤šæœºå¤šå¡çš„è‡ªåŠ¨å¹¶è¡Œè®­ç»ƒã€‚

è‡ªåŠ¨å¹¶è¡Œæ¨¡å¼åœ¨**mindspore r2.2ç‰ˆæœ¬åŠä¹‹åç‰ˆæœ¬**ç”Ÿæ•ˆï¼Œåœ¨**mindspore 2.1åŠä¹‹å‰ç‰ˆæœ¬**é‡‡ç”¨åŠè‡ªåŠ¨å¹¶è¡Œæ¨¡å¼ã€‚ç”¨æˆ·æ ¹æ®ä½¿ç”¨mindsporeç‰ˆæœ¬é€‰æ‹©å¯¹åº”çš„yamlé…ç½®æ–‡ä»¶ã€‚è‡ªåŠ¨å¹¶è¡Œæ¨¡å¼é…ç½®æ–‡ä»¶å¸¦æœ‰"auto_parallel"åç¼€ã€‚

ä½¿ç”¨è‡ªåŠ¨å¹¶è¡Œæ¨¡å¼éœ€è¦é…ç½®ä»¥ä¸‹å‚æ•°ï¼š

```yaml
use_parallel: True
parallel:
  parallel_mode: 2
  search_mode: "recursive_programming"
  auto_pipeline: True
parallel_config:
  mem_coeff: 0.1
```

- `use_parallel`: å¯ç”¨å¹¶è¡Œæ¨¡å¼çš„å¸ƒå°”å€¼
- `parallel_mode`: è®¾ç½®å¹¶è¡Œæ¨¡å¼çš„æ•´æ•°å€¼ï¼Œå…¶ä¸­0ä»£è¡¨æ•°æ®å¹¶è¡Œï¼Œ1ä»£è¡¨åŠè‡ªåŠ¨å¹¶è¡Œï¼Œ2ä»£è¡¨è‡ªåŠ¨å¹¶è¡Œ
- `search_mode`: è®¾ç½®æœç´¢æ¨¡å¼çš„å­—ç¬¦ä¸²ï¼Œå¯è®¾ç½®recursive_programmingæˆ–è€…sharding_propagation

ç”¨æˆ·å¯ä»¥é€šè¿‡ä»¥ä¸‹å‚æ•°è‡ªå®šä¹‰è‡ªåŠ¨å¹¶è¡Œçš„è¡Œä¸º:

- `mem_coeff`: æ­£æµ®ç‚¹å€¼ï¼Œè¡¨ç¤ºé«˜æ€§èƒ½çš„æ•°æ®å¹¶è¡Œç­–ç•¥ï¼ˆè®¾ç½®æˆè¾ƒå°å€¼ï¼Œä¾‹å¦‚<1ï¼‰å’Œä½å†…å­˜å ç”¨çš„æ¨¡å‹å¹¶è¡Œç­–ç•¥ï¼ˆè®¾ç½®æˆè¾ƒå¤§å€¼ï¼Œä¾‹å¦‚>1ï¼‰ä¹‹é—´çš„æƒè¡¡
- `auto_pipeline`: å¯ç”¨è‡ªåŠ¨æµæ°´çº¿é˜¶æ®µæ•°é€‰æ‹©çš„å¸ƒå°”å€¼

## batch_size

è‡ªåŠ¨å¹¶è¡Œä¸‹çš„*batch_size*é…ç½®é¡¹å’ŒåŠè‡ªåŠ¨å¹¶è¡Œä¸‹çš„*batch_size*ç•¥æœ‰ä¸åŒã€‚è¿™æ˜¯å› ä¸ºè‡ªåŠ¨å¹¶è¡Œä¸‹ä¸å­˜åœ¨åŠè‡ªåŠ¨å¹¶è¡Œçš„æ•°æ®å¹¶è¡Œæ•°ï¼ˆ*data_parallel_num*ï¼‰çš„æ¦‚å¿µï¼Œæ¯ä¸ªç®—å­çš„æ•°æ®å¹¶è¡Œå’Œæ¨¡å‹åˆ‡åˆ†éƒ½ä¸å°½ç›¸åŒï¼Œæ²¡æœ‰ç»Ÿä¸€çš„æ•°æ®å¹¶è¡Œæ•°å’Œæ¨¡å‹å¹¶è¡Œæ•°ã€‚

| Pipeline | Full Batch | Global batch size formula |
| :------: | :--------: | :------------------------ |
| False    | False      | `batch_size * device_num * micro_batch_interleave_num * gradient_accumulation_steps` |
| False    | True       | `batch_size * data_parallel * micro_batch_interleave_num * gradient_accumulation_steps` |
| True     | False      | `batch_size * device_num * micro_batch_interleave_num * micro_batch_num` |
| True     | True       | `batch_size * data_parallel * micro_batch_interleave_num * micro_batch_num` |

å¯ä»¥çœ‹åˆ°è‡ªåŠ¨å¹¶è¡Œä¸‹çš„*batch_size*å®é™…ä¸Šç›¸å½“äºåŠè‡ªåŠ¨å¹¶è¡Œæ¦‚å¿µä¸‹çš„ `batch_size * data_parallel`

## mem_coeff

åœ¨ yaml é…ç½®æ–‡ä»¶ä¸‹æ–°å¢äº† mem_coeff é…ç½®é¡¹ï¼Œç”¨æ¥æ§åˆ¶è‡ªåŠ¨å¹¶è¡Œç­–ç•¥ç”Ÿæˆæ—¶ï¼Œæ›´å€¾å‘äºæ•°æ®å¹¶è¡Œæˆ–è€…æ¨¡å‹å¹¶è¡Œã€‚æ­¤é…ç½®é¡¹çš„é»˜è®¤å€¼ä¸º0.1ï¼Œæ›´å€¾å‘äºè¿›è¡Œæ•°æ®å¹¶è¡Œï¼Œä½†å½“æ¨¡å‹å‚æ•°é‡è¾ƒå¤§æ—¶ï¼Œé‡‡ç”¨æ›´å¤šçš„æ•°æ®å¹¶è¡Œä¼šæ›´å¯èƒ½å‡ºç°å†…å­˜ä¸è¶³çš„æŠ¥é”™ã€‚æ­¤æ—¶ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡å¢å¤§ mem_coeff çš„å€¼æ¥æ§åˆ¶è‡ªåŠ¨å¹¶è¡Œç­–ç•¥ç”Ÿæˆæ›´å€¾å‘äºæ¨¡å‹å¹¶è¡Œï¼Œmem_coeff å€¼è¶Šå¤§ï¼Œæ¨¡å‹å¹¶è¡Œæ•°è¶Šå¤§ï¼ˆ**å»ºè®®ç”¨æˆ·ä»¥4ä¸ºå› æ•°å€å¢**ï¼‰ã€‚

**å½“å‰yamlé…ç½®æ–‡ä»¶ä¸‹çš„mem_coeffé…ç½®å€¼å·²ç»æ˜¯æœ€ä¼˜ï¼Œé€šå¸¸ä¸éœ€è¦ç”¨æˆ·è¿›è¡Œè°ƒæ•´ã€‚**

### è‡ªå®šä¹‰mem_coeff

è¦åˆ†é…ä¸€ä¸ªåˆé€‚çš„mem_coeffï¼Œéœ€è¦å¯¹åŒé€’å½’ç­–ç•¥æœç´¢ç®—æ³•æœ‰ä¸€ä¸ªç²—ç•¥çš„äº†è§£ã€‚

1. é¦–å…ˆæ„å»ºåŒ…å«ä¸»è¦ç®—å­ï¼ˆä¾‹å¦‚çŸ©é˜µä¹˜æ³•ï¼‰çš„è®¡ç®—å›¾ã€‚
2. é€’å½’åœ°ä¸ºæ‰€æœ‰ä¸»è¦ç®—å­é€‰æ‹©åˆ‡åˆ†ç­–ç•¥ã€‚
3. æœ€åå°†ä¸»è¦ç®—å­çš„åˆ‡åˆ†ç­–ç•¥ä¼ æ’­åˆ°å…¶ä»–ç®—å­ã€‚

åœ¨æ­¥éª¤2ä¸­ï¼Œä¼šé€šè¿‡ä»£ä»·æ¨¡å‹åˆ†ææ¯ä¸€ä¸ªåˆ‡åˆ†ç­–ç•¥çš„costï¼Œæœ€ç»ˆé€‰æ‹©costæœ€å°çš„åˆ‡åˆ†ç­–ç•¥ã€‚ä»¥çŸ©é˜µä¹˜æ³•ç®—å­ä¸ºä¾‹ï¼Œåœ¨çŸ©é˜µä¹˜æ³•çš„åˆ‡åˆ†ç­–ç•¥ä¸Šæœ‰å››ä¸ªé€‰æ‹©ï¼Œåˆ†åˆ«æ˜¯åˆ‡iè½´ã€åˆ‡jè½´ã€åˆ‡kè½´å’Œä¸åˆ‡åˆ†ï¼š

$$
C_{ij} = \sum_k A_{ik} \cdot B_{kj}
$$

`mem_coeff`æ˜¯ä»£ä»·æ¨¡å‹çš„ä¸€ä¸ªç³»æ•°ã€‚
æœ€é«˜çš„å€¼ä¼šå¼•å¯¼ä»£ä»·æ¨¡å‹åå‘æ¨¡å‹å¹¶è¡Œçš„åˆ‡åˆ†ç­–ç•¥ï¼ˆæ¯”å¦‚åˆ‡jè½´æˆ–åˆ‡kè½´ï¼‰ï¼Œé€šå¸¸æ˜¯æœ€èŠ‚çœå†…å­˜çš„ã€‚
è¾ƒä½çš„å€¼ä¼šå¼•å¯¼ä»£ä»·æ¨¡å‹åå‘æ•°æ®å¹¶è¡Œçš„åˆ‡åˆ†ç­–ç•¥ï¼ˆæ¯”å¦‚åˆ‡iè½´ï¼‰ï¼Œé€šå¸¸æ˜¯æœ€èŠ‚çœæ—¶é—´ã€æ€§èƒ½æœ€å¥½çš„ã€‚
æœ€ä½çš„å€¼ä¼šå¼•å¯¼ä»£ä»·æ¨¡å‹åå‘ä¸åˆ‡åˆ†çš„ç­–ç•¥ï¼Œè¿™æ˜¯æœ€ä¸èŠ‚çœå†…å­˜ä½†å¯¹äºå°ç®—å­å¯èƒ½æ˜¯æ€§èƒ½æœ€å¥½çš„ã€‚

`mem_coeff`åªæ˜¯ä»£ä»·æ¨¡å‹ä¸­çš„ä¸€ä¸ªç³»æ•°ï¼Œç›¸åŒçš„å€¼ä¸èƒ½ç¡®ä¿ä»£ä»·æ¨¡å‹åœ¨æ‰€æœ‰åœºæ™¯ä¸‹åšå‡ºåŒæ ·çš„é€‰æ‹©ã€‚
é»˜è®¤å€¼ 0.1 é€šå¸¸æœ‰åˆ©äºæ•°æ®å¹¶è¡Œï¼Œä½†å¹¶ä¸æ€»æ˜¯å¦‚æ­¤ã€‚
å¦‚æœç”¨æˆ·æƒ³è¦è¿›è¡Œçº¯æ•°æ®å¹¶è¡Œï¼Œé‚£ä¹ˆå¯ä»¥é€šè¿‡è°ƒæ•´`mem_coeff`è¾¾åˆ°æ•ˆæœã€‚

### æŒ‡å¯¼æ•™ç¨‹

å‡è®¾å½“å‰é…ç½®äº† `mem_coeff = 0.01` ï¼Œè‡ªåŠ¨å¹¶è¡Œæ ¹æ®ä»£ä»·æ¨¡å‹ä¸ºä¸€éƒ¨åˆ†ç®—å­ç”Ÿæˆäº†ä¸åˆ‡åˆ†çš„ç­–ç•¥ï¼Œç”¨æˆ·æƒ³è¦æ‰€æœ‰ç®—å­éƒ½æ˜¯çº¯æ•°æ®å¹¶è¡Œç­–ç•¥ã€‚ã€‚

#### 1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶

åœ¨æ—¥å¿—ä¸­æœç´¢å­—ç¬¦ä¸² â€œChoose NOT to cutâ€ï¼Œå¹¶æŸ¥çœ‹ä»£ä»·æ¨¡å‹ä¸­å„ä¸ªé€‰æ‹©çš„costã€‚
å¦‚æœæ²¡æœ‰å‡ºç°è¿™ä¸ªå­—ç¬¦ä¸²ï¼Œåˆ™è¡¨æ˜`mem_coeff`ä¸ä¼šå¯¼è‡´ä»£ä»·æ¨¡å‹åšå‡ºä¸åˆ‡åˆ†ç­–ç•¥çš„å†³ç­–ã€‚

```text
If the I-axis is cut, the op-cost is 20.48, the rest-cost is 0, and the total cost is 20.48
If the K-axis is cut, the op-cost is 4096, the rest-cost is 0, and the total cost is 4096
If do NOT cut the axis, the op-cost is 16.7772, the rest-cost is 0, and the total cost is 16.7772
The costs of cutting the I-axis/J-axis/K-axis/no_cut are : [const vector]{20.48, 1.79749e+308, 4096, 16.772}
Choose NOT to cut
```

#### 2. æŸ¥çœ‹æ•°æ®å¹¶è¡Œç­–ç•¥ï¼ˆåˆ‡iè½´ï¼‰çš„æ€»cost

åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œä»£ä»·æ¨¡å‹åˆ‡iè½´çš„æ€»$\newcommand{\costi}{\mathit{cost_i}}\costi$æ˜¯20.48ï¼Œå…¶ä¸­ç®—å­costæ˜¯20.48ï¼Œé‡æ’å¸ƒcostæ˜¯0.

#### 3. æŸ¥çœ‹ä¸åˆ‡åˆ†ç­–ç•¥çš„æ€»cost

åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œä»£ä»·æ¨¡å‹ä¸åˆ‡åˆ†çš„æ€»$\newcommand{\costr}{\mathit{cost_{rep}}}\costr$æ˜¯16.7772ï¼Œå…¶ä¸­ç®—å­costæ˜¯16.7772ï¼Œé‡æ’å¸ƒcostæ˜¯0.

#### 4. æ ¹æ®å…¬å¼è®¡ç®—å‡ºä¸€ä¸ªæ–°mem_coef($\newcommand{\coeffnew}{\mathit{coeff_{new}}}\coeffnew$)ï¼Œè®©ä»£ä»·æ¨¡å‹åˆ‡iè½´çš„æ€»costæ›´å°ï¼Œè¾¾åˆ°é€‰æ‹©åˆ‡iè½´çš„ç›®çš„

$$
\newcommand{\coeffold}{\mathit{coeff_{old}}}
\coeffnew = \frac{\costi \cdot \coeffold}{\costr} = \frac{20.48 \cdot 0.01}{16.7772} = 0.012207
$$

#### 5. é€‰æ‹©ä¸€ä¸ªç•¥é«˜äºæ–°mem_coeffçš„æ•°å€¼ï¼Œå³`mem_coeff = 0.013`

## auto_pipeline

åœ¨ yaml é…ç½®æ–‡ä»¶ä¸‹æ–°å¢äº† `auto_pipeline` é…ç½®é¡¹ï¼Œç”¨æ¥å†³å®šæ˜¯å¦ç”±è‡ªåŠ¨å¹¶è¡Œæ¨¡å¼ä¸ºæµæ°´çº¿å¹¶è¡Œï¼ˆpipeline stageï¼‰ç”Ÿæˆç­–ç•¥ï¼ˆpipeline stage numberï¼‰ã€‚å¦‚æœè®¾ç½®æˆTrueï¼Œé‚£ä¹ˆç”¨æˆ·æ— éœ€é…ç½®æµæ°´çº¿å¹¶è¡Œï¼Œè‡ªåŠ¨å¹¶è¡Œæ¨¡å¼ä¼šè‡ªåŠ¨ç”Ÿæˆåˆé€‚çš„æµæ°´çº¿å¹¶è¡Œç­–ç•¥ã€‚å¦‚æœè®¾ç½®ä¸ºFalseï¼Œé‚£ä¹ˆæ¨¡å‹ä¼šæ‰§è¡Œç”¨æˆ·é…ç½®çš„æµæ°´çº¿å¹¶è¡Œï¼ŒåŒæ—¶è‡ªåŠ¨å¹¶è¡Œæ¨¡å¼ä¼šåœ¨LOGä¸­å»ºè®®ä¸€ä¸ªåˆé€‚çš„æµæ°´çº¿å¹¶è¡Œç­–ç•¥ã€‚è¯·æ³¨æ„ï¼Œè‡ªåŠ¨å¹¶è¡ŒåŠŸèƒ½ç”Ÿæˆçš„æµæ°´çº¿å¹¶è¡Œç­–ç•¥ï¼ˆpipeline stage numberï¼‰ä¸ä¼šè¶…è¿‡ç”¨æˆ·å®šä¹‰çš„`micro_batch_num`ã€‚

## Performance benchmarks

Comparison between performances of semi parallel versus SAPP.
The SpeedUp is given by the ratio of average "tokens per second" of auto parallel and average "tokens per second" of semi parallel. Hence a SpeedUp above 100% means that auto parallel runs faster than the semi parallel version.

| model | parallel_config in semi | mem_coeff in auto | SpeedUp |
|---|---|---|---|
| Baichuan2-7B | dp=8, mp=1, pp=1 | 0.01 | 97.4% |
| Baichuan2-13B | dp=8, mp=1, pp=1 | 0.01 | 98.0% |
| Qwen-7B | dp=2, mp=4, pp=1 | 4.5 | 96.2% |
| Qwen-14B | dp=1, mp=8, pp=1 | 4.5 |  111.3% |
| LLaMA2-7B | dp=8, mp=1, pp=1 | 0.1 | 101.2% |
| LLaMA2-13B | dp=8, mp=1, pp=1 | 0.1 | 99.8% |
| LLaMA2-70B | dp=2, mp=4, pp=8 | 0.1 | 93.5% |

These benchmarks have been carried out on a machine with 8 devices Ascend (except LLaMA2-70B which ran on 8 nodes, 64 devices) using the default .yaml files in the mindformers repository.
The software configuration is:

- MindSpore v2.3.0
- Mindformers 1.2.0

