# Qwen3

## æ¨¡å‹æè¿°

Qwen3 æ˜¯ Qwen ç³»åˆ—æœ€æ–°ä¸€ä»£çš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚åŸºäºå¹¿æ³›çš„è®­ç»ƒï¼ŒQwen3 åœ¨æ¨ç†ã€æŒ‡ä»¤è·Ÿéšã€ä»£ç†èƒ½åŠ›å’Œå¤šè¯­è¨€æ”¯æŒæ–¹é¢å®ç°äº†çªç ´æ€§è¿›å±•ã€‚

```text
@misc{qwen3technicalreport,
      title={Qwen3 Technical Report},
      author={Qwen Team},
      year={2025},
      eprint={2505.09388},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.09388},
}
```

## æ”¯æŒè§„æ ¼

|    æ¨¡å‹åç§°    |  è§„æ ¼  | æ”¯æŒä»»åŠ¡ | æ¨¡å‹æ¶æ„  |                       æ”¯æŒè®¾å¤‡                        |                  æ¨¡å‹çº§åˆ«                  |
|:----------:|:----:|:----:|:-----:|:-------------------------------------------------:|:--------------------------------------:|
|   Qwen3    | 32B  | é¢„è®­ç»ƒ  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Validated](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)          |
|   Qwen3    | 32B  | å¾®è°ƒ  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Validated](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)          |
|   Qwen3    | 14B  | å¾®è°ƒ  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Preliminary](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)          |
|   Qwen3    | 8B  | å¾®è°ƒ  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Preliminary](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)          |
|   Qwen3    | 4B  | å¾®è°ƒ  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Preliminary](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)          |
|   Qwen3    | 1.7B  | å¾®è°ƒ  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Preliminary](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)          |
|   Qwen3    | 0.6B  | å¾®è°ƒ  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Preliminary](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)          |
|   Qwen3    | 32B  |  æ¨ç†  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Released](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)           |
|   Qwen3    | 0.6B |  æ¨ç†  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Validated](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)          |
|   Qwen3    |  8B  |  æ¨ç†  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Validated](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)          |
|   Qwen3    | 1.7B |  æ¨ç†  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Untested](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)           |
|   Qwen3    |  4B  |  æ¨ç†  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Untested](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)           |
|   Qwen3    | 14B  |  æ¨ç†  | Mcore | Atlas 800T A2/Atlas 800I A2/Atlas 900 A3 SuperPoD |          [Untested](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#%E6%A8%A1%E5%9E%8B%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D)           |

è¯´æ˜ï¼š

- æ¨¡å‹æ¶æ„ï¼š`Mcore` è¡¨ç¤º 1.6.0 å‘å¸ƒçš„æ–°æ¨¡å‹æ¶æ„ï¼Œ`Legacy` è¡¨ç¤ºåŸæœ‰æ¨¡å‹æ¶æ„ã€‚è¯¦è§[æ¶æ„è¯´æ˜](https://www.mindspore.cn/mindformers/docs/zh-CN/master/introduction/overview.html)ã€‚
- æ¨¡å‹çº§åˆ«ï¼šè®­ç»ƒå’Œæ¨ç†å„åˆ†ä¸º5ä¸ªçº§åˆ«ï¼Œåˆ†åˆ«ä»£è¡¨è¯¥æ¨¡å‹éµå¾ªä¸åŒçš„æ ‡å‡†ä¸Šçº¿ã€‚æ¯ä¸ªçº§åˆ«çš„ä»‹ç»è¯¦è§[æ¨¡å‹çº§åˆ«ä»‹ç»](https://gitee.com/mindspore/mindformers/blob/master/README_CN.md#æ¨¡å‹çº§åˆ«ä»‹ç»)ã€‚

## ç‰ˆæœ¬é…å¥—

Qwen3 å½“å‰æ”¯æŒçš„ç‰ˆæœ¬é…å¥—å¦‚ä¸‹ã€‚

|           | Mindspore Transformers | MindSpore | CANN | HDK |
|:---------:|:----------------------:|:---------:|:----:|:---:|
| å½“å‰æ”¯æŒçš„ç‰ˆæœ¬ |           åœ¨ç ”ç‰ˆæœ¬           |    åœ¨ç ”ç‰ˆæœ¬     |  åœ¨ç ”ç‰ˆæœ¬  | åœ¨ç ”ç‰ˆæœ¬  |

## ä½¿ç”¨æ ·ä¾‹

MindSpore Transformers æ”¯æŒä½¿ç”¨ Qwen3 è¿›è¡Œé¢„è®­ç»ƒå’Œæ¨ç†ã€‚å„ä»»åŠ¡çš„æ•´ä½“ä½¿ç”¨æµç¨‹å¦‚ä¸‹ï¼š

| ä»»åŠ¡  | å‰æœŸå‡†å¤‡                    | ä½¿ç”¨æµç¨‹                       |
|:---:|:------------------------|:---------------------------|
| é¢„è®­ç»ƒ | ç¯å¢ƒå®‰è£… -> é¢„è®­ç»ƒæ•°æ®é›†ä¸‹è½½        | æ•°æ®é¢„å¤„ç† -> ä¿®æ”¹ä»»åŠ¡é…ç½® -> å¯åŠ¨é¢„è®­ç»ƒä»»åŠ¡ |
| å¾®è°ƒ | ç¯å¢ƒå®‰è£… -> æ¨¡å‹ä¸‹è½½        |  ä¿®æ”¹ä»»åŠ¡é…ç½® -> å¯åŠ¨å¾®è°ƒä»»åŠ¡ |
| æ¨ç†  |  ç¯å¢ƒå®‰è£… -> æ¨¡å‹ä¸‹è½½                       |    ä¿®æ”¹ä»»åŠ¡é…ç½® -> å¯åŠ¨æ¨ç†ä»»åŠ¡                        |

### å‰æœŸå‡†å¤‡

#### ç¯å¢ƒå®‰è£…

æŒ‰ç…§ä¸Šè¿°ç‰ˆæœ¬é…å¥—ï¼Œå‚è€ƒ[ç¯å¢ƒå®‰è£…æŒ‡å—](https://www.mindspore.cn/mindformers/docs/zh-CN/master/installation.html)å®‰è£…è¿è¡Œç¯å¢ƒã€‚

#### æ¨¡å‹ä¸‹è½½

ç”¨æˆ·å¯ä»¥ä»Hugging Faceã€ModelScopeç­‰å¼€æºç¤¾åŒºä¸‹è½½æ‰€éœ€çš„æ¨¡å‹æ–‡ä»¶ï¼ŒåŒ…æ‹¬æ¨¡å‹æƒé‡ã€Tokenizerã€é…ç½®ç­‰ï¼ˆé‡å¤´é¢„è®­ç»ƒä¸éœ€åŠ è½½æƒé‡ï¼‰ã€‚ é“¾æ¥å¦‚ä¸‹ï¼š

|      æ¨¡å‹åç§°       | ä¸‹è½½é“¾æ¥                                                                                                                                                                                       | è¯´æ˜ |
|:---------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---|
| Qwen/Qwen3-0.6B | [Hugging Face](https://huggingface.co/Qwen/Qwen3-0.6B) / [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-0.6B)                                                              |    |
| Qwen/Qwen3-1.7B | [Hugging Face](https://huggingface.co/Qwen/Qwen3-1.7B) / [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-1.7B)                                                              |    |
|  Qwen/Qwen3-4B  | [Hugging Face](https://huggingface.co/Qwen/Qwen3-4B) / [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-4B)                                                                  |    |
|  Qwen/Qwen3-8B  | [Hugging Face](https://huggingface.co/Qwen/Qwen3-8B) / [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-8B)                                                                  |    |
| Qwen/Qwen3-14B  | [Hugging Face](https://huggingface.co/Qwen/Qwen3-14B) / [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-14B)                                                                |    |
| Qwen/Qwen3-32B  | [Hugging Face](https://huggingface.co/Qwen/Qwen3-32B) / [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-32B)         |    |

#### æ•°æ®é›†ä¸‹è½½

MindSpore Transformers ä»¥ä¸‹é¢çš„æ•°æ®é›†ä¸ºä¾‹æä¾›äº† Qwen3 çš„é¢„è®­ç»ƒæµç¨‹çš„ä½¿ç”¨æ¡ˆä¾‹ï¼Œå®é™…è®­ç»ƒæ—¶å¯å‚è€ƒ[æ•°æ®é›†](https://www.mindspore.cn/mindformers/docs/zh-CN/master/feature/dataset.html)ç« èŠ‚åˆ¶ä½œæ•°æ®é›†ã€‚è¯·åœ¨æ‰§è¡Œä»»åŠ¡å‰æå‰ä¸‹è½½æ‰€éœ€æ•°æ®é›†ã€‚é“¾æ¥å¦‚ä¸‹ï¼š

| ä»»åŠ¡  |    æ•°æ®é›†åç§°     | ä¸‹è½½é“¾æ¥         | è¯´æ˜ |
|:---:|:------------:|:-------------|:---|
| é¢„è®­ç»ƒ | WikiText-103 | [Download](https://dagshub.com/DagsHub/WIkiText-103/src/main/dataset/tokens/wiki.train.tokens) | ç”¨äºé¢„è®­ç»ƒçš„å¤§è§„æ¨¡æ–‡æœ¬æ•°æ®é›† |

### é¢„è®­ç»ƒæ ·ä¾‹

é¢„è®­ç»ƒæ˜¯æŒ‡åœ¨å¤§è§„æ¨¡æ— æ ‡æ³¨æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿå…¨é¢æ•æ‰è¯­è¨€çš„å¹¿æ³›ç‰¹æ€§ã€‚åœ¨MindSporeå®˜ç½‘æä¾›äº†è¯¦ç»†çš„[æŒ‡å¯¼](https://www.mindspore.cn/mindformers/docs/zh-CN/master/guide/pre_training.html)ã€‚

#### 1. æ•°æ®é¢„å¤„ç†

MindSpore Transformers é¢„è®­ç»ƒé˜¶æ®µå½“å‰å·²æ”¯æŒ[Megatronæ ¼å¼çš„æ•°æ®é›†](https://www.mindspore.cn/mindformers/docs/zh-CN/master/feature/dataset.html#megatron%E6%95%B0%E6%8D%AE%E9%9B%86)ã€‚ç”¨æˆ·å¯ä»¥å‚è€ƒ[æ•°æ®é›†](https://www.mindspore.cn/mindformers/docs/zh-CN/master/feature/dataset.html)ç« èŠ‚ï¼Œä½¿ç”¨ MindSpore æä¾›çš„å·¥å…·å°†åŸå§‹æ•°æ®é›†è½¬æ¢ä¸º Megatron æ ¼å¼ã€‚

åˆ¶ä½œMegatronæ ¼å¼æ•°æ®é›†ï¼Œéœ€è¦ç»è¿‡ä¸¤ä¸ªæ­¥éª¤ã€‚é¦–å…ˆå°†åŸå§‹æ–‡æœ¬æ•°æ®é›†è½¬æ¢ä¸ºjsonlæ ¼å¼æ•°æ®ï¼Œç„¶åä½¿ç”¨MindSpore Transformersæä¾›çš„è„šæœ¬å°†jsonlæ ¼å¼æ•°æ®è½¬æ¢ä¸ºMegatronæ ¼å¼çš„.binå’Œ.idxæ–‡ä»¶ã€‚

- `wiki.train.tokens` è½¬ä¸º `jsonl`æ ¼å¼æ•°æ®

ç”¨æˆ·éœ€è¦**è‡ªè¡Œå°†`wiki.train.tokens`æ•°æ®é›†å¤„ç†æˆjsonlæ ¼å¼çš„æ–‡ä»¶**ã€‚ä½œä¸ºå‚è€ƒï¼Œæ–‡æ¡£æœ«å°¾çš„[FAQ](#faq)éƒ¨åˆ†æä¾›äº†ä¸€ä¸ªä¸´æ—¶è½¬æ¢æ–¹æ¡ˆï¼Œç”¨æˆ·éœ€è¦æ ¹æ®å®é™…éœ€æ±‚è‡ªè¡Œå¼€å‘å’ŒéªŒè¯è½¬æ¢é€»è¾‘ã€‚

ä¸‹é¢æ˜¯jsonlæ ¼å¼æ–‡ä»¶çš„ç¤ºä¾‹ï¼š

```json
{"src": "www.nvidia.com", "text": "The quick brown fox", "type": "Eng", "id": "0", "title": "First Part"}
{"src": "The Internet", "text": "jumps over the lazy dog", "type": "Eng", "id": "42", "title": "Second Part"}
...
```

- `jsonl`æ ¼å¼æ•°æ® è½¬ä¸º `bin`æ ¼å¼æ•°æ®

MindSpore Transformersæä¾›äº†æ•°æ®é¢„å¤„ç†è„šæœ¬`toolkit/data_preprocess/megatron/preprocess_indexed_dataset.py`ç”¨äºå°†jsonlæ ¼å¼çš„åŸå§‹æ–‡æœ¬é¢„æ–™è½¬æ¢æˆ.binæˆ–.idxæ–‡ä»¶ã€‚

> è¿™é‡Œéœ€è¦æå‰ä¸‹è½½[Qwen3-32B](https://huggingface.co/Qwen/Qwen3-32B)æ¨¡å‹çš„tokenizeræ–‡ä»¶ã€‚

ä¾‹å¦‚ï¼š

```shell
python toolkit/data_preprocess/megatron/preprocess_indexed_dataset.py \
  --input /path/to/data.jsonl \
  --output-prefix /path/to/wiki103-megatron \
  --tokenizer-type HuggingFaceTokenizer \
  --tokenizer-dir /path/to/Qwen3-32B # å…¶ä»–è§„æ ¼çš„æ¨¡å‹å¯ä»¥è°ƒæ•´ä¸ºå¯¹åº”çš„tokenizerè·¯å¾„
```

> è¿è¡Œå®Œæˆåä¼šç”Ÿæˆ`/path/to/wiki103-megatron_text_document.bin`å’Œ`/path/to/wiki103-megatron_text_document.idx`æ–‡ä»¶ã€‚
> å¡«å†™æ•°æ®é›†è·¯å¾„æ—¶éœ€è¦ä½¿ç”¨`/path/to/wiki103-megatron_text_document`ï¼Œä¸éœ€è¦å¸¦åç¼€åã€‚

#### 2. ä¿®æ”¹ä»»åŠ¡é…ç½®

MindSpore Transformers æä¾›äº†é¢„è®­ç»ƒä»»åŠ¡çš„é…ç½®æ–‡ä»¶ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹é…ç½®æ–‡ä»¶ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹é…ç½®æ–‡ä»¶ç‰‡æ®µï¼Œç”¨æˆ·éœ€è¦æ ¹æ®è‡ªå·±çš„æ•°æ®é›†è·¯å¾„å’Œå…¶ä»–å‚æ•°è¿›è¡Œç›¸åº”ä¿®æ”¹ã€‚

- æ•°æ®é›†é…ç½®

```yaml
# Dataset configuration
train_dataset: &train_dataset
  data_loader:
    ...
    sizes:
      - 8000  # æ•°æ®é›†çš„å¤§å°ï¼Œå¯ä»¥æ ¹æ®å®é™…æ•°æ®é›†å¤§å°è¿›è¡Œè°ƒæ•´
      ...
    config:
      ...
      data_path:  # é‡‡æ ·æ¯”ä¾‹å’ŒMegatronæ ¼å¼æ•°æ®é›†è·¯å¾„
        - '1'
        - "/path/to/wiki103-megatron_text_document" # æ›¿æ¢ä¸ºå®é™…çš„Megatronæ ¼å¼æ•°æ®é›†è·¯å¾„ï¼Œæ­¤å¤„ä¸å¸¦åç¼€å
```

æ•°æ®é›†è·¯å¾„éœ€è¦æ›¿æ¢ä¸ºå®é™…çš„Megatronæ ¼å¼æ•°æ®é›†è·¯å¾„ã€‚

ä¸åŒè§„æ ¼å’Œåºåˆ—é•¿åº¦çš„å¹¶è¡Œé…ç½®å¯å‚è€ƒ[å¹¶è¡Œé…ç½®å»ºè®®](#å¹¶è¡Œé…ç½®å»ºè®®)ã€‚

#### 3. å¯åŠ¨é¢„è®­ç»ƒä»»åŠ¡

é€šè¿‡æŒ‡å®šæ¨¡å‹è·¯å¾„å’Œé…ç½®æ–‡ä»¶[configs/qwen3/pretrain_qwen3_32b_4k.yaml](https://gitee.com/mindspore/mindformers/blob/master/configs/qwen3/pretrain_qwen3_32b_4k.yaml)ä»¥msrunçš„æ–¹å¼å¯åŠ¨[run_mindformer.py](https://gitee.com/mindspore/mindformers/blob/master/run_mindformer.py)è„šæœ¬ï¼Œè¿›è¡Œ16å¡åˆ†å¸ƒå¼è®­ç»ƒã€‚å¯ä»¥å‚è€ƒå¦‚ä¸‹æ–¹å¼æ‹‰èµ·ä¸¤å°Atlas 800T A2ï¼ˆ64Gï¼‰è®­ç»ƒã€‚

åœ¨æ¯å°æœåŠ¡å™¨ä¸Šæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ã€‚è®¾ç½®`master_ip`ä¸ºä¸»èŠ‚ç‚¹IPåœ°å€ï¼Œå³`Rank 0`æœåŠ¡å™¨çš„IPï¼›`node_rank`ä¸ºæ¯ä¸ªèŠ‚ç‚¹çš„åºå·ï¼›`port`ä¸ºå½“å‰è¿›ç¨‹çš„ç«¯å£å·ï¼ˆå¯åœ¨50000~65536ä¸­é€‰æ‹©ï¼‰ã€‚

```shell
master_ip=192.168.1.1
node_rank=0
port=50001
bash scripts/msrun_launcher.sh "run_mindformer.py \
--config configs/qwen3/pretrain_qwen3_32b_4k.yaml \
--auto_trans_ckpt False \
--use_parallel True \
--run_mode train" \
16 8 $master_ip $port $node_rank output/msrun_log False 7200
```

> æ­¤å¤„æ ·ä¾‹ä»£ç å‡è®¾ä¸»èŠ‚ç‚¹ä¸º`192.168.1.1`ã€å½“å‰Rankåºå·ä¸º`0`ã€‚å®é™…æ‰§è¡Œæ—¶è¯·å°†`master_ip`è®¾ç½®ä¸ºå®é™…çš„ä¸»èŠ‚ç‚¹IPåœ°å€ï¼›å°†`node_rank`è®¾ç½®ä¸ºå½“å‰èŠ‚ç‚¹çš„Rankåºå·ï¼›å°†`port`è®¾ç½®ä¸ºå½“å‰è¿›ç¨‹çš„ç«¯å£å·ã€‚

ä¸Šè¿°å‘½ä»¤æ‰§è¡Œå®Œæ¯•åï¼Œè®­ç»ƒä»»åŠ¡å°†åœ¨åå°æ‰§è¡Œï¼Œè¿‡ç¨‹æ—¥å¿—ä¿å­˜åœ¨`./output/msrun_log`ä¸‹ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯å®æ—¶æŸ¥çœ‹è®­ç»ƒçŠ¶æ€ï¼ˆç”±äºå¼€å¯äº†æµæ°´å¹¶è¡Œï¼ŒçœŸå®lossåªæ˜¾ç¤ºåœ¨æœ€åä¸€ä¸ªpipeline stageçš„æ—¥å¿—ä¸­ï¼Œå…¶ä½™pipeline stageä¼šæ˜¾ç¤º`loss`ä¸º`0`ï¼‰

```shell
tail -f ./output/msrun_log/worker_15.log
```

è®­ç»ƒè¿‡ç¨‹ä¸­çš„æƒé‡checkpointå°†ä¼šä¿å­˜åœ¨`./output/checkpoint`ä¸‹ã€‚

å¦‚æœ‰å…³äºQwen3é¢„è®­ç»ƒçš„ç›¸å…³é—®é¢˜ï¼Œå¯ä»¥åœ¨MindSpore Transformersçš„Giteeä»“åº“ä¸­[æäº¤ISSUE](https://gitee.com/mindspore/mindformers/issues/new)ä»¥è·å–æ”¯æŒã€‚

### å¾®è°ƒæ ·ä¾‹

SFTï¼ˆSupervised Fine-Tuningï¼Œç›‘ç£å¾®è°ƒï¼‰é‡‡ç”¨æœ‰ç›‘ç£å­¦ä¹ æ€æƒ³ï¼Œæ˜¯æŒ‡åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡è°ƒæ•´éƒ¨åˆ†æˆ–å…¨éƒ¨å‚æ•°ï¼Œä½¿æ¨¡å‹æ›´é€‚åº”ç‰¹å®šä»»åŠ¡æˆ–æ•°æ®é›†çš„è¿‡ç¨‹ã€‚åœ¨MindSporeå®˜ç½‘æä¾›äº†è¯¦ç»†çš„[æŒ‡å¯¼](https://www.mindspore.cn/mindformers/docs/zh-CN/master/guide/supervised_fine_tuning.html)ã€‚

MindSpore Transformersæ”¯æŒå…¨å‚å¾®è°ƒå’ŒLoRAé«˜æ•ˆå¾®è°ƒä¸¤ç§SFTå¾®è°ƒæ–¹å¼ã€‚å…¨å‚å¾®è°ƒæ˜¯æŒ‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹æ‰€æœ‰å‚æ•°è¿›è¡Œæ›´æ–°ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æ•°æ®ç²¾è°ƒï¼Œèƒ½è·å¾—æœ€ä¼˜çš„ä»»åŠ¡é€‚åº”èƒ½åŠ›ï¼Œä½†éœ€è¦çš„è®¡ç®—èµ„æºè¾ƒå¤§ã€‚LoRAé«˜æ•ˆå¾®è°ƒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä»…æ›´æ–°éƒ¨åˆ†å‚æ•°ï¼Œç›¸æ¯”å…¨å‚å¾®è°ƒæ˜¾å­˜å ç”¨æ›´å°‘ã€è®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œä½†åœ¨æŸäº›ä»»åŠ¡ä¸­çš„æ•ˆæœä¸å¦‚å…¨å‚å¾®è°ƒã€‚

#### 1. é…ç½®æ–‡ä»¶ä¿®æ”¹

MindSpore Transformers æä¾›äº†å¾®è°ƒä»»åŠ¡çš„é…ç½®æ–‡ä»¶ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹é…ç½®æ–‡ä»¶ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹é…ç½®æ–‡ä»¶ç‰‡æ®µï¼Œç”¨æˆ·éœ€è¦æ ¹æ®è‡ªå·±çš„æ•°æ®é›†è·¯å¾„å’Œå…¶ä»–å‚æ•°è¿›è¡Œç›¸åº”ä¿®æ”¹ã€‚ä»£ç ä»“ä¸­æä¾›äº†Qwen3-32Bå…¨å‚å¾®è°ƒçš„é…ç½®æ–‡ä»¶[configs/qwen3/finetune_qwen3.yaml](https://gitee.com/mindspore/mindformers/blob/master/configs/qwen3/finetune_qwen3.yaml)ï¼Œå¦‚æœéœ€è¦ä¿®æ”¹å…¶ä»–æ¨¡å‹ï¼Œä¾‹å¦‚Qwen3-14Bã€Qwen3-8Bã€Qwen3-4Bã€Qwen3-1.7Bã€Qwen3-0.6Bç­‰ï¼Œå¯ä»¥å‚è€ƒè¯¥é…ç½®æ–‡ä»¶è¿›è¡Œç›¸åº”ä¿®æ”¹ã€‚å¹¶å‚è€ƒ[é™„å½•](#é™„å½•)ä¸­çš„[å¹¶è¡Œé…ç½®å»ºè®®](#å¹¶è¡Œé…ç½®å»ºè®®)ç« èŠ‚è¿›è¡Œä¿®æ”¹

**å…¨å‚å¾®è°ƒé…ç½®ç¤ºä¾‹ï¼š**

```yaml
# æ•°æ®é›†é…ç½®
train_dataset: &train_dataset
  data_loader:
    type: HFDataLoader
    path: "llm-wizard/alpaca-gpt4-data-zh" # alpacaé£æ ¼æ•°æ®é›†ï¼Œç¡®ä¿ç½‘ç»œç¯å¢ƒèƒ½å¤Ÿè®¿é—®huggingfaceï¼Œä»¥å®ç°è‡ªåŠ¨ä¸‹è½½æ•°æ®é›†åŠŸèƒ½ã€‚
    # path: "json"  # å¦‚æœä½¿ç”¨æœ¬åœ°jsonæ–‡ä»¶ç¦»çº¿åŠ è½½æ•°æ®é›†ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Šä¸‹é¢ä¸¤è¡Œï¼Œå¹¶æ³¨é‡Šæ‰ä¸Šé¢ä¸€è¡Œ
    # data_files: '/path/to/alpaca_gpt4_data_zh.json'
    handler:
      - type: take # è°ƒç”¨datasetsåº“çš„takeæ–¹æ³•ï¼Œå–å‰næ¡æ•°æ®ç”¨äºç¤ºä¾‹
        n: 2000    # å–å‰2000æ¡æ•°æ®ç”¨äºç¤ºä¾‹ï¼Œå®é™…ä½¿ç”¨æ—¶å¯ä»¥å»æ‰è¿™ä¸€è¡Œå’Œä¸Šé¢ä¸€è¡Œ
```

**LoRAå¾®è°ƒé…ç½®ç¤ºä¾‹ï¼š**

LoRAå¾®è°ƒå¯ä»¥åœ¨å•æœº8å¡ç¯å¢ƒä¸‹è¿è¡Œï¼Œèµ„æºéœ€æ±‚è¾ƒä½ã€‚ä»¥ä¸‹æ˜¯é…ç½®ç¤ºä¾‹ï¼š

```yaml
# æ•°æ®é›†é…ç½®
train_dataset: &train_dataset
  data_loader:
    type: HFDataLoader
    path: "llm-wizard/alpaca-gpt4-data-zh" # alpacaé£æ ¼æ•°æ®é›†ï¼Œç¡®ä¿ç½‘ç»œç¯å¢ƒèƒ½å¤Ÿè®¿é—®huggingfaceï¼Œä»¥å®ç°è‡ªåŠ¨ä¸‹è½½æ•°æ®é›†åŠŸèƒ½ã€‚
    # path: "json"  # å¦‚æœä½¿ç”¨æœ¬åœ°jsonæ–‡ä»¶ç¦»çº¿åŠ è½½æ•°æ®é›†ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Šä¸‹é¢ä¸¤è¡Œï¼Œå¹¶æ³¨é‡Šæ‰ä¸Šé¢ä¸€è¡Œ
    # data_files: '/path/to/alpaca_gpt4_data_zh.json'
    handler:
      - type: take # è°ƒç”¨datasetsåº“çš„takeæ–¹æ³•ï¼Œå–å‰næ¡æ•°æ®ç”¨äºç¤ºä¾‹
        n: 2000    # å–å‰2000æ¡æ•°æ®ç”¨äºç¤ºä¾‹ï¼Œå®é™…ä½¿ç”¨æ—¶å¯ä»¥å»æ‰è¿™ä¸€è¡Œå’Œä¸Šé¢ä¸€è¡Œ

# LoRAé…ç½®
model:
  model_config:
    ...
    # åœ¨model_configå±‚çº§ä¸‹æ·»åŠ pet_config
    pet_config:
      pet_type: lora
      lora_rank: 8
      lora_alpha: 16
      lora_dropout: 0.1
      lora_a_init: 'normal'
      lora_b_init: 'zeros'
      target_modules: '.*word_embeddings|.*linear_qkv|.*linear_proj|.*linear_fc1|.*linear_fc2'
      freeze_include: ['*']
      freeze_exclude: ['*lora*']
```

`pet_config`å…³é”®å‚æ•°è¯´æ˜ï¼š

| å‚æ•° | è¯´æ˜ |
|:-----|:-----|
| `pet_type` | å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯ç±»å‹ |
| `lora_rank` | LoRAçš„ç§© |
| `lora_alpha` | LoRAç¼©æ”¾å› å­alpha |
| `lora_dropout` | LoRAä¸­çš„dropoutæ¦‚ç‡ |
| `lora_a_init` | LoRAçš„AçŸ©é˜µåˆå§‹åŒ–æ–¹å¼ |
| `lora_b_init` | LoRAçš„BçŸ©é˜µåˆå§‹åŒ–æ–¹å¼ |
| `target_modules` | åº”ç”¨LoRAçš„æ¨¡å—ï¼Œä¸Šè¿°é…ç½®å¯¹word_embeddingsã€attentionå’Œmlpçš„æƒé‡çŸ©é˜µåº”ç”¨LoRA |

#### 3. å¯åŠ¨å¾®è°ƒä»»åŠ¡

- **å¤šæœºå¤šå¡è®­ç»ƒï¼ˆä»¥Qwen3 32Bå…¨å‚å¾®è°ƒä¸ºä¾‹ï¼‰**

é€šè¿‡æŒ‡å®šæ¨¡å‹è·¯å¾„å’Œé…ç½®æ–‡ä»¶[configs/qwen3/finetune_qwen3.yaml](https://gitee.com/mindspore/mindformers/blob/master/configs/qwen3/finetune_qwen3.yaml)ä»¥msrunçš„æ–¹å¼å¯åŠ¨[run_mindformer.py](https://gitee.com/mindspore/mindformers/blob/master/run_mindformer.py)è„šæœ¬ï¼Œå¯åŠ¨å¡åˆ†å¸ƒå¼è®­ç»ƒã€‚

ä¸‹åˆ—è„šæœ¬å¯ä»¥å‚è€ƒå¦‚ä¸‹æ–¹å¼æ‹‰èµ·**ä¸¤å°Atlas 800T A2ï¼ˆ64Gï¼‰è®­ç»ƒ**ã€‚

åœ¨æ¯å°æœåŠ¡å™¨ä¸Šæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ã€‚è®¾ç½®ï¼š

- `total_rank_num=16`è¡¨ç¤ºä¸¤å°Atlas 800T A2ï¼ˆ64Gï¼‰å…±æœ‰`2x8=16`ä¸ªNPUï¼›
- `local_rank_num=8`è¡¨ç¤ºæ¯å°Atlas 800T A2ï¼ˆ64Gï¼‰æœ‰8ä¸ªNPUï¼›
- `master_ip`ä¸ºä¸»èŠ‚ç‚¹IPåœ°å€ï¼›
- `node_rank`ä¸ºæ¯ä¸ªèŠ‚ç‚¹çš„åºå·ï¼›
- `port`ä¸ºå½“å‰è¿›ç¨‹çš„ç«¯å£å·ï¼ˆå¯åœ¨50000~65536ä¸­é€‰æ‹©ï¼‰ã€‚

```bash
total_rank_num=16
local_rank_num=8
master_ip=192.168.1.1
node_rank=0
port=50001
bash scripts/msrun_launcher.sh "run_mindformer.py \
--config configs/qwen3/finetune_qwen3.yaml \
--auto_trans_ckpt True \
--use_parallel True \
--run_mode train \
--pretrained_model_dir /path/to/Qwen3-32B \
--parallel_config.data_parallel 1 \
--parallel_config.model_parallel 4 \
--parallel_config.pipeline_stage 4 \
--parallel_config.micro_batch_num 4 \
--recompute_config.recompute True" \
$total_rank_num $local_rank_num $master_ip $port $node_rank output/msrun_log False 7200
```

> `--pretrained_model_dir` å¯ä»¥ç”¨äºé€‰æ‹©ä¸åŒè§„æ ¼çš„Qwen3æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä¾‹å¦‚`/path/to/Qwen3-14B`ã€`/path/to/Qwen3-8B`ã€`/path/to/Qwen3-4B`ã€`/path/to/Qwen3-1.7B`ã€`/path/to/Qwen3-0.6B`ç­‰ã€‚
> æ­¤å¤„æ ·ä¾‹ä»£ç å‡è®¾ä¸»èŠ‚ç‚¹ä¸º`192.168.1.1`ã€å½“å‰Rankåºå·ä¸º`0`ã€‚å®é™…æ‰§è¡Œæ—¶è¯·å°†`master_ip`è®¾ç½®ä¸ºå®é™…çš„ä¸»èŠ‚ç‚¹IPåœ°å€ï¼›å°†`node_rank`è®¾ç½®ä¸ºå½“å‰èŠ‚ç‚¹çš„Rankåºå·ï¼›å°†`port`è®¾ç½®ä¸ºå½“å‰è¿›ç¨‹çš„ç«¯å£å·ã€‚

ä¸Šè¿°å‘½ä»¤æ‰§è¡Œå®Œæ¯•åï¼Œè®­ç»ƒä»»åŠ¡å°†åœ¨åå°æ‰§è¡Œï¼Œè¿‡ç¨‹æ—¥å¿—ä¿å­˜åœ¨`./output/msrun_log`ä¸‹ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯å®æ—¶æŸ¥çœ‹è®­ç»ƒçŠ¶æ€

```bash
tail -f ./output/msrun_log/worker_15.log
```

è®­ç»ƒè¿‡ç¨‹ä¸­çš„æƒé‡checkpointå°†ä¼šä¿å­˜åœ¨`./output/checkpoint`ä¸‹ã€‚

å¦‚æœ‰å…³äºQwen3å…¨å‚å¾®è°ƒçš„ç›¸å…³é—®é¢˜ï¼Œå¯ä»¥åœ¨MindSpore Transformersçš„Giteeä»“åº“ä¸­[æäº¤ISSUE](https://gitee.com/mindspore/mindformers/issues/new)ä»¥è·å–æ”¯æŒã€‚

- **å•æœºå¤šå¡è®­ç»ƒï¼ˆä»¥Qwen3 32B LoRAå¾®è°ƒä¸ºä¾‹ï¼‰**

é€šè¿‡æŒ‡å®šæ¨¡å‹è·¯å¾„å’Œé…ç½®æ–‡ä»¶[configs/qwen3/finetune_qwen3.yaml](https://gitee.com/mindspore/mindformers/blob/master/configs/qwen3/finetune_qwen3.yaml)ä»¥msrunçš„æ–¹å¼å¯åŠ¨[run_mindformer.py](https://gitee.com/mindspore/mindformers/blob/master/run_mindformer.py)è„šæœ¬ï¼Œå¯åŠ¨å¡åˆ†å¸ƒå¼è®­ç»ƒã€‚

ä¸‹åˆ—è„šæœ¬å¯ä»¥å‚è€ƒå¦‚ä¸‹æ–¹å¼æ‹‰èµ·**ä¸€å°Atlas 800T A2ï¼ˆ64Gï¼‰è®­ç»ƒ**ã€‚

```bash
total_rank_num=8
bash scripts/msrun_launcher.sh "run_mindformer.py \
--config configs/qwen3/finetune_qwen3.yaml \
--auto_trans_ckpt True \
--use_parallel True \
--run_mode train \
--pretrained_model_dir /path/to/Qwen3-32B \
--parallel_config.data_parallel 1 \
--parallel_config.model_parallel 8 \
--parallel_config.pipeline_stage 1 \
--parallel_config.micro_batch_num 1 \
--recompute_config.recompute True" \
$total_rank_num
```

> `--pretrained_model_dir` å¯ä»¥ç”¨äºé€‰æ‹©ä¸åŒè§„æ ¼çš„Qwen3æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä¾‹å¦‚`/path/to/Qwen3-14B`ã€`/path/to/Qwen3-8B`ã€`/path/to/Qwen3-4B`ã€`/path/to/Qwen3-1.7B`ã€`/path/to/Qwen3-0.6B`ç­‰ã€‚

ä¸Šè¿°å‘½ä»¤æ‰§è¡Œå®Œæ¯•åï¼Œè®­ç»ƒä»»åŠ¡å°†åœ¨åå°æ‰§è¡Œï¼Œè¿‡ç¨‹æ—¥å¿—ä¿å­˜åœ¨`./output/msrun_log`ä¸‹ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯å®æ—¶æŸ¥çœ‹è®­ç»ƒçŠ¶æ€

```bash
tail -f ./output/msrun_log/worker_7.log
```

è®­ç»ƒè¿‡ç¨‹ä¸­çš„æƒé‡checkpointå°†ä¼šä¿å­˜åœ¨`./output/checkpoint`ä¸‹ã€‚

å¦‚æœ‰å…³äºQwen3 LoRAå¾®è°ƒçš„ç›¸å…³é—®é¢˜ï¼Œå¯ä»¥åœ¨MindSpore Transformersçš„Giteeä»“åº“ä¸­[æäº¤ISSUE](https://gitee.com/mindspore/mindformers/issues/new)ä»¥è·å–æ”¯æŒã€‚

#### 4. æƒé‡åˆå¹¶

`output`ç›®å½•ä¸‹çš„`checkpoint`æ–‡ä»¶å¤¹ä¸­ä¼šä¿å­˜å¾®è°ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„åˆ†å¸ƒå¼safetensorsæƒé‡æ–‡ä»¶ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©åˆé€‚çš„æƒé‡è¿›è¡Œæƒé‡åˆå¹¶ï¼Œå¾—åˆ°å®Œæ•´çš„safetensorsæƒé‡ï¼Œé€‚ç”¨äºåç»­æ¨ç†æµç¨‹ã€‚

ä½¿ç”¨MindSpore Transformersæä¾›çš„safetensorsæƒé‡åˆå¹¶è„šæœ¬ï¼ŒæŒ‰ç…§å¦‚ä¸‹æ–¹å¼è¿›è¡Œsafetensorsæƒé‡åˆå¹¶ã€‚åˆå¹¶åçš„æƒé‡æ ¼å¼ä¸ºå®Œæ•´æƒé‡ã€‚

```bash
python toolkit/safetensors/unified_safetensors.py \
  --src_strategy_dirs src_strategy_path_or_dir \
  --mindspore_ckpt_dir mindspore_ckpt_dir\
  --output_dir output_dir \
  --file_suffix "1_1" \
  --has_redundancy False
```

å‚æ•°è¯´æ˜

- **src_strategy_dirs**ï¼šæºæƒé‡å¯¹åº”çš„åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶è·¯å¾„ï¼Œé€šå¸¸åœ¨å¯åŠ¨è®­ç»ƒä»»åŠ¡åé»˜è®¤ä¿å­˜åœ¨ `output/strategy/` ç›®å½•ä¸‹ã€‚åˆ†å¸ƒå¼æƒé‡éœ€æ ¹æ®ä»¥ä¸‹æƒ…å†µå¡«å†™ï¼š

    - **æºæƒé‡å¼€å¯äº†æµæ°´çº¿å¹¶è¡Œ**ï¼šæƒé‡è½¬æ¢åŸºäºåˆå¹¶çš„ç­–ç•¥æ–‡ä»¶ï¼Œå¡«å†™åˆ†å¸ƒå¼ç­–ç•¥æ–‡ä»¶å¤¹è·¯å¾„ã€‚è„šæœ¬ä¼šè‡ªåŠ¨å°†æ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰ `ckpt_strategy_rank_x.ckpt` æ–‡ä»¶åˆå¹¶ï¼Œå¹¶åœ¨æ–‡ä»¶å¤¹ä¸‹ç”Ÿæˆ `merged_ckpt_strategy.ckpt`ã€‚å¦‚æœå·²ç»å­˜åœ¨ `merged_ckpt_strategy.ckpt`ï¼Œå¯ä»¥ç›´æ¥å¡«å†™è¯¥æ–‡ä»¶çš„è·¯å¾„ã€‚
    - **æºæƒé‡æœªå¼€å¯æµæ°´çº¿å¹¶è¡Œ**ï¼šæƒé‡è½¬æ¢å¯åŸºäºä»»ä¸€ç­–ç•¥æ–‡ä»¶ï¼Œå¡«å†™ä»»æ„ä¸€ä¸ª `ckpt_strategy_rank_x.ckpt` æ–‡ä»¶çš„è·¯å¾„å³å¯ã€‚

    **æ³¨æ„**ï¼šå¦‚æœç­–ç•¥æ–‡ä»¶å¤¹ä¸‹å·²å­˜åœ¨ `merged_ckpt_strategy.ckpt` ä¸”ä»ä¼ å…¥æ–‡ä»¶å¤¹è·¯å¾„ï¼Œè„šæœ¬ä¼šé¦–å…ˆåˆ é™¤æ—§çš„ `merged_ckpt_strategy.ckpt`ï¼Œå†åˆå¹¶ç”Ÿæˆæ–°çš„ `merged_ckpt_strategy.ckpt` ä»¥ç”¨äºæƒé‡è½¬æ¢ã€‚å› æ­¤ï¼Œè¯·ç¡®ä¿è¯¥æ–‡ä»¶å¤¹å…·æœ‰è¶³å¤Ÿçš„å†™å…¥æƒé™ï¼Œå¦åˆ™æ“ä½œå°†æŠ¥é”™ã€‚
- **mindspore_ckpt_dir**ï¼šåˆ†å¸ƒå¼æƒé‡è·¯å¾„ï¼Œè¯·å¡«å†™æºæƒé‡æ‰€åœ¨æ–‡ä»¶å¤¹çš„è·¯å¾„ï¼Œæºæƒé‡åº”æŒ‰ `model_dir/rank_x/xxx.safetensors` æ ¼å¼å­˜æ”¾ï¼Œå¹¶å°†æ–‡ä»¶å¤¹è·¯å¾„å¡«å†™ä¸º `model_dir`ã€‚
- **output_dir**ï¼šç›®æ ‡æƒé‡çš„ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤å€¼ä¸º "/new_llm_data/******/ckpt/nbg3_31b/tmp"ï¼Œå³ç›®æ ‡æƒé‡å°†æ”¾ç½®åœ¨ `/new_llm_data/******/ckpt/nbg3_31b/tmp` ç›®å½•ä¸‹ã€‚
- **file_suffix**ï¼šç›®æ ‡æƒé‡æ–‡ä»¶çš„å‘½ååç¼€ï¼Œé»˜è®¤å€¼ä¸º "1_1"ï¼Œå³ç›®æ ‡æƒé‡å°†æŒ‰ç…§ `*1_1.safetensors` æ ¼å¼æŸ¥æ‰¾ã€‚
- **has_redundancy**ï¼šåˆå¹¶çš„æºæƒé‡æ˜¯å¦æ˜¯å†—ä½™çš„æƒé‡ï¼Œé»˜è®¤ä¸º `True`ã€‚
- **filter_out_param_prefix**ï¼šåˆå¹¶æƒé‡æ—¶å¯è‡ªå®šä¹‰è¿‡æ»¤æ‰éƒ¨åˆ†å‚æ•°ï¼Œè¿‡æ»¤è§„åˆ™ä»¥å‰ç¼€ååŒ¹é…ã€‚å¦‚ä¼˜åŒ–å™¨å‚æ•°"adam_"ã€‚
- **max_process_num**ï¼šåˆå¹¶æœ€å¤§è¿›ç¨‹æ•°ã€‚é»˜è®¤å€¼ï¼š64ã€‚

æ›´å¤šSafetensorsæƒé‡ç›¸å…³çš„æ“ä½œè¯·å‚è€ƒ[MindSpore Transformers - Safetensorsæƒé‡](https://www.mindspore.cn/mindformers/docs/zh-CN/master/feature/safetensors.html#%E6%9D%83%E9%87%8D%E5%90%88%E5%B9%B6)

### æ¨ç†æ ·ä¾‹

æ¨ç†æ˜¯æŒ‡åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œåˆ©ç”¨å·²å­¦ä¹ åˆ°çš„è¯­è¨€çŸ¥è¯†å¯¹æ–°çš„è¾“å…¥æ•°æ®è¿›è¡Œé¢„æµ‹æˆ–ç”Ÿæˆã€‚åœ¨MindSporeå®˜ç½‘æä¾›äº†è¯¦ç»†çš„[æŒ‡å¯¼](https://www.mindspore.cn/mindformers/docs/zh-CN/master/guide/inference.html)ã€‚

#### 1. ä¿®æ”¹ä»»åŠ¡é…ç½®

MindSpore Transformers æä¾›äº†æ¨ç†ä»»åŠ¡çš„[é…ç½®æ–‡ä»¶](https://gitee.com/mindspore/mindformers/blob/master/configs/qwen3/predict_qwen3.yaml)ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹æ­¤é…ç½®æ–‡ä»¶ä¸­çš„æƒé‡è·¯å¾„å’Œå…¶ä»–å‚æ•°ã€‚

å½“å‰æ¨ç†å¯ä»¥ç›´æ¥å¤ç”¨Hugging Faceçš„é…ç½®æ–‡ä»¶å’Œtokenizerï¼Œå¹¶ä¸”åœ¨çº¿åŠ è½½Hugging Faceçš„safetensorsæ ¼å¼çš„æƒé‡ï¼Œä½¿ç”¨æ—¶é…ç½®ä¿®æ”¹å¦‚ä¸‹ï¼š

```yaml
pretrained_model_dir: '/path/hf_dir'
parallel_config:
  data_parallel: 1
  model_parallel: 1
```

å‚æ•°è¯´æ˜ï¼š

- pretrained_model_dirï¼šHugging Faceæ¨¡å‹ç›®å½•è·¯å¾„ï¼Œæ”¾ç½®æ¨¡å‹é…ç½®ã€Tokenizerç­‰æ–‡ä»¶ã€‚`/path/hf_dir`ä¸­çš„å†…å®¹å¦‚ä¸‹ï¼š

```text
ğŸ“‚Qwen3-0.6B
â”œâ”€â”€ ğŸ“„config.json
â”œâ”€â”€ ğŸ“„generation_config.json
â”œâ”€â”€ ğŸ“„merges.txt
â”œâ”€â”€ ğŸ“„model-xxx.safetensors
â”œâ”€â”€ ğŸ“„model-xxx.safetensors
â”œâ”€â”€ ğŸ“„model.safetensors.index.json
â”œâ”€â”€ ğŸ“„tokenizer.json
â”œâ”€â”€ ğŸ“„tokenizer_config.json
â””â”€â”€ ğŸ“„vocab.json
```

- data_parallelï¼šæ•°æ®å¹¶è¡Œï¼Œå½“å‰æ¨ç†å¹¶ä¸æ”¯æŒæ­¤å¹¶è¡Œç­–ç•¥ï¼Œé»˜è®¤ä¸º1ï¼›
- model_parallelï¼šæ¨¡å‹å¹¶è¡Œï¼Œé»˜è®¤å€¼ä¸º 1ã€‚éœ€æ ¹æ®å®é™…æ¨¡å‹è§„æ¨¡åŠç¡¬ä»¶èµ„æºæƒ…å†µï¼Œè°ƒæ•´è¯¥å‚æ•°ä¸ºç›¸åº”çš„device_nuï¼ˆå³å®é™…ä½¿ç”¨çš„å¡æ•°ï¼‰ã€‚

ä¸åŒè§„æ ¼å’Œåºåˆ—é•¿åº¦çš„å¹¶è¡Œé…ç½®å¯å‚è€ƒ[å¹¶è¡Œé…ç½®å»ºè®®](#å¹¶è¡Œé…ç½®å»ºè®®)ã€‚

#### 2. å¯åŠ¨æ¨ç†ä»»åŠ¡

ä½¿ç”¨ `run_mindformer` ç»Ÿä¸€è„šæœ¬æ‰§è¡Œæ¨ç†ä»»åŠ¡ã€‚

å•å¡æ¨ç†å¯ä»¥ç›´æ¥æ‰§è¡Œ[run_mindformer.py](https://gitee.com/mindspore/mindformers/blob/master/run_mindformer.py)è„šæœ¬ï¼Œå¤šå¡æ¨ç†éœ€è¦å€ŸåŠ©[scripts/msrun_launcher.sh](https://gitee.com/mindspore/mindformers/blob/master/scripts/msrun_launcher.sh)æ¥å¯åŠ¨ã€‚

run_mindformer.pyçš„å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š

| å‚æ•°                             | å‚æ•°è¯´æ˜                                                       |
|:-------------------------------|:-----------------------------------------------------------|
| config                         | yamlé…ç½®æ–‡ä»¶çš„è·¯å¾„                                                |
| run_mode                       | è¿è¡Œçš„æ¨¡å¼ï¼Œæ¨ç†è®¾ç½®ä¸ºpredict                                         |
| use_parallel                   | æ˜¯å¦ä½¿ç”¨å¤šå¡æ¨ç†                                                   |
| predict_data                   | æ¨ç†çš„è¾“å…¥æ•°æ®ï¼Œå¤šbatchæ¨ç†æ—¶éœ€è¦ä¼ å…¥è¾“å…¥æ•°æ®çš„txtæ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«å¤šè¡Œè¾“å…¥                   |
| predict_batch_size             | å¤šbatchæ¨ç†çš„batch_sizeå¤§å°                                      |
| pretrained_model_dir           | Hugging Faceæ¨¡å‹ç›®å½•è·¯å¾„ï¼Œæ”¾ç½®æ¨¡å‹é…ç½®ã€Tokenizerç­‰æ–‡ä»¶                     |
| parallel_config.data_parallel  | æ•°æ®å¹¶è¡Œï¼Œå½“å‰æ¨ç†ä»¬æ¨¡å¼ä¸‹è®¾ç½®ä¸º1                                          |
| parallel_config.model_parallel | æ¨¡å‹å¹¶è¡Œï¼Œé»˜è®¤å€¼ä¸º 1ã€‚éœ€æ ¹æ®å®é™…æ¨¡å‹è§„æ¨¡åŠç¡¬ä»¶èµ„æºæƒ…å†µï¼Œè°ƒæ•´è¯¥å‚æ•°ä¸ºç›¸åº”çš„device_numï¼ˆå³å®é™…ä½¿ç”¨çš„å¡æ•°ï¼‰ |

msrun_launcher.shåŒ…æ‹¬run_mindformer.pyå‘½ä»¤å’Œæ¨ç†å¡æ•°ä¸¤ä¸ªå‚æ•°ã€‚

å•å¡æ¨ç†ï¼š

å½“ä½¿ç”¨å®Œæ•´æƒé‡æ¨ç†æ—¶ï¼Œæ¨èä½¿ç”¨é»˜è®¤[é…ç½®](https://gitee.com/mindspore/mindformers/blob/master/configs/qwen3/predict_qwen3.yaml)ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤å³å¯å¯åŠ¨æ¨ç†ä»»åŠ¡ï¼š

```shell
python run_mindformer.py \
--config configs/qwen3/predict_qwen3.yaml \
--run_mode predict \
--use_parallel False \
--pretrained_model_dir '/path/hf_dir' \
--parallel_config.data_parallel 1 \
--parallel_config.model_parallel 1 \
--predict_data 'å¸®åŠ©æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥'
```

å‡ºç°å¦‚ä¸‹ç»“æœï¼Œè¯æ˜æ¨ç†æˆåŠŸã€‚æ¨ç†ç»“æœä¹Ÿä¼šä¿å­˜åˆ°å½“å‰ç›®å½•ä¸‹çš„ `text_generation_result.txt` æ–‡ä»¶ä¸­ã€‚

```text
'text_generation_text': [å¸®åŠ©æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥ï¼ŒåŒ…æ‹¬æ™¯ç‚¹ã€ç¾é£Ÿã€ä½å®¿ç­‰ä¿¡æ¯...]
```

å¤šå¡æ¨ç†ï¼š

å¤šå¡æ¨ç†çš„é…ç½®è¦æ±‚ä¸å•å¡å­˜åœ¨å·®å¼‚ï¼Œéœ€å‚è€ƒä¸‹é¢ä¿®æ”¹é…ç½®ï¼š

1. æ¨¡å‹å¹¶è¡Œmodel_parallelçš„é…ç½®å’Œä½¿ç”¨çš„å¡æ•°éœ€ä¿æŒä¸€è‡´ï¼Œä¸‹æ–‡ç”¨ä¾‹ä¸º2å¡æ¨ç†ï¼Œéœ€å°†model_parallelè®¾ç½®æˆ2ï¼›
2. å½“å‰ç‰ˆæœ¬çš„å¤šå¡æ¨ç†ä¸æ”¯æŒæ•°æ®å¹¶è¡Œï¼Œéœ€å°†data_parallelè®¾ç½®ä¸º1ã€‚

å½“ä½¿ç”¨å®Œæ•´æƒé‡æ¨ç†æ—¶ï¼Œéœ€è¦å¼€å¯åœ¨çº¿åˆ‡åˆ†æ–¹å¼åŠ è½½æƒé‡ï¼Œå‚è€ƒä»¥ä¸‹å‘½ä»¤ï¼š

```shell
bash scripts/msrun_launcher.sh "run_mindformer.py \
 --config configs/qwen3/predict_qwen3.yaml \
 --run_mode predict \
 --use_parallel True \
 --pretrained_model_dir '/path/hf_dir' \
 --parallel_config.data_parallel 1 \
 --parallel_config.model_parallel 2 \
 --predict_data 'å¸®åŠ©æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥'" 2
```

å‡ºç°å¦‚ä¸‹ç»“æœï¼Œè¯æ˜æ¨ç†æˆåŠŸã€‚æ¨ç†ç»“æœä¹Ÿä¼šä¿å­˜åˆ°å½“å‰ç›®å½•ä¸‹çš„ text_generation_result.txt æ–‡ä»¶ä¸­ã€‚è¯¦ç»†æ—¥å¿—å¯é€šè¿‡`./output/msrun_log`ç›®å½•æŸ¥çœ‹ã€‚

```text
'text_generation_text': [å¸®åŠ©æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥ï¼ŒåŒ…æ‹¬æ™¯ç‚¹ã€ç¾é£Ÿã€ä½å®¿ç­‰ä¿¡æ¯...]
```

å¤šå¡å¤šbatchæ¨ç†ï¼š

å¤šå¡å¤šbatchæ¨ç†çš„å¯åŠ¨æ–¹å¼å¯å‚è€ƒä¸Šè¿°[å¤šå¡æ¨ç†](#å¤šå¡æ¨ç†)ï¼Œä½†æ˜¯éœ€è¦å¢åŠ `predict_batch_size`çš„å…¥å‚ï¼Œå¹¶ä¿®æ”¹`predict_data`çš„å…¥å‚ã€‚

`input_predict_data.txt`æ–‡ä»¶çš„å†…å®¹å’Œæ ¼å¼æ˜¯æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªè¾“å…¥ï¼Œé—®é¢˜çš„ä¸ªæ•°ä¸`predict_batch_size`ä¸€è‡´ï¼Œå¯ä»¥å‚è€ƒä»¥ä¸‹æ ¼å¼ï¼š

```text
å¸®åŠ©æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥
å¸®åŠ©æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥
å¸®åŠ©æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥
å¸®åŠ©æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥
```

ä»¥å®Œæ•´æƒé‡æ¨ç†ä¸ºä¾‹ï¼Œå¯ä»¥å‚è€ƒä»¥ä¸‹å‘½ä»¤å¯åŠ¨æ¨ç†ä»»åŠ¡ï¼š

```shell
bash scripts/msrun_launcher.sh "run_mindformer.py \
 --config configs/qwen3/predict_qwen3.yaml \
 --run_mode predict \
 --predict_batch_size 4 \
 --use_parallel True \
 --pretrained_model_dir '/path/hf_dir' \
 --parallel_config.data_parallel 1 \
 --parallel_config.model_parallel 2 \
 --predict_data path/to/input_predict_data.txt" 2
```

æ¨ç†ç»“æœæŸ¥çœ‹æ–¹å¼ï¼Œä¸å¤šå¡æ¨ç†ç›¸åŒã€‚

å¤šæœºå¤šå¡æ¨ç†ï¼š

åœ¨æ¯å°æœåŠ¡å™¨ä¸Šæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ã€‚è®¾ç½®`master_ip`ä¸ºä¸»èŠ‚ç‚¹IPåœ°å€ï¼Œå³`Rank 0`æœåŠ¡å™¨çš„IPï¼›`node_rank`ä¸ºæ¯ä¸ªèŠ‚ç‚¹çš„åºå·ï¼›`port`ä¸ºå½“å‰è¿›ç¨‹çš„ç«¯å£å·ï¼ˆå¯åœ¨50000~65536ä¸­é€‰æ‹©ï¼‰ã€‚

```shell
master_ip=192.168.1.1
node_rank=0
port=50001

bash scripts/msrun_launcher.sh "run_mindformer.py \
 --config configs/qwen3/predict_qwen3.yaml" \
 --run_mode predict \
 --use_parallel True \
 --pretrained_model_dir '/path/hf_dir' \
 --parallel_config.data_parallel 1 \
 --parallel_config.model_parallel 2 \
 --predict_data å¸®åŠ©æˆ‘åˆ¶å®šä¸€ä»½å»ä¸Šæµ·çš„æ—…æ¸¸æ”»ç•¥" $worker_num $local_worker $master_ip $port $node_rank output/msrun_log False 300
```

> æ­¤å¤„æ ·ä¾‹ä»£ç å‡è®¾ä¸»èŠ‚ç‚¹ä¸º`192.168.1.1`ã€å½“å‰Rankåºå·ä¸º`0`ã€‚å®é™…æ‰§è¡Œæ—¶è¯·å°†`master_ip`è®¾ç½®ä¸ºå®é™…çš„ä¸»èŠ‚ç‚¹IPåœ°å€ï¼›å°†`node_rank`è®¾ç½®ä¸ºå½“å‰èŠ‚ç‚¹çš„Rankåºå·ï¼›å°†`$local_worker`è®¾ç½®ä¸ºå½“å‰èŠ‚ç‚¹ä¸Šæ‹‰èµ·çš„è¿›ç¨‹æ•°(å½“å‰æœºå™¨ä½¿ç”¨çš„å¡æ•°)ï¼›å°†`$worker_num`è®¾ç½®ä¸ºå‚ä¸ä»»åŠ¡çš„è¿›ç¨‹æ€»æ•°(ä½¿ç”¨çš„æ€»å¡æ•°)ï¼›å°†`$port`è®¾ç½®ä¸ºå¯åŠ¨ä»»åŠ¡çš„ç«¯å£å·ã€‚

æ¨ç†ç»“æœæŸ¥çœ‹æ–¹å¼ï¼Œä¸å¤šå¡æ¨ç†ç›¸åŒã€‚

## é™„å½•

### æ¨¡å‹æ–‡ä»¶è¯´æ˜

Qwen3çš„æ¨¡å‹æ–‡ä»¶åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š

```text
ğŸ“¦mindformers
â”œâ”€â”€ ğŸ“‚mindformers
â”‚   â””â”€â”€ ğŸ“‚models
â”‚       â””â”€â”€ ğŸ“‚qwen3
â”‚           â”œâ”€â”€ ğŸ“„__init__.py                   # Qwen3æ¨¡å—åˆå§‹åŒ–æ–‡ä»¶
â”‚           â”œâ”€â”€ ğŸ“„configuration_qwen3.py        # Qwen3æ¨¡å‹é…ç½®ç±»å®šä¹‰
â”‚           â”œâ”€â”€ ğŸ“„modeling_qwen3.py             # Qwen3æ¨¡å‹ä¸»ä½“å®ç°
â”‚           â”œâ”€â”€ ğŸ“„modeling_qwen3_infer.py       # Qwen3æ¨ç†æ¨¡å‹å®ç°
â”‚           â”œâ”€â”€ ğŸ“„modeling_qwen3_train.py       # Qwen3è®­ç»ƒæ¨¡å‹å®ç°
â”‚           â””â”€â”€ ğŸ“„utils.py                      # Qwen3å·¥å…·å‡½æ•°å’ŒåŸºç¡€ç±»
â”œâ”€â”€ ğŸ“‚configs
â”‚   â””â”€â”€ ğŸ“‚qwen3
â”‚       â”œâ”€â”€ ğŸ“„pretrain_qwen3_32b_4k.yaml       # Qwen3-32B 4k é¢„è®­ç»ƒé…ç½®
â”‚       â”œâ”€â”€ ğŸ“„predict_qwen3.yaml               # Qwen3æ¨ç†é…ç½®
â”‚       â””â”€â”€ ğŸ“„parallel_speed_up.json           # æ•°æ®é›†å¹¶è¡Œé€šä¿¡é…ç½®
â””â”€â”€ ğŸ“„run_mindformer.py                        # ä¸»è¦æ‰§è¡Œè„šæœ¬
```

### å¹¶è¡Œé…ç½®å»ºè®®

ä»¥ä¸‹é…ç½®ä¸ºè®­ç»ƒæˆ–æ¨ç†åœºæ™¯ä¸‹ï¼Œä¸åŒæ¨¡å‹è§„æ ¼çš„æ¨èé…ç½®ã€‚å…¶ä¸­éƒ¨åˆ†é…ç½®ä¸ºç»è¿‡éªŒè¯çš„æœ€ä½³é…ç½®ï¼Œéƒ¨åˆ†é…ç½®ä¸ºå¯ä»¥è¿è¡Œçš„é…ç½®ã€‚ç”¨æˆ·å¯æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©åˆé€‚çš„é…ç½®ã€‚

> æ³¨æ„ï¼šmax_device_memory åœ¨ Atlas 800T A2 å’Œ Atlas 900 A3 SuperPoD ç­‰æœºå™¨ä¸Šä¸€èˆ¬è®¾ç½®â‰¤60GBï¼Œåœ¨ Atlas 800I A2 ä¸Šä¸€èˆ¬è®¾ç½®â‰¤30GBã€‚

- é¢„è®­ç»ƒ/å…¨å‚å¾®è°ƒï¼š

<table>
  <tr>
    <th>æ¨¡å‹</th>
    <th>è§„æ ¼</th>
    <th>è®¾å¤‡</th>
    <th>å¡æ•°</th>
    <th>åºåˆ—é•¿åº¦</th>
    <th>å¹¶è¡Œé…ç½®</th>
    <th>é‡è®¡ç®—é…ç½®</th>
    <th>å†…å­˜é…ç½®</th>
    <th>æ¨¡å‹çº§åˆ«</th>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>32B</td>
    <td>2 Ã— Atlas 800T A2 (8P)</td>
    <td>16</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 4
  pipeline_stage: 4
  micro_batch_num: 4
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: True
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Validated </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>14B</td>
    <td>1 Ã— Atlas 800T A2 (8P)</td>
    <td>8</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 8
  pipeline_stage: 1
  micro_batch_num: 1
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: True
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Preliminary </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>8B</td>
    <td>1 Ã— Atlas 800T A2 (8P)</td>
    <td>8</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 8
  pipeline_stage: 1
  micro_batch_num: 1
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: False
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Preliminary </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>4B</td>
    <td>1 Ã— Atlas 800T A2 (8P)</td>
    <td>8</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 8
  pipeline_stage: 1
  micro_batch_num: 1
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: False
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Preliminary </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>1.7B</td>
    <td>1 Ã— Atlas 800T A2 (8P)</td>
    <td>8</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 8
  pipeline_stage: 1
  micro_batch_num: 1
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: False
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Preliminary </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>0.6B</td>
    <td>1 Ã— Atlas 800T A2 (8P)</td>
    <td>8</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 8
  pipeline_stage: 1
  micro_batch_num: 1
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: False
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Preliminary </td>
  </tr>
</table>

- LoRAå¾®è°ƒï¼š

<table>
  <tr>
    <th>æ¨¡å‹</th>
    <th>è§„æ ¼</th>
    <th>è®¾å¤‡</th>
    <th>å¡æ•°</th>
    <th>åºåˆ—é•¿åº¦</th>
    <th>å¹¶è¡Œé…ç½®</th>
    <th>é‡è®¡ç®—é…ç½®</th>
    <th>å†…å­˜é…ç½®</th>
    <th>æ¨¡å‹çº§åˆ«</th>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>32B</td>
    <td>Atlas 800T A2 (8P)</td>
    <td>8</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 8
  pipeline_stage: 1
  micro_batch_num: 1
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: True
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Validated </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>14B</td>
    <td>1 Ã— Atlas 800T A2 (8P)</td>
    <td>8</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 8
  pipeline_stage: 1
  micro_batch_num: 1
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: True
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Preliminary </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>8B</td>
    <td>1 Ã— Atlas 800T A2 (8P)</td>
    <td>8</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 8
  pipeline_stage: 1
  micro_batch_num: 1
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: False
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Preliminary </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>4B</td>
    <td>1 Ã— Atlas 800T A2 (8P)</td>
    <td>8</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 8
  pipeline_stage: 1
  micro_batch_num: 1
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: False
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Untested </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>1.7B</td>
    <td>1 Ã— Atlas 800T A2 (8P)</td>
    <td>8</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 8
  pipeline_stage: 1
  micro_batch_num: 1
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: False
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Untested </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>0.6B</td>
    <td>1 Ã— Atlas 800T A2 (8P)</td>
    <td>8</td>
    <td>4096</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 8
  pipeline_stage: 1
  micro_batch_num: 1
  use_seq_parallel: False
  gradient_aggregation_group: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">recompute_config:
  recompute: False
  select_recompute: False
  parallel_optimizer_comm_recompute: True
  mp_comm_recompute: True</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "58GB"</code></pre>
    </td>
    <td> Untested </td>
  </tr>
</table>

- æ¨ç†ï¼š

<table>
  <tr>
    <th>æ¨¡å‹</th>
    <th>è§„æ ¼</th>
    <th>è®¾å¤‡</th>
    <th>å¡æ•°</th>
    <th>å¹¶è¡Œé…ç½®</th>
    <th>å†…å­˜é…ç½®</th>
    <th>æ¨¡å‹çº§åˆ«</th>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>32B</td>
    <td>1 Ã— Atlas 800T A2 (2P)</td>
    <td>2</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 2</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "59GB"</code></pre>
    </td>
    <td> Released </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>0.6B</td>
    <td>1 Ã— Atlas 800T A2 (1P)</td>
    <td>1</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "59GB"</code></pre>
    </td>
    <td> Validated </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>8B</td>
    <td>1 Ã— Atlas 800T A2 (1P)</td>
    <td>1</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "59GB"</code></pre>
    </td>
    <td> Validated </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>1.7B</td>
    <td>1 Ã— Atlas 800T A2 (1P)</td>
    <td>1</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "59GB"</code></pre>
    </td>
    <td> Untested </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>4B</td>
    <td>1 Ã— Atlas 800T A2 (1P)</td>
    <td>1</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "59GB"</code></pre>
    </td>
    <td> Untested </td>
  </tr>
  <tr>
    <td>Qwen3</td>
    <td>14B</td>
    <td>1 Ã— Atlas 800T A2 (1P)</td>
    <td>1</td>
    <td>
      <pre><code class="language-yaml">parallel_config:
  data_parallel: &dp 1
  model_parallel: 1</code></pre>
    </td>
    <td>
      <pre><code class="language-yaml">context:
  ...
  max_device_memory: "59GB"</code></pre>
    </td>
    <td> Untested </td>
  </tr>
</table>

### FAQ

Q1ï¼šæˆ‘æœ‰ä¸¤å°Atlas 800T A2æœåŠ¡å™¨ï¼Œå¦‚ä½•è¿›è¡ŒQwen3çš„é¢„è®­ç»ƒï¼Ÿæ‹‰èµ·ä»»åŠ¡çš„æŒ‡ä»¤æ˜¯ä»€ä¹ˆï¼Ÿ

A1ï¼šæ ¹æ®æŒ‡å¯¼ä¿®æ”¹é…ç½®åï¼Œå‚è€ƒå¦‚ä¸‹å‘½ä»¤æ‹‰èµ·ä»»åŠ¡ï¼š

- æœºå™¨1 IP: 192.168.1.1 ï¼ˆä½œä¸ºä¸»èŠ‚ç‚¹ï¼‰

```bash
# æœºå™¨1çš„å¯åŠ¨æŒ‡ä»¤
master_ip=192.168.1.1
node_rank=0
port=50001

bash scripts/msrun_launcher.sh "run_mindformer.py \
--config configs/qwen3/pretrain_qwen3_32b_4k.yaml \
--auto_trans_ckpt False \
--use_parallel True \
--run_mode train" \
16 8 $master_ip $port $node_rank output/msrun_log False 7200
```

- æœºå™¨2 IP: 192.168.1.2

```bash
# æœºå™¨2çš„å¯åŠ¨æŒ‡ä»¤
master_ip=192.168.1.1
node_rank=1
port=50001

bash scripts/msrun_launcher.sh "run_mindformer.py \
--config configs/qwen3/pretrain_qwen3_32b_4k.yaml \
--auto_trans_ckpt False \
--use_parallel True \
--run_mode train" \
16 8 $master_ip $port $node_rank output/msrun_log False 7200
```

Q2: æ•°æ®é›†å‡†å¤‡éƒ¨åˆ†ä¸­ï¼Œåº”è¯¥å¦‚ä½•å°†`wiki.train.tokens` è½¬ä¸º `jsonl`æ ¼å¼æ•°æ®ï¼Ÿ

A2: [ç¤¾åŒºissue](https://gitee.com/mindspore/mindformers/issues/ICOKGY)ä¸­æä¾›äº†ä¸€ä¸ªä¸´æ—¶è½¬æ¢è„šæœ¬ï¼Œä»…ä½œä¸ºå‚è€ƒä½¿ç”¨ã€‚ç”¨æˆ·éœ€è¦æ ¹æ®è‡ªå·±çš„æ•°æ®ç‰¹ç‚¹å’Œéœ€æ±‚ï¼Œè‡ªè¡Œå¼€å‘å’ŒéªŒè¯é€‚åˆçš„è½¬æ¢é€»è¾‘ã€‚

Q3ï¼šå¦‚æœä¿®æ”¹äº†é…ç½®ä¸­çš„å‚æ•°ï¼Œä½¿ç”¨`run_mindformer.py`æ‹‰èµ·ä»»åŠ¡æ—¶ï¼Œè¿˜éœ€è¦é‡æ–°ä¼ å‚å—ï¼Ÿ

A3ï¼šæ ¹æ®æŒ‡å¯¼ä¿®æ”¹é…ç½®åï¼Œå‚æ•°å€¼å·²è¢«ä¿®æ”¹ï¼Œæ— éœ€é‡å¤ä¼ å‚ï¼Œ`run_mindformer.py`ä¼šè‡ªåŠ¨è¯»å–è§£æé…ç½®ä¸­çš„å‚æ•°ï¼›å¦‚æœæ²¡æœ‰ä¿®æ”¹é…ç½®ä¸­çš„å‚æ•°ï¼Œåˆ™éœ€è¦åœ¨å‘½ä»¤ä¸­æ·»åŠ å‚æ•°ã€‚

Q4ï¼šç”¨æˆ·ä½¿ç”¨åŒä¸€ä¸ªæœåŠ¡å™¨æ‹‰èµ·å¤šä¸ªæ¨ç†ä»»åŠ¡æ—¶ï¼Œç«¯å£å·å†²çªæ€ä¹ˆåŠï¼Ÿ

A4ï¼šç”¨æˆ·ä½¿ç”¨åŒä¸€ä¸ªæœåŠ¡å™¨æ‹‰èµ·å¤šä¸ªæ¨ç†ä»»åŠ¡æ—¶ï¼Œè¦æ³¨æ„ä¸èƒ½ä½¿ç”¨ç›¸åŒçš„ç«¯å£å·ï¼Œå»ºè®®å°†ç«¯å£å·ä»50000~65536ä¸­é€‰å–ï¼Œé¿å…ç«¯å£å·å†²çªçš„æƒ…å†µå‘ç”Ÿã€‚

Q5ï¼šæˆ‘æƒ³çœ‹çœ‹æˆ‘è®­ç»ƒä¸‹æ¥çš„æƒé‡æ•ˆæœæ€ä¹ˆæ ·ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨è®­ç»ƒæƒé‡åšæ¨ç†å—ï¼Ÿ

A5ï¼šå½“ç„¶å¯ä»¥ï¼ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹ä¸¤ç§æ–¹å¼è¿›è¡Œæ¨ç†ï¼š

1. **ç›´æ¥ä½¿ç”¨è®­ç»ƒæƒé‡è¿›è¡Œæ¨ç†**ï¼Œå¯ä»¥å‚è€ƒ[ã€Šè®­ç»ƒåæ¨¡å‹è¿›è¡Œè¯„æµ‹ã€‹](https://www.mindspore.cn/mindformers/docs/zh-CN/master/guide/evaluation.html#%E8%AE%AD%E7%BB%83%E5%90%8E%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E8%AF%84%E6%B5%8B)æ–‡æ¡£ï¼Œä½¿ç”¨å»ä¼˜åŒ–å™¨åˆå¹¶çš„è®­ç»ƒæƒé‡è¿›è¡Œæ¨ç†ã€‚
2. **åè½¬è®­ç»ƒæƒé‡ä¸º Hugging Face æ ¼å¼ï¼Œå¤ç”¨ Hugging Face ç”Ÿæ€è¿›è¡Œæ¨ç†**ï¼Œå¯ä»¥å‚è€ƒ [Qwen3 åè½¬è„šæœ¬](../../toolkit/weight_convert/qwen3/README.md)è¿›è¡Œæƒé‡åè½¬åï¼Œå†è¿›è¡Œæ¨ç†ä»»åŠ¡ã€‚